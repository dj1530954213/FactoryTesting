# FAT_TEST 系统重构详细实施步骤

## 📋 重构实施概览

### 🎯 实施原则
1.  **分阶段实施**: 确保每个阶段可独立验证，降低风险。
2.  **向后兼容**: 新组件在设计上应考虑逐步替换旧实现的可能性。
3.  **测试驱动**: 每个核心组件和业务逻辑都应有完整的单元测试和集成测试覆盖。
4.  **持续验证**: 每个阶段完成后进行严格的集成测试和端到端测试。
5.  **遵循规范**: 严格遵守项目 `mainrules` 中定义的技术栈、架构设计和代码规范。

### 🗓️ 实施计划 (4个阶段)

#### Phase 1: 数据访问层重构 (Repository Layer)
*   **目标**: 建立统一、类型安全、异步的数据访问接口，将数据存储细节与业务逻辑解耦。实现配置数据、运行时数据和持久化数据的分离管理。
*   **工期**: 2-3周
*   **关键产出**:
    *   `IRepository` 基础接口。
    *   `IConfigurationRepository` 接口和内存/Excel实现。
    *   `IRuntimeRepository` 接口和内存实现。
    *   `IPersistentRepository` 接口和SQLite (`sqlx`) 及内存实现。
    *   完整的单元测试和集成测试。

#### Phase 2: 状态管理器重构 (State Management)
*   **目标**: 建立严格、一致且事件驱动的 `ChannelTestInstance` 状态管理机制，遵循 `FAT-CSM-001` 和 `FAT-CSM-002` 规则。
*   **工期**: 1-2周
*   **关键产出**:
    *   `IChannelStateManager` 接口。
    *   `EnhancedChannelStateManager` 实现，集成 `IRuntimeRepository`。
    *   基于 `tokio::sync::broadcast` 的状态变更事件系统 (`FAT-EVT-001`)。
    *   详细的状态转换规则 (`StateTransitionRules`)。
    *   完整的单元测试。

#### Phase 3: 任务调度器与执行器重构 (Task Scheduling & Execution)
*   **目标**: 设计和实现一个健壮、高效、可控的测试任务调度与执行引擎，遵循 `FAT-TTM-001` 和 `FAT-CTK-001` 规则。
*   **工期**: 2-3周
*   **关键产出**:
    *   `ITaskScheduler` 接口。
    *   `AdvancedTaskScheduler` 实现，支持并发控制、任务生命周期管理。
    *   `ITestExecutor` 接口。
    *   针对核心 `SubTestItem` (如 `HardPoint`) 的 `ISpecificTestStepExecutor` 实现。
    *   任务事件系统。
    *   完整的单元测试和集成测试。

#### Phase 4: 应用服务层与Tauri接口重构 (Application Services & Tauri Commands)
*   **目标**: 重构应用服务层，采用服务组合模式封装业务流程。优化Tauri指令，确保前后端通信高效且类型安全。
*   **工期**: 2-3周
*   **关键产出**:
    *   `ITestOrchestrationService` 等核心应用服务接口及实现。
    *   `IDataManagementService` 和 `ISystemManagementService` 接口及实现（基于现有功能优化）。
    *   重构后的Tauri `#[tauri::command]` 函数，统一错误处理和数据格式。
    *   前端 `TauriApiService` 的对应调整。
    *   端到端测试。

---

## 🚀 Phase 1: 数据访问层重构 (Repository Layer)

### 📌 重构原因 (Phase 1)
当前系统中，数据访问逻辑可能散布在不同模块，或者与业务逻辑耦合较深。缺乏统一的数据访问抽象层会导致以下问题：
*   **难以维护和替换存储实现**: 如果需要从JSON文件切换到数据库，或更换数据库类型，将涉及大量代码修改。
*   **测试困难**: 业务逻辑直接依赖具体数据存储实现，难以进行单元测试和Mock。
*   **数据一致性风险**: 不同模块可能以不同方式操作数据，增加数据不一致的风险。
*   **代码重复**: 类似的数据查询和操作逻辑可能在多处重复。

通过引入Repository模式，我们可以创建一个抽象层来封装数据访问的细节，使得上层业务逻辑只依赖于接口，从而解决上述问题，提高系统的模块化、可测试性和可维护性。

### 步骤 1.1: 创建Repository基础接口

#### 🎯 目标
建立通用的数据访问抽象 `IRepository<T, K>`，为所有数据实体的基本CRUD操作提供一致的接口。同时定义统一的查询条件结构和Repository层错误类型。

#### 📝 具体实施

##### 1.1.1 创建基础Repository接口 (`IRepository`)
```rust
// src/services/persistence/repositories/base.rs
// 或者 src/repositories/base.rs (根据您的项目结构调整)
use async_trait::async_trait;
use serde::{Serialize, de::DeserializeOwned};
use std::fmt::Debug;
use crate::utils::error::AppError; // 使用项目统一的 AppError

/// 通用查询条件
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryCriteria {
    pub filters: Vec<Filter>,
    pub sort_by: Option<SortDescriptor>,
    pub limit: Option<usize>,
    pub offset: Option<usize>,
}

/// 过滤条件
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Filter {
    pub field: String,
    pub operator: FilterOperator,
    pub value: FilterValue,
}

/// 过滤操作符
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum FilterOperator {
    Equal,
    NotEqual,
    GreaterThan,
    LessThan,
    GreaterThanOrEqual,
    LessThanOrEqual,
    Contains,
    In,
    IsNull,
    IsNotNull,
}

/// 过滤值 (使用serde_json::Value以支持多种类型)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FilterValue {
    String(String),
    Number(f64), // 可以用 serde_json::Number 更灵活
    Boolean(bool),
    List(Vec<String>), // 对于 IN 操作符，值可以是字符串列表
    Json(serde_json::Value), // 通用JSON值
}

/// 排序描述符
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SortDescriptor {
    pub field: String,
    pub direction: SortDirection,
}

/// 排序方向
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SortDirection {
    Ascending,
    Descending,
}

impl QueryCriteria {
    pub fn new() -> Self {
        Self {
            filters: Vec::new(),
            sort_by: None,
            limit: None,
            offset: None,
        }
    }

    pub fn add_filter(mut self, field: &str, operator: FilterOperator, value: FilterValue) -> Self {
        self.filters.push(Filter {
            field: field.to_string(),
            operator,
            value,
        });
        self
    }

    pub fn set_sort(mut self, field: &str, direction: SortDirection) -> Self {
        self.sort_by = Some(SortDescriptor {
            field: field.to_string(),
            direction,
        });
        self
    }

    pub fn set_limit(mut self, limit: usize) -> Self {
        self.limit = Some(limit);
        self
    }

    pub fn set_offset(mut self, offset: usize) -> Self {
        self.offset = Some(offset);
        self
    }
}


/// 基础Repository接口定义
/// T: 实体类型, K: 实体主键类型
#[async_trait]
pub trait IRepository<T, K>: Send + Sync
where
    T: Send + Sync + Clone + Debug + Serialize + DeserializeOwned,
    K: Send + Sync + Clone + Debug + Serialize + DeserializeOwned,
{
    /// 根据主键获取单个实体
    async fn get_by_id(&self, id: &K) -> Result<Option<T>, AppError>;

    /// 获取所有实体
    async fn list_all(&self) -> Result<Vec<T>, AppError>;

    /// 根据查询条件获取实体列表
    async fn query(&self, criteria: QueryCriteria) -> Result<Vec<T>, AppError>;
    
    /// 根据查询条件统计实体数量
    async fn count(&self, criteria: QueryCriteria) -> Result<i64, AppError>;

    /// 创建新实体
    async fn create(&self, entity: &T) -> Result<T, AppError>;

    /// 更新现有实体
    async fn update(&self, entity: &T) -> Result<T, AppError>;

    /// 根据主键删除实体
    async fn delete_by_id(&self, id: &K) -> Result<bool, AppError>;

    /// 检查具有给定主键的实体是否存在
    async fn exists_by_id(&self, id: &K) -> Result<bool, AppError>;
}
```
**注意**: `AppError` 应包含适用于Repository操作的错误变体，如 `AppError::RecordNotFound`, `AppError::PersistenceError(String)`, `AppError::InvalidInput(String)` 等。这些应在 `src/utils/error.rs` 中定义。

#### 🧪 测试方案 (步骤 1.1)
由于 `IRepository` 是一个通用接口，其测试将在具体实现该接口的Repository（如 `MemoryConfigurationRepository` 或 `SqlitePersistentRepository`）中进行。这里可以规划一个通用的测试套件辅助trait，供具体实现使用。

```rust
// src/services/persistence/repositories/tests/repository_test_suite.rs
// 或者 src/repositories/tests/repository_test_suite.rs
#[async_trait::async_trait]
pub trait RepositoryTestSuite<T, K, R>
where
    T: Send + Sync + Clone + Debug + PartialEq + Serialize + DeserializeOwned + Default, // Default 用于轻松创建实例
    K: Send + Sync + Clone + Debug + Serialize + DeserializeOwned + PartialEq,
    R: IRepository<T, K> + Send + Sync,
{
    /// 创建Repository的实例以供测试
    async fn create_repository() -> R;

    /// 创建一个有效的测试实体，不包含ID (ID应由create方法生成或手动设置)
    fn create_sample_entity_to_create() -> T;
    
    /// 获取已创建实体的ID
    fn get_id_from_entity(entity: &T) -> K;
    
    /// 修改实体以供更新测试
    fn modify_entity_for_update(entity: &mut T);

    async fn run_all_tests() {
        Self::test_create_and_get().await;
        Self::test_update_entity().await;
        Self::test_delete_entity().await;
        Self::test_list_all_and_query().await;
        Self::test_exists_by_id().await;
        Self::test_count().await;
        Self::test_get_non_existent().await;
        Self::test_delete_non_existent().await;
    }

    async fn test_create_and_get() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();

        // 测试创建
        let created_entity = repo.create(&sample_entity).await.expect("创建实体失败");
        let entity_id = Self::get_id_from_entity(&created_entity);

        // 测试通过ID获取
        let fetched_entity = repo.get_by_id(&entity_id).await.expect("通过ID获取实体失败").expect("实体未找到");
        assert_eq!(created_entity, fetched_entity, "创建和获取的实体应该相同");
    }

    async fn test_update_entity() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();
        let mut created_entity = repo.create(&sample_entity).await.expect("创建实体失败");
        let entity_id = Self::get_id_from_entity(&created_entity);

        Self::modify_entity_for_update(&mut created_entity);
        let updated_entity = repo.update(&created_entity).await.expect("更新实体失败");
        assert_eq!(created_entity, updated_entity, "更新后的实体与预期不符");

        let fetched_after_update = repo.get_by_id(&entity_id).await.expect("获取更新后实体失败").expect("更新后实体未找到");
        assert_eq!(updated_entity, fetched_after_update, "获取的更新后实体与预期不符");
    }

    async fn test_delete_entity() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();
        let created_entity = repo.create(&sample_entity).await.expect("创建实体失败");
        let entity_id = Self::get_id_from_entity(&created_entity);

        let deleted = repo.delete_by_id(&entity_id).await.expect("删除实体失败");
        assert!(deleted, "删除操作应该返回true");

        let should_be_none = repo.get_by_id(&entity_id).await.expect("删除后获取实体失败");
        assert!(should_be_none.is_none(), "删除后实体应该不存在");
    }
    
    async fn test_list_all_and_query() {
        let repo = Self::create_repository().await;
        // 清理可能存在的旧数据或使用独立的测试数据库/表
        
        let mut entity1 = Self::create_sample_entity_to_create();
        // 为了查询，可能需要给实体设置一些可区分的字段值
        // (假设T有可供查询的字段，或者QueryCriteria支持特殊查询)
        repo.create(&entity1).await.expect("创建实体1失败");
        
        let mut entity2 = Self::create_sample_entity_to_create();
        Self::modify_entity_for_update(&mut entity2); // 使其与entity1不同
        repo.create(&entity2).await.expect("创建实体2失败");

        let all_entities = repo.list_all().await.expect("列出所有实体失败");
        assert!(all_entities.len() >= 2, "至少应有两个实体");

        // 此处需要具体的查询条件，取决于实体T的结构和测试目标
        // 例如： let criteria = QueryCriteria::new().add_filter("some_field", FilterOperator::Equal, FilterValue::String("value1".to_string()));
        // let queried_entities = repo.query(criteria).await.expect("查询实体失败");
        // assert_eq!(queried_entities.len(), 1);
    }

    async fn test_exists_by_id() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();
        let created_entity = repo.create(&sample_entity).await.expect("创建实体失败");
        let entity_id = Self::get_id_from_entity(&created_entity);
        
        let exists = repo.exists_by_id(&entity_id).await.expect("检查存在性失败");
        assert!(exists, "已创建的实体应该存在");

        // 假设一个不存在的ID
        // let non_existent_id: K = ...; // 需要一种方法创建或获取一个保证不存在的K类型ID
        // let not_exists = repo.exists_by_id(&non_existent_id).await.expect("检查不存在性失败");
        // assert!(!not_exists, "不存在的实体不应该存在");
    }
    
    async fn test_count() {
        let repo = Self::create_repository().await;
        // 清理或确保环境干净
        let initial_count = repo.count(QueryCriteria::new()).await.expect("初始计数失败");

        let entity1 = Self::create_sample_entity_to_create();
        repo.create(&entity1).await.expect("创建实体1失败");
        let count_after_one = repo.count(QueryCriteria::new()).await.expect("创建后计数失败");
        assert_eq!(count_after_one, initial_count + 1, "计数应增加1");

        // 此处可以添加带条件的计数测试
    }
    
    async fn test_get_non_existent() {
        let repo = Self::create_repository().await;
        // 假设一个不存在的ID
        // let non_existent_id: K = ...;
        // let result = repo.get_by_id(&non_existent_id).await.expect("获取不存在实体失败");
        // assert!(result.is_none(), "获取不存在的实体应返回None");
    }

    async fn test_delete_non_existent() {
        let repo = Self::create_repository().await;
        // 假设一个不存在的ID
        // let non_existent_id: K = ...;
        // let deleted = repo.delete_by_id(&non_existent_id).await.expect("删除不存在实体失败");
        // assert!(!deleted, "删除不存在的实体应返回false");
    }
}
```

#### ✅ 预期结果/完成标准 (步骤 1.1)
1.  `IRepository` 接口及其相关的 `QueryCriteria`, `Filter`, `SortDescriptor` 等辅助结构在代码库中定义完毕。
2.  `AppError` 中已包含 Repository 操作可能产生的错误类型 (如 `RecordNotFound`, `PersistenceError`)。
3.  `RepositoryTestSuite` 辅助 trait 定义完成，可供后续具体 Repository 实现使用。
4.  代码通过编译，符合项目代码规范。

---

### 步骤 1.2: 创建配置数据Repository (`IConfigurationRepository`)

#### 🎯 目标
实现专门管理配置数据的Repository，包括通道点位定义 (`ChannelPointDefinition`) 和测试参数集 (`TestParameterSet`)。提供从Excel导入/导出点位定义的功能，以及配置集的管理。此Repository将主要使用内存实现，因为配置数据通常在应用启动时加载且变动不频繁。

#### 📝 具体实施

##### 1.2.1 定义配置Repository接口 (`IConfigurationRepository`)
```rust
// src/services/persistence/repositories/configuration_repository.rs
// 或者 src/repositories/configuration_repository.rs
use async_trait::async_trait;
use std::collections::HashMap;
use crate::models::config::{ChannelPointDefinition, TestParameterSet, ExcelImportConfig}; // 假设这些已在models::config中定义
use crate::models::enums::ModuleType; // 假设已定义
use crate::utils::error::AppError;
use super::base::QueryCriteria; // 从 Step 1.1 引入

/// 验证问题详情
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ValidationIssue {
    pub severity: ValidationSeverity,
    pub message: String,
    pub field: Option<String>,    // 例如 "tag", "range_lower_limit"
    pub row_number: Option<usize>, // Excel导入时使用
    pub suggestion: Option<String>,
}

/// 验证严重级别
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum ValidationSeverity {
    Error,   // 阻止导入或保存
    Warning, // 可导入但提示用户
    Info,
}

/// 配置数据一致性报告
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConsistencyReport {
    pub total_definitions_checked: usize,
    pub duplicate_tags: Vec<String>, // 重复的位号
    pub issues: Vec<ValidationIssue>, // 其他一致性问题
}

/// 配置数据Repository接口
#[async_trait]
pub trait IConfigurationRepository: Send + Sync {
    // 单个点位定义管理
    async fn get_channel_definition_by_id(&self, id: &str) -> Result<Option<ChannelPointDefinition>, AppError>;
    async fn get_channel_definition_by_tag(&self, tag: &str) -> Result<Option<ChannelPointDefinition>, AppError>;
    async fn save_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError>; // 返回保存后的实体 (可能包含生成的ID)
    async fn update_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError>;
    async fn delete_channel_definition(&self, id: &str) -> Result<bool, AppError>;
    async fn list_all_channel_definitions(&self) -> Result<Vec<ChannelPointDefinition>, AppError>;
    async fn query_channel_definitions(&self, criteria: QueryCriteria) -> Result<Vec<ChannelPointDefinition>, AppError>;

    // 批量操作点位定义
    async fn save_channel_definitions_batch(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ChannelPointDefinition>, AppError>;
    async fn delete_channel_definitions_batch(&self, ids: &[String]) -> Result<usize, AppError>; // 返回删除的数量

    // Excel 导入/导出
    async fn import_definitions_from_excel(&self, file_path: &str, import_config: &ExcelImportConfig) -> Result<(Vec<ChannelPointDefinition>, Vec<ValidationIssue>), AppError>;
    async fn export_definitions_to_excel(&self, definitions: &[ChannelPointDefinition], file_path: &str) -> Result<(), AppError>;

    // 配置集管理 (例如，一个特定项目或产品型号的点位表)
    async fn save_configuration_set(&self, name: &str, definition_ids: &[String]) -> Result<(), AppError>;
    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, AppError>; // 返回该配置集包含的所有点位定义
    async fn list_configuration_sets(&self) -> Result<Vec<String>, AppError>; // 返回所有配置集名称
    async fn delete_configuration_set(&self, name: &str) -> Result<bool, AppError>;
    async fn add_definition_to_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError>;
    async fn remove_definition_from_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError>;

    // 测试参数管理 (例如，AI模块的测试容差、测试点)
    async fn get_test_parameters(&self, module_type: ModuleType) -> Result<Option<TestParameterSet>, AppError>;
    async fn save_test_parameters(&self, module_type: ModuleType, params: &TestParameterSet) -> Result<(), AppError>;
    async fn list_all_test_parameters(&self) -> Result<HashMap<ModuleType, TestParameterSet>, AppError>;

    // 数据验证和一致性检查
    async fn validate_definitions_list(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ValidationIssue>, AppError>;
    async fn check_overall_consistency(&self) -> Result<ConsistencyReport, AppError>;
}
```
**注意**: `ChannelPointDefinition`, `TestParameterSet`, `ExcelImportConfig` 等结构体需要在 `src/models/config.rs` 或类似模块中详细定义。`ExcelImportConfig` 可以包含如工作表名称、起始行、列映射等配置。

##### 1.2.2 实现内存配置Repository (`MemoryConfigurationRepository`)
```rust
// src/services/persistence/repositories/memory_configuration_repository.rs
// 或者 src/repositories/memory_configuration_repository.rs
use super::configuration_repository::*;
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;
use crate::models::enums::PointDataType; // 假设已定义

pub struct MemoryConfigurationRepository {
    // 使用ID作为主键
    definitions_by_id: Arc<RwLock<HashMap<String, ChannelPointDefinition>>>,
    // 辅助索引，位号 -> ID
    definitions_by_tag: Arc<RwLock<HashMap<String, String>>>,
    // 配置集名称 -> 点位ID列表
    configuration_sets: Arc<RwLock<HashMap<String, Vec<String>>>>,
    // 模块类型 -> 测试参数
    test_parameters: Arc<RwLock<HashMap<ModuleType, TestParameterSet>>>,
}

impl MemoryConfigurationRepository {
    pub fn new() -> Self {
        Self {
            definitions_by_id: Arc::new(RwLock::new(HashMap::new())),
            definitions_by_tag: Arc::new(RwLock::new(HashMap::new())),
            configuration_sets: Arc::new(RwLock::new(HashMap::new())),
            test_parameters: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    // 辅助函数，用于预填充测试数据
    pub async fn _populate_test_data(&self) {
        let def1 = ChannelPointDefinition {
            id: Uuid::new_v4().to_string(),
            tag: "AI_TEMP_001".to_string(),
            variable_name: "反应釜温度".to_string(),
            variable_description: "第一反应釜温度监测点".to_string(),
            module_type: ModuleType::AI,
            data_type: PointDataType::Float,
            plc_communication_address: "DB100.DBD0".to_string(),
            range_lower_limit: Some(0.0),
            range_upper_limit: Some(200.0),
            engineering_unit: Some("C".to_string()),
            // ... 其他字段根据 ChannelPointDefinition 补全
            station_name: "Station A".to_string(),
            module_name: "AI_Module_1".to_string(),
            channel_tag_in_module: "CH1".to_string(),
            power_supply_type: "24VDC".to_string(),
            wire_system: "2-wire".to_string(),
            plc_absolute_address: None,
            sll_set_value: None,
            sll_set_point_address: None,
            sll_feedback_address: None,
            sl_set_value: None,
            sl_set_point_address: None,
            sl_feedback_address: None,
            sh_set_value: None,
            sh_set_point_address: None,
            sh_feedback_address: None,
            shh_set_value: None,
            shh_set_point_address: None,
            shh_feedback_address: None,
            maintenance_value_set_point_address: None,
            maintenance_enable_switch_point_address: None,
            access_property: Some("RO".to_string()),
            save_history: Some(true),
            power_failure_protection: Some(false),
            test_rig_plc_address: None,
        };
        self.save_channel_definition(&def1).await.unwrap();

        let params_ai = TestParameterSet {
            default_range: Some((0.0, 100.0)),
            test_points: vec![0.0, 25.0, 50.0, 75.0, 100.0],
            tolerance: 0.5,
            test_sequence: vec![/* SubTestItem::HardPoint, ... */], // 需要 SubTestItem 定义
        };
        self.save_test_parameters(ModuleType::AI, &params_ai).await.unwrap();
    }
}

#[async_trait]
impl IConfigurationRepository for MemoryConfigurationRepository {
    async fn get_channel_definition_by_id(&self, id: &str) -> Result<Option<ChannelPointDefinition>, AppError> {
        let defs = self.definitions_by_id.read().await;
        Ok(defs.get(id).cloned())
    }

    async fn get_channel_definition_by_tag(&self, tag: &str) -> Result<Option<ChannelPointDefinition>, AppError> {
        let tags_to_ids = self.definitions_by_tag.read().await;
        if let Some(id) = tags_to_ids.get(tag) {
            let defs = self.definitions_by_id.read().await;
            Ok(defs.get(id).cloned())
        } else {
            Ok(None)
        }
    }

    async fn save_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError> {
        // 检查位号唯一性
        if self.get_channel_definition_by_tag(&definition.tag).await?.is_some() {
            return Err(AppError::ValidationFailed(format!("位号 '{}' 已存在", definition.tag)));
        }
        
        let mut def_to_save = definition.clone();
        if def_to_save.id.is_empty() || Uuid::try_parse(&def_to_save.id).is_err() { // 如果ID为空或无效，则生成新ID
            def_to_save.id = Uuid::new_v4().to_string();
        }

        let mut defs_by_id = self.definitions_by_id.write().await;
        let mut tags_to_ids = self.definitions_by_tag.write().await;

        defs_by_id.insert(def_to_save.id.clone(), def_to_save.clone());
        tags_to_ids.insert(def_to_save.tag.clone(), def_to_save.id.clone());
        
        Ok(def_to_save)
    }

    async fn update_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError> {
        let mut defs_by_id = self.definitions_by_id.write().await;
        let mut tags_to_ids = self.definitions_by_tag.write().await;

        if let Some(existing_def) = defs_by_id.get_mut(&definition.id) {
            // 如果位号发生改变，需要更新tag索引
            if existing_def.tag != definition.tag {
                // 检查新位号是否已存在 (且不属于当前更新的这个点)
                if let Some(id_for_new_tag) = tags_to_ids.get(&definition.tag) {
                    if id_for_new_tag != &definition.id {
                        return Err(AppError::ValidationFailed(format!("位号 '{}' 已被其他点位占用", definition.tag)));
                    }
                }
                tags_to_ids.remove(&existing_def.tag);
                tags_to_ids.insert(definition.tag.clone(), definition.id.clone());
            }
            *existing_def = definition.clone();
            Ok(definition.clone())
        } else {
            Err(AppError::RecordNotFound(format!("点位定义 ID: {} 未找到", definition.id)))
        }
    }
    
    async fn delete_channel_definition(&self, id: &str) -> Result<bool, AppError> {
        let mut defs_by_id = self.definitions_by_id.write().await;
        if let Some(removed_def) = defs_by_id.remove(id) {
            let mut tags_to_ids = self.definitions_by_tag.write().await;
            tags_to_ids.remove(&removed_def.tag);
            
            // 从所有配置集中移除该点位
            let mut sets = self.configuration_sets.write().await;
            for def_ids in sets.values_mut() {
                def_ids.retain(|def_id| def_id != id);
            }
            Ok(true)
        } else {
            Ok(false)
        }
    }

    async fn list_all_channel_definitions(&self) -> Result<Vec<ChannelPointDefinition>, AppError> {
        let defs = self.definitions_by_id.read().await;
        Ok(defs.values().cloned().collect())
    }

    async fn query_channel_definitions(&self, criteria: QueryCriteria) -> Result<Vec<ChannelPointDefinition>, AppError> {
        // 内存实现的查询逻辑 (简化版，可根据QueryCriteria扩展)
        let defs = self.definitions_by_id.read().await;
        let mut results: Vec<ChannelPointDefinition> = defs.values().cloned().collect();

        for filter in &criteria.filters {
            results.retain(|def| {
                match filter.field.as_str() {
                    "tag" => if let FilterValue::String(v) = &filter.value { def.tag.contains(v) } else { false },
                    "module_type" => if let FilterValue::String(v_str) = &filter.value {
                        if let Ok(mt) = v_str.parse::<ModuleType>() { def.module_type == mt } else { false }
                    } else { false },
                    // 添加更多字段过滤
                    _ => true,
                }
            });
        }
        // 实现排序、分页等
        Ok(results)
    }

    async fn save_channel_definitions_batch(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ChannelPointDefinition>, AppError> {
        let mut saved_definitions = Vec::new();
        for def in definitions {
            // 这里可以选择是否覆盖已存在的点位，或者返回错误。当前实现是覆盖。
            // 为了更安全，可以先检查是否存在，或者提供一个 overwrite 标志。
            // 当前save_channel_definition会处理ID生成和位号唯一性检查。
            match self.save_channel_definition(def).await {
                 Ok(saved_def) => saved_definitions.push(saved_def),
                 Err(AppError::ValidationFailed(msg)) if msg.contains("已存在") => {
                    // 如果是因为位号已存在而保存失败，尝试更新（如果业务逻辑允许）
                    // 或者收集这些错误统一返回
                    // 为简化，这里直接返回错误
                    return Err(AppError::ValidationFailed(format!("批量保存失败：{}", msg)));
                 }
                 Err(e) => return Err(e),
            }
        }
        Ok(saved_definitions)
    }
    
    async fn delete_channel_definitions_batch(&self, ids: &[String]) -> Result<usize, AppError> {
        let mut deleted_count = 0;
        for id in ids {
            if self.delete_channel_definition(id).await? {
                deleted_count += 1;
            }
        }
        Ok(deleted_count)
    }

    // Excel 导入/导出 (此为复杂功能，需要引入Excel处理库如 calamine, rust_xlsxwriter)
    // 以下为伪代码/高级步骤，具体实现会比较长
    async fn import_definitions_from_excel(&self, file_path: &str, import_config: &ExcelImportConfig) -> Result<(Vec<ChannelPointDefinition>, Vec<ValidationIssue>), AppError> {
        log::info!("开始从Excel导入点位定义: {}", file_path);
        // 1. 使用 calamine 打开和读取Excel文件 (workbook, worksheet)
        // 2. 根据 import_config (起始行, 列映射) 遍历行
        // 3. 对每一行数据:
        //    a. 解析单元格数据到 ChannelPointDefinition 结构体的字段
        //    b. 进行初步的数据类型转换和格式校验
        //    c. 如果有解析错误，记录到 ValidationIssue (Error级别)
        // 4. 收集所有成功解析的 ChannelPointDefinition
        // 5. 对解析成功的列表进行业务逻辑验证 (例如，通过 validate_definitions_list)
        // 6. 如果没有Error级别的ValidationIssue，则可以考虑保存这些点位 (例如，通过 save_channel_definitions_batch)
        // 7. 返回成功导入的点位列表和所有ValidationIssue (包括Error和Warning)
        
        // 示例：
        // let definitions_from_excel = parse_excel(file_path, import_config)?; // parse_excel是需要实现的辅助函数
        // let validation_issues = self.validate_definitions_list(&definitions_from_excel).await?;
        // if validation_issues.iter().any(|iss| iss.severity == ValidationSeverity::Error) {
        //     return Ok((vec![], validation_issues)); // 不导入，仅返回问题
        // }
        // let saved_definitions = self.save_channel_definitions_batch(&definitions_from_excel).await?;
        // Ok((saved_definitions, validation_issues))
        Err(AppError::NotImplemented("Excel导入功能尚未实现".to_string())) // 替换为实际实现
    }

    async fn export_definitions_to_excel(&self, definitions: &[ChannelPointDefinition], file_path: &str) -> Result<(), AppError> {
        log::info!("开始导出点位定义到Excel: {}", file_path);
        // 1. 使用 rust_xlsxwriter 创建新的Excel工作簿和工作表
        // 2. 写入表头 (根据 ChannelPointDefinition 的字段)
        // 3. 遍历 definitions 列表
        // 4. 将每个 ChannelPointDefinition 的字段写入到对应的单元格
        // 5. 保存工作簿到 file_path
        Err(AppError::NotImplemented("Excel导出功能尚未实现".to_string())) // 替换为实际实现
    }

    // 配置集管理
    async fn save_configuration_set(&self, name: &str, definition_ids: &[String]) -> Result<(), AppError> {
        let mut sets = self.configuration_sets.write().await;
        // 验证所有definition_id是否存在
        let defs_by_id = self.definitions_by_id.read().await;
        for id in definition_ids {
            if !defs_by_id.contains_key(id) {
                return Err(AppError::RecordNotFound(format!("点位 ID: {} 不存在，无法添加到配置集 '{}'", id, name)));
            }
        }
        sets.insert(name.to_string(), definition_ids.to_vec());
        Ok(())
    }

    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, AppError> {
        let sets = self.configuration_sets.read().await;
        if let Some(ids) = sets.get(name) {
            let defs_by_id = self.definitions_by_id.read().await;
            let mut result_defs = Vec::new();
            for id in ids {
                if let Some(def) = defs_by_id.get(id) {
                    result_defs.push(def.clone());
                } else {
                    log::warn!("配置集 '{}' 包含一个孤立的点位ID: {}", name, id);
                }
            }
            Ok(result_defs)
        } else {
            Err(AppError::RecordNotFound(format!("配置集 '{}' 未找到", name)))
        }
    }
    
    async fn list_configuration_sets(&self) -> Result<Vec<String>, AppError> {
        let sets = self.configuration_sets.read().await;
        Ok(sets.keys().cloned().collect())
    }

    async fn delete_configuration_set(&self, name: &str) -> Result<bool, AppError> {
        let mut sets = self.configuration_sets.write().await;
        Ok(sets.remove(name).is_some())
    }
    
    async fn add_definition_to_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError> {
        let mut sets = self.configuration_sets.write().await;
        if let Some(ids) = sets.get_mut(set_name) {
            if !self.definitions_by_id.read().await.contains_key(definition_id) {
                 return Err(AppError::RecordNotFound(format!("点位 ID: {} 不存在", definition_id)));
            }
            if !ids.contains(&definition_id.to_string()) {
                ids.push(definition_id.to_string());
            }
            Ok(())
        } else {
            Err(AppError::RecordNotFound(format!("配置集 '{}' 未找到", set_name)))
        }
    }

    async fn remove_definition_from_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError> {
        let mut sets = self.configuration_sets.write().await;
        if let Some(ids) = sets.get_mut(set_name) {
            ids.retain(|id| id != definition_id);
            Ok(())
        } else {
            Err(AppError::RecordNotFound(format!("配置集 '{}' 未找到", set_name)))
        }
    }

    // 测试参数管理
    async fn get_test_parameters(&self, module_type: ModuleType) -> Result<Option<TestParameterSet>, AppError> {
        let params = self.test_parameters.read().await;
        Ok(params.get(&module_type).cloned())
    }

    async fn save_test_parameters(&self, module_type: ModuleType, params: &TestParameterSet) -> Result<(), AppError> {
        let mut param_map = self.test_parameters.write().await;
        param_map.insert(module_type, params.clone());
        Ok(())
    }

    async fn list_all_test_parameters(&self) -> Result<HashMap<ModuleType, TestParameterSet>, AppError> {
        let params = self.test_parameters.read().await;
        Ok(params.clone())
    }
    
    // 数据验证和一致性检查
    async fn validate_definitions_list(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ValidationIssue>, AppError> {
        let mut issues = Vec::new();
        let mut existing_tags = HashMap::new(); // 用于检查列表内部的重复位号

        for (index, def) in definitions.iter().enumerate() {
            // 检查必填项
            if def.tag.is_empty() {
                issues.push(ValidationIssue {
                    severity: ValidationSeverity::Error, message: "位号不能为空".to_string(),
                    field: Some("tag".to_string()), row_number: Some(index + 1), suggestion: None,
                });
            } else {
                if let Some(first_occurrence_index) = existing_tags.get(&def.tag) {
                     issues.push(ValidationIssue {
                        severity: ValidationSeverity::Error,
                        message: format!("列表中存在重复位号: {}", def.tag),
                        field: Some("tag".to_string()), row_number: Some(index + 1),
                        suggestion: Some(format!("首次出现于行 {}", first_occurrence_index)),
                    });
                } else {
                    existing_tags.insert(def.tag.clone(), index + 1);
                }
            }
            if def.plc_communication_address.is_empty() {
                 issues.push(ValidationIssue {
                    severity: ValidationSeverity::Error, message: "PLC通讯地址不能为空".to_string(),
                    field: Some("plc_communication_address".to_string()), row_number: Some(index + 1), suggestion: None,
                });
            }
            // 检查量程
            if let (Some(low), Some(high)) = (def.range_lower_limit, def.range_upper_limit) {
                if low >= high {
                    issues.push(ValidationIssue {
                        severity: ValidationSeverity::Error,
                        message: format!("量程下限 ({}) 不能大于或等于上限 ({})", low, high),
                        field: Some("range".to_string()), row_number: Some(index + 1), suggestion: None,
                    });
                }
            }
            // TODO: 添加更多验证规则 (例如地址格式，枚举值有效性等)
        }
        Ok(issues)
    }

    async fn check_overall_consistency(&self) -> Result<ConsistencyReport, AppError> {
        let defs = self.definitions_by_id.read().await;
        let mut duplicate_tags = Vec::new();
        // 内存实现中，通过save/update时的检查，理论上不会有重复位号存入。
        // 但此检查可以用于验证数据完整性，或在从外部源加载数据后使用。
        // 此处简化，因为内存版在写入时已检查。
        
        Ok(ConsistencyReport {
            total_definitions_checked: defs.len(),
            duplicate_tags,
            issues: vec![], // 可添加更多检查，如孤立的配置集引用等
        })
    }
}
```

#### 🧪 测试方案 (步骤 1.2)
```rust
// src/services/persistence/repositories/tests/memory_configuration_repository_tests.rs
// 或者 src/repositories/tests/memory_configuration_repository_tests.rs
use crate::services::persistence::repositories::configuration_repository::*;
use crate::models::config::{ChannelPointDefinition, TestParameterSet}; // 假设在models::config中
use crate::models::enums::{ModuleType, PointDataType}; // 假设在models::enums中
use std::collections::HashMap;
use tokio;

// 辅助函数创建测试用 ChannelPointDefinition
fn create_sample_def(id_suffix: &str, tag: &str, module_type: ModuleType) -> ChannelPointDefinition {
    ChannelPointDefinition {
        id: format!("id_{}", id_suffix),
        tag: tag.to_string(),
        variable_name: format!("Var {}", tag),
        variable_description: format!("Desc for {}", tag),
        module_type,
        data_type: PointDataType::Float, // 示例
        plc_communication_address: format!("DB1.DBD{}", id_suffix),
        // ... 其他字段初始化 ...
        station_name: "Station A".to_string(),
        module_name: "AI_Module_1".to_string(),
        channel_tag_in_module: "CH1".to_string(),
        power_supply_type: "24VDC".to_string(),
        wire_system: "2-wire".to_string(),
        plc_absolute_address: None,
        range_lower_limit: Some(0.0),
        range_upper_limit: Some(100.0),
        engineering_unit: Some("mA".to_string()),
        sll_set_value: None, sll_set_point_address: None, sll_feedback_address: None,
        sl_set_value: None, sl_set_point_address: None, sl_feedback_address: None,
        sh_set_value: None, sh_set_point_address: None, sh_feedback_address: None,
        shh_set_value: None, shh_set_point_address: None, shh_feedback_address: None,
        maintenance_value_set_point_address: None, maintenance_enable_switch_point_address: None,
        access_property: Some("RW".to_string()), save_history: Some(true), power_failure_protection: Some(false),
        test_rig_plc_address: None,
    }
}

#[tokio::test]
async fn test_config_repo_save_and_get_definition() {
    let repo = MemoryConfigurationRepository::new();
    let def1_no_id = ChannelPointDefinition { 
        id: "".to_string(), // 测试ID自动生成
        tag: "TAG_001".to_string(), 
        module_type: ModuleType::AI, 
        plc_communication_address: "Addr1".to_string(),
        // ... 其他必填字段
        variable_name: "Var1".to_string(), variable_description: "Desc1".to_string(), data_type: PointDataType::Float,
        station_name: "S1".to_string(), module_name: "M1".to_string(), channel_tag_in_module: "C1".to_string(),
        power_supply_type: "P1".to_string(), wire_system: "W1".to_string(),
    };

    let saved_def1 = repo.save_channel_definition(&def1_no_id).await.unwrap();
    assert!(!saved_def1.id.is_empty());
    assert_eq!(saved_def1.tag, "TAG_001");

    let fetched_by_id = repo.get_channel_definition_by_id(&saved_def1.id).await.unwrap().unwrap();
    assert_eq!(fetched_by_id.tag, "TAG_001");

    let fetched_by_tag = repo.get_channel_definition_by_tag("TAG_001").await.unwrap().unwrap();
    assert_eq!(fetched_by_tag.id, saved_def1.id);

    // 测试保存具有相同位号的点位（应失败）
    let def_dup_tag = ChannelPointDefinition { 
        id: "".to_string(), 
        tag: "TAG_001".to_string(), // 相同位号
        module_type: ModuleType::AO, 
        plc_communication_address: "Addr2".to_string(),
        // ...
        variable_name: "Var2".to_string(), variable_description: "Desc2".to_string(), data_type: PointDataType::Float,
        station_name: "S2".to_string(), module_name: "M2".to_string(), channel_tag_in_module: "C2".to_string(),
        power_supply_type: "P2".to_string(), wire_system: "W2".to_string(),
    };
    assert!(repo.save_channel_definition(&def_dup_tag).await.is_err(), "保存重复位号应失败");
}

#[tokio::test]
async fn test_config_repo_update_definition() {
    let repo = MemoryConfigurationRepository::new();
    let initial_def = create_sample_def("1", "TAG_UPDATE_001", ModuleType::AI);
    let mut saved_def = repo.save_channel_definition(&initial_def).await.unwrap();

    saved_def.variable_name = "Updated Variable Name".to_string();
    saved_def.range_upper_limit = Some(250.0);
    let updated_def = repo.update_channel_definition(&saved_def).await.unwrap();
    assert_eq!(updated_def.variable_name, "Updated Variable Name");
    assert_eq!(updated_def.range_upper_limit, Some(250.0));

    let fetched_def = repo.get_channel_definition_by_id(&saved_def.id).await.unwrap().unwrap();
    assert_eq!(fetched_def.variable_name, "Updated Variable Name");
    
    // 测试更新位号
    saved_def.tag = "TAG_UPDATED_NEW".to_string();
    let tag_updated_def = repo.update_channel_definition(&saved_def).await.unwrap();
    assert_eq!(tag_updated_def.tag, "TAG_UPDATED_NEW");
    assert!(repo.get_channel_definition_by_tag("TAG_UPDATE_001").await.unwrap().is_none()); // 旧tag应不存在
    assert!(repo.get_channel_definition_by_tag("TAG_UPDATED_NEW").await.unwrap().is_some());
}

#[tokio::test]
async fn test_config_repo_delete_definition() {
    let repo = MemoryConfigurationRepository::new();
    let def_to_delete = create_sample_def("del1", "TAG_DELETE_001", ModuleType::DI);
    let saved_def = repo.save_channel_definition(&def_to_delete).await.unwrap();

    let deleted = repo.delete_channel_definition(&saved_def.id).await.unwrap();
    assert!(deleted);
    assert!(repo.get_channel_definition_by_id(&saved_def.id).await.unwrap().is_none());
    assert!(repo.get_channel_definition_by_tag("TAG_DELETE_001").await.unwrap().is_none());

    let not_deleted = repo.delete_channel_definition("non_existent_id").await.unwrap();
    assert!(!not_deleted);
}

#[tokio::test]
async fn test_config_repo_batch_operations() {
    let repo = MemoryConfigurationRepository::new();
    let defs_to_save = vec![
        create_sample_def("b1", "TAG_BATCH_001", ModuleType::AI),
        create_sample_def("b2", "TAG_BATCH_002", ModuleType::DO),
        create_sample_def("b3", "TAG_BATCH_003", ModuleType::AI),
    ];
    let saved_defs = repo.save_channel_definitions_batch(&defs_to_save).await.unwrap();
    assert_eq!(saved_defs.len(), 3);

    let all_defs = repo.list_all_channel_definitions().await.unwrap();
    assert_eq!(all_defs.len(), 3);

    let ids_to_delete: Vec<String> = saved_defs.iter().take(2).map(|d| d.id.clone()).collect();
    let deleted_count = repo.delete_channel_definitions_batch(&ids_to_delete).await.unwrap();
    assert_eq!(deleted_count, 2);

    let remaining_defs = repo.list_all_channel_definitions().await.unwrap();
    assert_eq!(remaining_defs.len(), 1);
    assert_eq!(remaining_defs[0].tag, "TAG_BATCH_003");
}

#[tokio::test]
async fn test_config_repo_configuration_sets() {
    let repo = MemoryConfigurationRepository::new();
    let def1 = repo.save_channel_definition(&create_sample_def("s1", "TAG_SET_001", ModuleType::AI)).await.unwrap();
    let def2 = repo.save_channel_definition(&create_sample_def("s2", "TAG_SET_002", ModuleType::DI)).await.unwrap();
    let def3 = repo.save_channel_definition(&create_sample_def("s3", "TAG_SET_003", ModuleType::AO)).await.unwrap();

    let set_name = "MyTestSet";
    repo.save_configuration_set(set_name, &vec![def1.id.clone(), def2.id.clone()]).await.unwrap();

    let loaded_set = repo.load_configuration_set(set_name).await.unwrap();
    assert_eq!(loaded_set.len(), 2);
    assert!(loaded_set.iter().any(|d| d.id == def1.id));
    assert!(loaded_set.iter().any(|d| d.id == def2.id));

    let set_list = repo.list_configuration_sets().await.unwrap();
    assert!(set_list.contains(&set_name.to_string()));
    
    // 添加点位到现有set
    repo.add_definition_to_set(set_name, &def3.id).await.unwrap();
    let loaded_set_after_add = repo.load_configuration_set(set_name).await.unwrap();
    assert_eq!(loaded_set_after_add.len(), 3);

    // 从set移除点位
    repo.remove_definition_from_set(set_name, &def1.id).await.unwrap();
    let loaded_set_after_remove = repo.load_configuration_set(set_name).await.unwrap();
    assert_eq!(loaded_set_after_remove.len(), 2);


    let deleted = repo.delete_configuration_set(set_name).await.unwrap();
    assert!(deleted);
    assert!(repo.load_configuration_set(set_name).await.is_err());
}

#[tokio::test]
async fn test_config_repo_test_parameters() {
    let repo = MemoryConfigurationRepository::new();
    let params_ai = TestParameterSet {
        default_range: Some((0.0, 100.0)),
        test_points: vec![0.0, 50.0, 100.0],
        tolerance: 1.0,
        test_sequence: vec![/* SubTestItem::HardPoint */], // 假设SubTestItem已定义
    };
    repo.save_test_parameters(ModuleType::AI, &params_ai).await.unwrap();

    let fetched_params = repo.get_test_parameters(ModuleType::AI).await.unwrap().unwrap();
    assert_eq!(fetched_params.tolerance, 1.0);

    let all_params = repo.list_all_test_parameters().await.unwrap();
    assert_eq!(all_params.len(), 1);
    assert!(all_params.contains_key(&ModuleType::AI));
}

#[tokio::test]
async fn test_config_repo_validation() {
    let repo = MemoryConfigurationRepository::new();
    let invalid_defs = vec![
        ChannelPointDefinition { tag: "".to_string(), plc_communication_address: "Addr".to_string(), module_type: ModuleType::AI, ..Default::default() }, // 空tag
        ChannelPointDefinition { tag: "ValidTag".to_string(), plc_communication_address: "".to_string(), module_type: ModuleType::DI, ..Default::default() }, // 空地址
        ChannelPointDefinition { tag: "RangeTest".to_string(), plc_communication_address: "Addr3".to_string(), module_type: ModuleType::AI, range_lower_limit: Some(100.0), range_upper_limit: Some(0.0), ..Default::default() }, // 错误量程
    ];
    let issues = repo.validate_definitions_list(&invalid_defs).await.unwrap();
    assert_eq!(issues.len(), 3);
    assert!(issues.iter().all(|issue| issue.severity == ValidationSeverity::Error));
    
    // 测试列表内重复位号
    let duplicate_tag_defs = vec![
        create_sample_def("dup1", "DUPLICATE_TAG", ModuleType::AI),
        create_sample_def("dup2", "DUPLICATE_TAG", ModuleType::AO),
    ];
    let duplicate_issues = repo.validate_definitions_list(&duplicate_tag_defs).await.unwrap();
    assert!(duplicate_issues.iter().any(|iss| iss.message.contains("DUPLICATE_TAG") && iss.field == Some("tag".to_string()) && iss.severity == ValidationSeverity::Error));
}

// TODO: 添加 Excel 导入/导出功能的测试用例 (需要mock文件系统或使用临时文件)
```

#### ✅ 预期结果/完成标准 (步骤 1.2)
1.  `IConfigurationRepository` 接口和 `MemoryConfigurationRepository` 实现完成。
2.  点位定义 (`ChannelPointDefinition`) 和测试参数 (`TestParameterSet`) 的CRUD操作功能正常。
3.  Excel导入/导出（高级步骤已规划，具体实现可后续迭代，但接口已定义）。
4.  配置集管理功能 (保存、加载、列表、删除) 正常工作。
5.  基本的数据验证逻辑 (`validate_definitions_list`) 已实现。
6.  单元测试覆盖核心功能，包括边界条件和错误处理。
7.  代码符合项目规范。

---

### 步骤 1.3: 创建运行时数据Repository (`IRuntimeRepository`)

#### 🎯 目标
实现专门管理运行时数据的Repository，例如 `ChannelTestInstance`（通道测试实例的实时状态和结果）和 `TestBatchInfo`（测试批次的运行时信息）。此Repository将主要使用内存实现，以保证高性能的读写访问。

#### 📝 具体实施

##### 1.3.1 定义运行时Repository接口 (`IRuntimeRepository`)
```rust
// src/services/persistence/repositories/runtime_repository.rs
// 或者 src/repositories/runtime_repository.rs
use async_trait::async_trait;
use crate::models::runtime::{ChannelTestInstance, TestBatchInfo, BatchStatistics, CacheStatistics}; // 假设在models::runtime中
use crate::models::enums::OverallTestStatus; // 假设在models::enums中
use crate::utils::error::AppError;
use super::base::QueryCriteria; // 从 Step 1.1 引入
use std::collections::HashMap;
use chrono::{DateTime, Utc};

/// 运行时数据Repository接口
#[async_trait]
pub trait IRuntimeRepository: Send + Sync {
    // 单个通道测试实例管理
    async fn get_channel_instance(&self, instance_id: &str) -> Result<Option<ChannelTestInstance>, AppError>;
    async fn save_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError>; // 返回保存的实例
    async fn update_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError>;
    async fn delete_channel_instance(&self, instance_id: &str) -> Result<bool, AppError>;
    async fn list_all_channel_instances(&self) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn query_channel_instances(&self, criteria: QueryCriteria) -> Result<Vec<ChannelTestInstance>, AppError>;

    // 批量操作通道测试实例
    async fn save_channel_instances_batch(&self, instances: &[ChannelTestInstance]) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn update_instances_status_batch(&self, instance_ids: &[String], new_status: OverallTestStatus, operator_notes: Option<String>) -> Result<usize, AppError>; // 返回更新的数量
    async fn delete_channel_instances_batch(&self, instance_ids: &[String]) -> Result<usize, AppError>;

    // 与特定测试批次相关的实例操作
    async fn list_instances_by_batch_id(&self, batch_id: &str) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn count_instances_by_batch_id(&self, batch_id: &str) -> Result<i64, AppError>;
    async fn get_batch_statistics(&self, batch_id: &str) -> Result<BatchStatistics, AppError>;
    async fn delete_instances_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError>; // 删除批次下所有实例

    // 按状态查询实例
    async fn list_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn count_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<i64, AppError>;

    // 测试批次信息管理
    async fn get_test_batch_info(&self, batch_id: &str) -> Result<Option<TestBatchInfo>, AppError>;
    async fn save_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError>;
    async fn update_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError>;
    async fn delete_test_batch_info(&self, batch_id: &str) -> Result<bool, AppError>; // 同时应考虑处理其下所有实例
    async fn list_all_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError>;
    async fn list_active_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError>; // 例如，状态不是Completed或Cancelled的批次

    // 缓存管理 (内存实现通常不需要显式缓存管理，但接口可以保留以备将来扩展)
    async fn clear_all_runtime_data(&self) -> Result<(), AppError>; // 清空所有运行时数据
    async fn get_runtime_cache_stats(&self) -> Result<CacheStatistics, AppError>;
}
```
**注意**: `ChannelTestInstance` 和 `TestBatchInfo` 结构体需要在 `src/models/runtime.rs` 中详细定义。`ChannelTestInstance` 应包含 `instance_id`, `definition_id`, `test_batch_id`, `overall_status`, `sub_test_results`, 时间戳等。`TestBatchInfo` 应包含 `batch_id`, `product_model`, 状态摘要，点位数等。

##### 1.3.2 实现内存运行时Repository (`MemoryRuntimeRepository`)
```rust
// src/services/persistence/repositories/memory_runtime_repository.rs
// 或者 src/repositories/memory_runtime_repository.rs
use super::runtime_repository::*;
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;
use crate::models::enums::SubTestItem; // For BatchStatistics example
use crate::models::runtime::SubTestExecutionResult; // For BatchStatistics example


pub struct MemoryRuntimeRepository {
    instances: Arc<RwLock<HashMap<String, ChannelTestInstance>>>,
    batches: Arc<RwLock<HashMap<String, TestBatchInfo>>>,
    // 辅助索引：batch_id -> Vec<instance_id>
    batch_to_instances_map: Arc<RwLock<HashMap<String, Vec<String>>>>,
    // 简易缓存统计
    cache_stats: Arc<RwLock<CacheStatistics>>,
}

impl MemoryRuntimeRepository {
    pub fn new() -> Self {
        Self {
            instances: Arc::new(RwLock::new(HashMap::new())),
            batches: Arc::new(RwLock::new(HashMap::new())),
            batch_to_instances_map: Arc::new(RwLock::new(HashMap::new())),
            cache_stats: Arc::new(RwLock::new(CacheStatistics {
                instance_count: 0,
                batch_count: 0,
                // 其他统计数据可以根据需要添加
            })),
        }
    }
    
    async fn update_stats_after_change(&self) {
        let mut stats = self.cache_stats.write().await;
        stats.instance_count = self.instances.read().await.len();
        stats.batch_count = self.batches.read().await.len();
    }
}

#[async_trait]
impl IRuntimeRepository for MemoryRuntimeRepository {
    async fn get_channel_instance(&self, instance_id: &str) -> Result<Option<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        Ok(inst_map.get(instance_id).cloned())
    }

    async fn save_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError> {
        let mut inst_to_save = instance.clone();
        if inst_to_save.instance_id.is_empty() || Uuid::try_parse(&inst_to_save.instance_id).is_err() {
            inst_to_save.instance_id = Uuid::new_v4().to_string();
        }
        
        let mut inst_map = self.instances.write().await;
        if inst_map.contains_key(&inst_to_save.instance_id) {
            return Err(AppError::AlreadyExists(format!("实例 ID: {} 已存在", inst_to_save.instance_id)));
        }
        inst_map.insert(inst_to_save.instance_id.clone(), inst_to_save.clone());

        // 更新 batch_to_instances_map
        let mut batch_map = self.batch_to_instances_map.write().await;
        batch_map.entry(inst_to_save.test_batch_id.clone())
            .or_default()
            .push(inst_to_save.instance_id.clone());
            
        self.update_stats_after_change().await;
        Ok(inst_to_save)
    }
    
    async fn update_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError> {
        let mut inst_map = self.instances.write().await;
        if !inst_map.contains_key(&instance.instance_id) {
            return Err(AppError::RecordNotFound(format!("实例 ID: {} 未找到", instance.instance_id)));
        }
        // 假设实例的test_batch_id不会改变；如果会，需要更复杂的逻辑来更新batch_to_instances_map
        inst_map.insert(instance.instance_id.clone(), instance.clone());
        self.update_stats_after_change().await;
        Ok(instance.clone())
    }

    async fn delete_channel_instance(&self, instance_id: &str) -> Result<bool, AppError> {
        let mut inst_map = self.instances.write().await;
        if let Some(removed_instance) = inst_map.remove(instance_id) {
            let mut batch_map = self.batch_to_instances_map.write().await;
            if let Some(ids_in_batch) = batch_map.get_mut(&removed_instance.test_batch_id) {
                ids_in_batch.retain(|id| id != instance_id);
                if ids_in_batch.is_empty() {
                    batch_map.remove(&removed_instance.test_batch_id);
                }
            }
            self.update_stats_after_change().await;
            Ok(true)
        } else {
            Ok(false)
        }
    }

    async fn list_all_channel_instances(&self) -> Result<Vec<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        Ok(inst_map.values().cloned().collect())
    }

    async fn query_channel_instances(&self, criteria: QueryCriteria) -> Result<Vec<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        let mut results: Vec<ChannelTestInstance> = inst_map.values().cloned().collect();
        // 实现过滤、排序、分页逻辑
        for filter in &criteria.filters {
            results.retain(|inst| {
                match filter.field.as_str() {
                    "test_batch_id" => if let FilterValue::String(v) = &filter.value { inst.test_batch_id == *v } else { false },
                    "overall_status" => if let FilterValue::String(v_str) = &filter.value {
                        if let Ok(status) = v_str.parse::<OverallTestStatus>() { inst.overall_status == status } else { false }
                    } else { false },
                    // ... 其他字段
                    _ => true,
                }
            });
        }
        Ok(results)
    }
    
    async fn save_channel_instances_batch(&self, instances: &[ChannelTestInstance]) -> Result<Vec<ChannelTestInstance>, AppError> {
        let mut saved_instances = Vec::new();
        for inst in instances {
            // 这里简化处理，如果ID已存在则跳过或报错。实际中可能需要更复杂的逻辑。
            if self.instances.read().await.contains_key(&inst.instance_id) {
                 log::warn!("批量保存时跳过已存在的实例ID: {}", inst.instance_id);
                 continue; // 或者返回错误
            }
            saved_instances.push(self.save_channel_instance(inst).await?);
        }
        Ok(saved_instances)
    }

    async fn update_instances_status_batch(&self, instance_ids: &[String], new_status: OverallTestStatus, operator_notes: Option<String>) -> Result<usize, AppError> {
        let mut inst_map = self.instances.write().await;
        let mut updated_count = 0;
        for id in instance_ids {
            if let Some(instance) = inst_map.get_mut(id) {
                instance.overall_status = new_status;
                instance.last_updated_time = Utc::now();
                // instance.error_message = operator_notes.clone(); // 根据需要设置
                updated_count += 1;
            }
        }
        Ok(updated_count)
    }
    
    async fn delete_channel_instances_batch(&self, instance_ids: &[String]) -> Result<usize, AppError> {
        let mut deleted_count = 0;
        for id in instance_ids {
            if self.delete_channel_instance(id).await? {
                deleted_count += 1;
            }
        }
        Ok(deleted_count)
    }

    async fn list_instances_by_batch_id(&self, batch_id: &str) -> Result<Vec<ChannelTestInstance>, AppError> {
        let batch_map = self.batch_to_instances_map.read().await;
        if let Some(instance_ids) = batch_map.get(batch_id) {
            let inst_map = self.instances.read().await;
            let result = instance_ids.iter()
                .filter_map(|id| inst_map.get(id).cloned())
                .collect();
            Ok(result)
        } else {
            Ok(Vec::new())
        }
    }
    
    async fn count_instances_by_batch_id(&self, batch_id: &str) -> Result<i64, AppError> {
        let batch_map = self.batch_to_instances_map.read().await;
        Ok(batch_map.get(batch_id).map_or(0, |ids| ids.len() as i64))
    }

    async fn get_batch_statistics(&self, batch_id: &str) -> Result<BatchStatistics, AppError> {
        let instances = self.list_instances_by_batch_id(batch_id).await?;
        let total_instances = instances.len();
        let mut stats = BatchStatistics {
            batch_id: batch_id.to_string(),
            total_instances,
            status_counts: HashMap::new(),
            progress_percentage: 0.0,
            // ... 其他统计字段
        };
        let mut tested_count = 0;
        for inst in instances {
            *stats.status_counts.entry(inst.overall_status).or_insert(0) += 1;
            if inst.overall_status != OverallTestStatus::NotTested && inst.overall_status != OverallTestStatus::Skipped { // 假设Skipped不算测试过
                 tested_count +=1;
            }
        }
        if total_instances > 0 {
            let completed_count = stats.status_counts.get(&OverallTestStatus::TestCompletedPassed).unwrap_or(&0) +
                                  stats.status_counts.get(&OverallTestStatus::TestCompletedFailed).unwrap_or(&0) +
                                  stats.status_counts.get(&OverallTestStatus::Skipped).unwrap_or(&0);
            stats.progress_percentage = (completed_count as f64 / total_instances as f64) * 100.0;
        }
        Ok(stats)
    }
    
    async fn delete_instances_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError> {
        let mut inst_map = self.instances.write().await;
        let mut batch_map = self.batch_to_instances_map.write().await;
        let mut deleted_count = 0;

        if let Some(instance_ids) = batch_map.remove(batch_id) {
            for id in instance_ids {
                if inst_map.remove(&id).is_some() {
                    deleted_count +=1;
                }
            }
        }
        self.update_stats_after_change().await;
        Ok(deleted_count)
    }

    async fn list_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<Vec<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        let results = inst_map.values()
            .filter(|inst| inst.overall_status == status && (batch_id.is_none() || inst.test_batch_id == batch_id.unwrap()))
            .cloned()
            .collect();
        Ok(results)
    }

    async fn count_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<i64, AppError> {
        let inst_map = self.instances.read().await;
        let count = inst_map.values()
            .filter(|inst| inst.overall_status == status && (batch_id.is_none() || inst.test_batch_id == batch_id.unwrap()))
            .count();
        Ok(count as i64)
    }

    async fn get_test_batch_info(&self, batch_id: &str) -> Result<Option<TestBatchInfo>, AppError> {
        let batch_map = self.batches.read().await;
        Ok(batch_map.get(batch_id).cloned())
    }

    async fn save_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError> {
        let mut batch_to_save = batch_info.clone();
        if batch_to_save.batch_id.is_empty() || Uuid::try_parse(&batch_to_save.batch_id).is_err() {
             batch_to_save.batch_id = Uuid::new_v4().to_string();
        }

        let mut batch_map = self.batches.write().await;
        if batch_map.contains_key(&batch_to_save.batch_id) {
            return Err(AppError::AlreadyExists(format!("批次ID: {} 已存在", batch_to_save.batch_id)));
        }
        batch_map.insert(batch_to_save.batch_id.clone(), batch_to_save.clone());
        self.update_stats_after_change().await;
        Ok(batch_to_save)
    }
    
    async fn update_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError> {
        let mut batch_map = self.batches.write().await;
        if !batch_map.contains_key(&batch_info.batch_id) {
            return Err(AppError::RecordNotFound(format!("批次ID: {} 未找到", batch_info.batch_id)));
        }
        batch_map.insert(batch_info.batch_id.clone(), batch_info.clone());
        self.update_stats_after_change().await;
        Ok(batch_info.clone())
    }

    async fn delete_test_batch_info(&self, batch_id: &str) -> Result<bool, AppError> {
        let mut batch_map = self.batches.write().await;
        if batch_map.remove(batch_id).is_some() {
            // 同时删除该批次下的所有实例
            self.delete_instances_by_batch_id(batch_id).await?;
            self.update_stats_after_change().await;
            Ok(true)
        } else {
            Ok(false)
        }
    }
    
    async fn list_all_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError> {
        let batch_map = self.batches.read().await;
        Ok(batch_map.values().cloned().collect())
    }

    async fn list_active_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError> {
        let batch_map = self.batches.read().await;
        // 示例：假设TestBatchInfo有一个 status 字段
        // Ok(batch_map.values().filter(|b| b.status != BatchStatus::Completed && b.status != BatchStatus::Cancelled).cloned().collect())
        // 为简化，此处返回所有
        Ok(batch_map.values().cloned().collect())
    }

    async fn clear_all_runtime_data(&self) -> Result<(), AppError> {
        self.instances.write().await.clear();
        self.batches.write().await.clear();
        self.batch_to_instances_map.write().await.clear();
        self.update_stats_after_change().await;
        log::info!("所有运行时数据已清空");
        Ok(())
    }
    
    async fn get_runtime_cache_stats(&self) -> Result<CacheStatistics, AppError> {
        Ok(self.cache_stats.read().await.clone())
    }
}
```

#### 🧪 测试方案 (步骤 1.3)
```rust
// src/services/persistence/repositories/tests/memory_runtime_repository_tests.rs
// 或者 src/repositories/tests/memory_runtime_repository_tests.rs
use crate::services::persistence::repositories::runtime_repository::*;
use crate::models::runtime::{ChannelTestInstance, TestBatchInfo, SubTestExecutionResult};
use crate::models::enums::{OverallTestStatus, SubTestItem, TestResult}; // 假设在models::enums中
use tokio;
use uuid::Uuid;
use chrono::Utc;

// 辅助函数创建测试用 ChannelTestInstance
fn create_sample_instance(id_suffix: &str, batch_id: &str, status: OverallTestStatus) -> ChannelTestInstance {
    ChannelTestInstance {
        instance_id: format!("inst_{}", id_suffix),
        definition_id: format!("def_{}", id_suffix),
        test_batch_id: batch_id.to_string(),
        overall_status: status,
        current_step_details: None,
        error_message: None,
        start_time: Some(Utc::now()),
        last_updated_time: Utc::now(),
        final_test_time: None,
        total_test_duration_ms: None,
        sub_test_results: HashMap::new(),
        hardpoint_readings: None,
        manual_test_current_value_input: None,
        manual_test_current_value_output: None,
    }
}

// 辅助函数创建测试用 TestBatchInfo
fn create_sample_batch(id_suffix: &str, product_model: &str) -> TestBatchInfo {
    TestBatchInfo {
        batch_id: format!("batch_{}", id_suffix),
        product_model: Some(product_model.to_string()),
        serial_number: Some(format!("SN{}", id_suffix)),
        customer_name: Some("Test Customer".to_string()),
        creation_time: Utc::now(),
        status_summary: Some("已创建".to_string()),
        total_points: 0,
        tested_points: 0,
        passed_points: 0,
        failed_points: 0,
    }
}


#[tokio::test]
async fn test_runtime_repo_save_and_get_instance() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("1", "ModelX")).await.unwrap();
    let inst1 = create_sample_instance("1", &batch1.batch_id, OverallTestStatus::NotTested);
    
    let saved_inst = repo.save_channel_instance(&inst1).await.unwrap();
    assert_eq!(saved_inst.instance_id, inst1.instance_id);

    let fetched_inst = repo.get_channel_instance(&inst1.instance_id).await.unwrap().unwrap();
    assert_eq!(fetched_inst.definition_id, inst1.definition_id);
    
    // 检查是否已添加到 batch_to_instances_map
    let batch_instances = repo.list_instances_by_batch_id(&batch1.batch_id).await.unwrap();
    assert_eq!(batch_instances.len(), 1);
    assert_eq!(batch_instances[0].instance_id, inst1.instance_id);
}

#[tokio::test]
async fn test_runtime_repo_update_instance() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("1", "ModelX")).await.unwrap();
    let mut inst1 = create_sample_instance("1", &batch1.batch_id, OverallTestStatus::NotTested);
    repo.save_channel_instance(&inst1).await.unwrap();

    inst1.overall_status = OverallTestStatus::TestCompletedPassed;
    inst1.error_message = Some("Test error".to_string());
    let updated_inst = repo.update_channel_instance(&inst1).await.unwrap();
    assert_eq!(updated_inst.overall_status, OverallTestStatus::TestCompletedPassed);

    let fetched_inst = repo.get_channel_instance(&inst1.instance_id).await.unwrap().unwrap();
    assert_eq!(fetched_inst.error_message, Some("Test error".to_string()));
}

#[tokio::test]
async fn test_runtime_repo_delete_instance() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("1", "ModelX")).await.unwrap();
    let inst1 = create_sample_instance("1", &batch1.batch_id, OverallTestStatus::NotTested);
    repo.save_channel_instance(&inst1).await.unwrap();

    let deleted = repo.delete_channel_instance(&inst1.instance_id).await.unwrap();
    assert!(deleted);
    assert!(repo.get_channel_instance(&inst1.instance_id).await.unwrap().is_none());
    
    // 检查是否已从 batch_to_instances_map 移除
    let batch_instances = repo.list_instances_by_batch_id(&batch1.batch_id).await.unwrap();
    assert!(batch_instances.is_empty());
}

#[tokio::test]
async fn test_runtime_repo_batch_instance_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("b1", "ModelX")).await.unwrap();
    let instances_to_save = vec![
        create_sample_instance("b_i1", &batch1.batch_id, OverallTestStatus::NotTested),
        create_sample_instance("b_i2", &batch1.batch_id, OverallTestStatus::NotTested),
    ];
    let saved_instances = repo.save_channel_instances_batch(&instances_to_save).await.unwrap();
    assert_eq!(saved_instances.len(), 2);

    let instance_ids: Vec<String> = saved_instances.iter().map(|i| i.instance_id.clone()).collect();
    let updated_count = repo.update_instances_status_batch(&instance_ids, OverallTestStatus::HardPointTesting, None).await.unwrap();
    assert_eq!(updated_count, 2);

    let fetched_inst1 = repo.get_channel_instance(&instance_ids[0]).await.unwrap().unwrap();
    assert_eq!(fetched_inst1.overall_status, OverallTestStatus::HardPointTesting);
    
    let deleted_count = repo.delete_channel_instances_batch(&instance_ids).await.unwrap();
    assert_eq!(deleted_count, 2);
    assert_eq!(repo.list_instances_by_batch_id(&batch1.batch_id).await.unwrap().len(), 0);
}

#[tokio::test]
async fn test_runtime_repo_batch_info_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch_info1 = create_sample_batch("info1", "ModelY");
    
    let saved_batch = repo.save_test_batch_info(&batch_info1).await.unwrap();
    assert_eq!(saved_batch.batch_id, batch_info1.batch_id);

    let mut fetched_batch = repo.get_test_batch_info(&batch_info1.batch_id).await.unwrap().unwrap();
    assert_eq!(fetched_batch.product_model, Some("ModelY".to_string()));

    fetched_batch.status_summary = Some("测试中".to_string());
    repo.update_test_batch_info(&fetched_batch).await.unwrap();
    let updated_batch = repo.get_test_batch_info(&batch_info1.batch_id).await.unwrap().unwrap();
    assert_eq!(updated_batch.status_summary, Some("测试中".to_string()));

    let all_batches = repo.list_all_test_batch_infos().await.unwrap();
    assert_eq!(all_batches.len(), 1);

    let deleted = repo.delete_test_batch_info(&batch_info1.batch_id).await.unwrap();
    assert!(deleted);
    assert!(repo.get_test_batch_info(&batch_info1.batch_id).await.unwrap().is_none());
}

#[tokio::test]
async fn test_runtime_repo_delete_batch_cascades_instances() {
    let repo = MemoryRuntimeRepository::new();
    let batch = repo.save_test_batch_info(&create_sample_batch("cascade", "ModelZ")).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("c_i1", &batch.batch_id, OverallTestStatus::NotTested)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("c_i2", &batch.batch_id, OverallTestStatus::NotTested)).await.unwrap();

    assert_eq!(repo.list_instances_by_batch_id(&batch.batch_id).await.unwrap().len(), 2);

    repo.delete_test_batch_info(&batch.batch_id).await.unwrap();
    assert!(repo.get_test_batch_info(&batch.batch_id).await.unwrap().is_none());
    assert_eq!(repo.list_instances_by_batch_id(&batch.batch_id).await.unwrap().len(), 0, "删除批次后其实例也应被删除");
    assert!(repo.batch_to_instances_map.read().await.get(&batch.batch_id).is_none(), "批次映射也应被清除");
}

#[tokio::test]
async fn test_runtime_repo_get_batch_statistics() {
    let repo = MemoryRuntimeRepository::new();
    let batch = repo.save_test_batch_info(&create_sample_batch("stats", "ModelStats")).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i1", &batch.batch_id, OverallTestStatus::NotTested)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i2", &batch.batch_id, OverallTestStatus::TestCompletedPassed)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i3", &batch.batch_id, OverallTestStatus::TestCompletedFailed)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i4", &batch.batch_id, OverallTestStatus::HardPointTesting)).await.unwrap();

    let stats = repo.get_batch_statistics(&batch.batch_id).await.unwrap();
    assert_eq!(stats.total_instances, 4);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::NotTested).unwrap_or(&0), 1);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::TestCompletedPassed).unwrap_or(&0), 1);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::TestCompletedFailed).unwrap_or(&0), 1);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::HardPointTesting).unwrap_or(&0), 1);
    assert_eq!(stats.progress_percentage, 50.0); // (Passed + Failed) / Total = 2/4
}


#[tokio::test]
async fn test_runtime_repo_clear_all() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("clear1", "ModelX")).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("c_i1", &batch1.batch_id, OverallTestStatus::NotTested)).await.unwrap();
    
    repo.clear_all_runtime_data().await.unwrap();
    
    assert_eq!(repo.list_all_channel_instances().await.unwrap().len(), 0);
    assert_eq!(repo.list_all_test_batch_infos().await.unwrap().len(), 0);
    let stats = repo.get_runtime_cache_stats().await.unwrap();
    assert_eq!(stats.instance_count, 0);
    assert_eq!(stats.batch_count, 0);
}
```

#### ✅ 预期结果/完成标准 (步骤 1.3)
1.  `IRuntimeRepository` 接口和 `MemoryRuntimeRepository` 实现完成。
2.  `ChannelTestInstance` 和 `TestBatchInfo` 的CRUD及批量操作功能正常。
3.  与批次相关的实例查询和统计功能正常工作。
4.  按状态查询实例的功能正常工作。
5.  基本的缓存统计信息能够获取。
6.  单元测试覆盖核心功能，确保数据一致性和并发场景下的正确性。
7.  代码符合项目规范。

---
### 步骤 1.4: 创建持久化数据Repository (`IPersistentRepository`)

#### 🎯 重构原因
运行时Repository (`MemoryRuntimeRepository`) 中的数据是易失的，无法满足长期数据存储、历史追溯和报告的需求。`IPersistentRepository` 的目标是提供一个接口，用于将关键的测试数据（如最终的测试记录、批次摘要）保存到持久化存储中（本项目选用SQLite）。这确保了数据的持久性、可审计性和用于历史分析。

#### 📝 具体实施

##### 1.4.1 定义持久化Repository接口和相关数据结构
这些结构体主要用于持久化存储，可能与运行时结构体有差异或为其快照。

```rust
// src/services/persistence/repositories/persistent_repository.rs
// 或者 src/repositories/persistent_repository.rs
use async_trait::async_trait;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use crate::utils::error::AppError;
use super::base::QueryCriteria; // 从 Step 1.1 引入
use crate::models::enums::{OverallTestStatus, TestResult, SubTestItem}; // 引入所需枚举

/// 用于持久化的测试记录 (TestRecord 的持久化版本)
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, sqlx::FromRow)]
pub struct PersistedTestRecord {
    #[sqlx(rename = "record_id")] // 确保与数据库列名一致
    pub record_id: String,        // 主键, 可以是 instance_id
    pub instance_id: String,
    pub definition_id: String,
    pub test_batch_id: String,
    pub product_model: Option<String>,
    pub serial_number: Option<String>,
    pub overall_status_text: String, // 存储 OverallTestStatus 的文本表示
    pub start_time: Option<DateTime<Utc>>,
    pub final_test_time: Option<DateTime<Utc>>,
    pub total_test_duration_ms: Option<i64>,
    pub error_message: Option<String>,
    pub sub_test_results_json: String, // 存储序列化后的 HashMap<SubTestItem, SubTestExecutionResult>
    // 从 ChannelPointDefinition 快照的关键信息
    pub tag: String,
    pub variable_name: String,
    pub plc_communication_address: String,
    pub module_type_text: String, // 存储 ModuleType 的文本表示
    // 记录创建和更新时间
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

/// 用于持久化的测试批次信息 (TestBatchInfo 的持久化版本)
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, sqlx::FromRow)]
pub struct PersistedTestBatch {
    #[sqlx(rename = "batch_id")]
    pub batch_id: String, // 主键
    pub product_model: Option<String>,
    pub serial_number: Option<String>,
    pub customer_name: Option<String>,
    pub creation_time: DateTime<Utc>,
    pub completion_time: Option<DateTime<Utc>>,
    pub status_summary_text: String, // 例如 "已完成", "部分失败"
    pub total_points: i32,
    pub tested_points: i32,
    pub passed_points: i32,
    pub failed_points: i32,
    pub skipped_points: i32,
    pub report_path: Option<String>, // 生成的报告文件路径
    // 记录创建和更新时间
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

// 子测试执行结果，用于序列化到 PersistedTestRecord 的 JSON 字段
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct PersistedSubTestExecutionResult {
    pub result: TestResult,
    pub measured_value: Option<f64>,
    pub expected_value: Option<f64>,
    pub tolerance: Option<f64>,
    pub timestamp: DateTime<Utc>,
    pub error_message: Option<String>,
    pub duration_ms: Option<i64>,
}


/// 持久化数据Repository接口
#[async_trait]
pub trait IPersistentRepository: Send + Sync {
    // 测试记录管理
    async fn save_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError>;
    async fn get_test_record_by_id(&self, record_id: &str) -> Result<Option<PersistedTestRecord>, AppError>;
    async fn list_test_records_by_batch_id(&self, batch_id: &str) -> Result<Vec<PersistedTestRecord>, AppError>;
    async fn query_test_records(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestRecord>, AppError>;
    async fn count_test_records(&self, criteria: QueryCriteria) -> Result<i64, AppError>;
    async fn update_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError>; // 如果需要更新已持久化的记录

    // 批次持久化管理
    async fn save_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError>;
    async fn get_test_batch_by_id(&self, batch_id: &str) -> Result<Option<PersistedTestBatch>, AppError>;
    async fn list_historical_batches(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestBatch>, AppError>; // 使用QueryCriteria进行灵活查询
    async fn count_historical_batches(&self, criteria: QueryCriteria) -> Result<i64, AppError>;
    async fn update_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError>;

    // 数据清理 (可选，根据需求)
    async fn delete_old_test_records(&self, older_than: DateTime<Utc>) -> Result<usize, AppError>; // 返回删除的记录数
    async fn delete_old_test_batches(&self, older_than: DateTime<Utc>) -> Result<usize, AppError>;
    
    // 初始化 (例如，创建表结构)
    async fn initialize_schema(&self) -> Result<(), AppError>;
}
```

##### 1.4.2 SQLite 表结构设计
以下是建议的SQLite表结构，请您根据 `ChannelMappings_202505292135.sql` 和实际需求调整。

```sql
-- 表：persisted_test_batches (存储测试批次摘要信息)
CREATE TABLE IF NOT EXISTS persisted_test_batches (
    batch_id TEXT PRIMARY KEY NOT NULL,
    product_model TEXT,
    serial_number TEXT,
    customer_name TEXT,
    creation_time TEXT NOT NULL,       -- ISO8601 DateTime String
    completion_time TEXT,            -- ISO8601 DateTime String
    status_summary_text TEXT NOT NULL, -- 'Completed', 'Failed', 'Cancelled'
    total_points INTEGER NOT NULL DEFAULT 0,
    tested_points INTEGER NOT NULL DEFAULT 0,
    passed_points INTEGER NOT NULL DEFAULT 0,
    failed_points INTEGER NOT NULL DEFAULT 0,
    skipped_points INTEGER NOT NULL DEFAULT 0,
    report_path TEXT,
    created_at TEXT NOT NULL,          -- ISO8601 DateTime String
    updated_at TEXT NOT NULL           -- ISO8601 DateTime String
);

CREATE INDEX IF NOT EXISTS idx_ptb_creation_time ON persisted_test_batches(creation_time);
CREATE INDEX IF NOT EXISTS idx_ptb_product_model ON persisted_test_batches(product_model);
CREATE INDEX IF NOT EXISTS idx_ptb_serial_number ON persisted_test_batches(serial_number);

-- 表：persisted_test_records (存储单个测试实例的详细结果)
CREATE TABLE IF NOT EXISTS persisted_test_records (
    record_id TEXT PRIMARY KEY NOT NULL, -- 通常是 instance_id
    instance_id TEXT NOT NULL,
    definition_id TEXT NOT NULL,
    test_batch_id TEXT NOT NULL,
    product_model TEXT,
    serial_number TEXT,                  -- 从批次信息冗余或关联查询
    overall_status_text TEXT NOT NULL,   -- OverallTestStatus 枚举的文本
    start_time TEXT,                     -- ISO8601 DateTime String
    final_test_time TEXT,                -- ISO8601 DateTime String
    total_test_duration_ms INTEGER,
    error_message TEXT,
    sub_test_results_json TEXT NOT NULL, -- JSON 字符串存储 HashMap<SubTestItem, PersistedSubTestExecutionResult>
    tag TEXT NOT NULL,                   -- 从 ChannelPointDefinition 快照
    variable_name TEXT NOT NULL,         -- 从 ChannelPointDefinition 快照
    plc_communication_address TEXT NOT NULL, -- 从 ChannelPointDefinition 快照
    module_type_text TEXT NOT NULL,      -- ModuleType 枚举的文本, 从 ChannelPointDefinition 快照
    created_at TEXT NOT NULL,            -- ISO8601 DateTime String
    updated_at TEXT NOT NULL,             -- ISO8601 DateTime String
    FOREIGN KEY (test_batch_id) REFERENCES persisted_test_batches(batch_id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_ptr_test_batch_id ON persisted_test_records(test_batch_id);
CREATE INDEX IF NOT EXISTS idx_ptr_tag ON persisted_test_records(tag);
CREATE INDEX IF NOT EXISTS idx_ptr_final_test_time ON persisted_test_records(final_test_time);
CREATE INDEX IF NOT EXISTS idx_ptr_overall_status ON persisted_test_records(overall_status_text);
```

##### 1.4.3 实现SQLite持久化Repository (`SqlitePersistentRepository`)
需要 `sqlx` crate，并启用 `sqlite`, `runtime-tokio-rustls` (或 `runtime-tokio-native-tls`), `macros`, `chrono`, `json` 特性。

```rust
// src/services/persistence/repositories/sqlite_persistent_repository.rs
// 或者 src/repositories/sqlite_persistent_repository.rs
use super::persistent_repository::*;
use sqlx::{SqlitePool, Row}; // Row for manual mapping if needed
use sqlx::sqlite::SqliteConnectOptions;
use std::str::FromStr;

pub struct SqlitePersistentRepository {
    pool: SqlitePool,
}

impl SqlitePersistentRepository {
    pub async fn new(database_url: &str) -> Result<Self, AppError> {
        let options = SqliteConnectOptions::from_str(database_url)?
            .create_if_missing(true); // 自动创建数据库文件
            
        let pool = SqlitePool::connect_with(options).await
            .map_err(|e| AppError::DatabaseConnectionError(e.to_string()))?;
        let repo = Self { pool };
        repo.initialize_schema().await?; // 确保表已创建
        Ok(repo)
    }
}

#[async_trait]
impl IPersistentRepository for SqlitePersistentRepository {
    async fn initialize_schema(&self) -> Result<(), AppError> {
        sqlx::query(
            r#"
            CREATE TABLE IF NOT EXISTS persisted_test_batches (
                batch_id TEXT PRIMARY KEY NOT NULL, product_model TEXT, serial_number TEXT,
                customer_name TEXT, creation_time TEXT NOT NULL, completion_time TEXT,
                status_summary_text TEXT NOT NULL, total_points INTEGER NOT NULL DEFAULT 0,
                tested_points INTEGER NOT NULL DEFAULT 0, passed_points INTEGER NOT NULL DEFAULT 0,
                failed_points INTEGER NOT NULL DEFAULT 0, skipped_points INTEGER NOT NULL DEFAULT 0,
                report_path TEXT, created_at TEXT NOT NULL, updated_at TEXT NOT NULL
            );
            CREATE INDEX IF NOT EXISTS idx_ptb_creation_time ON persisted_test_batches(creation_time);

            CREATE TABLE IF NOT EXISTS persisted_test_records (
                record_id TEXT PRIMARY KEY NOT NULL, instance_id TEXT NOT NULL, definition_id TEXT NOT NULL,
                test_batch_id TEXT NOT NULL, product_model TEXT, serial_number TEXT,
                overall_status_text TEXT NOT NULL, start_time TEXT, final_test_time TEXT,
                total_test_duration_ms INTEGER, error_message TEXT, sub_test_results_json TEXT NOT NULL,
                tag TEXT NOT NULL, variable_name TEXT NOT NULL, plc_communication_address TEXT NOT NULL,
                module_type_text TEXT NOT NULL, created_at TEXT NOT NULL, updated_at TEXT NOT NULL,
                FOREIGN KEY (test_batch_id) REFERENCES persisted_test_batches(batch_id) ON DELETE CASCADE
            );
            CREATE INDEX IF NOT EXISTS idx_ptr_test_batch_id ON persisted_test_records(test_batch_id);
            CREATE INDEX IF NOT EXISTS idx_ptr_tag ON persisted_test_records(tag);
            "#
        )
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(format!("初始化表结构失败: {}", e)))?;
        Ok(())
    }

    async fn save_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        sqlx::query(
            r#"
            INSERT INTO persisted_test_records (
                record_id, instance_id, definition_id, test_batch_id, product_model, serial_number,
                overall_status_text, start_time, final_test_time, total_test_duration_ms, error_message,
                sub_test_results_json, tag, variable_name, plc_communication_address, module_type_text,
                created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            "#
        )
        .bind(&record.record_id).bind(&record.instance_id).bind(&record.definition_id)
        .bind(&record.test_batch_id).bind(&record.product_model).bind(&record.serial_number)
        .bind(&record.overall_status_text).bind(record.start_time.map(|dt| dt.to_rfc3339()))
        .bind(record.final_test_time.map(|dt| dt.to_rfc3339())).bind(record.total_test_duration_ms)
        .bind(&record.error_message).bind(&record.sub_test_results_json).bind(&record.tag)
        .bind(&record.variable_name).bind(&record.plc_communication_address).bind(&record.module_type_text)
        .bind(record.created_at.to_rfc3339()).bind(record.updated_at.to_rfc3339())
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }
    
    async fn update_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        sqlx::query(
            r#"
            UPDATE persisted_test_records SET
                instance_id = ?, definition_id = ?, test_batch_id = ?, product_model = ?, serial_number = ?,
                overall_status_text = ?, start_time = ?, final_test_time = ?, total_test_duration_ms = ?,
                error_message = ?, sub_test_results_json = ?, tag = ?, variable_name = ?,
                plc_communication_address = ?, module_type_text = ?, updated_at = ?
            WHERE record_id = ?
            "#
        )
        .bind(&record.instance_id).bind(&record.definition_id)
        .bind(&record.test_batch_id).bind(&record.product_model).bind(&record.serial_number)
        .bind(&record.overall_status_text).bind(record.start_time.map(|dt| dt.to_rfc3339()))
        .bind(record.final_test_time.map(|dt| dt.to_rfc3339())).bind(record.total_test_duration_ms)
        .bind(&record.error_message).bind(&record.sub_test_results_json).bind(&record.tag)
        .bind(&record.variable_name).bind(&record.plc_communication_address).bind(&record.module_type_text)
        .bind(Utc::now().to_rfc3339()) // 更新 updated_at
        .bind(&record.record_id)
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }

    async fn get_test_record_by_id(&self, record_id: &str) -> Result<Option<PersistedTestRecord>, AppError> {
        sqlx::query_as::<_, PersistedTestRecord>(
            "SELECT * FROM persisted_test_records WHERE record_id = ?"
        )
        .bind(record_id)
        .fetch_optional(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))
    }
    
    async fn list_test_records_by_batch_id(&self, batch_id: &str) -> Result<Vec<PersistedTestRecord>, AppError> {
        sqlx::query_as::<_, PersistedTestRecord>(
            "SELECT * FROM persisted_test_records WHERE test_batch_id = ? ORDER BY created_at ASC"
        )
        .bind(batch_id)
        .fetch_all(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))
    }

    async fn query_test_records(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestRecord>, AppError> {
        // 构建动态SQL查询 (注意SQL注入风险，对于复杂查询，考虑查询构建器)
        // 此处为简化示例，实际应更健壮
        let mut sql = "SELECT * FROM persisted_test_records WHERE 1=1".to_string();
        // TODO: 根据 criteria.filters 构建 WHERE 子句
        // TODO: 根据 criteria.sort_by 构建 ORDER BY 子句
        // TODO: 根据 criteria.limit, criteria.offset 构建 LIMIT 和 OFFSET
        sqlx::query_as::<_, PersistedTestRecord>(&sql)
            .fetch_all(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))
    }
    
    async fn count_test_records(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        // 简化实现，实际应根据criteria构建查询
        let row = sqlx::query("SELECT COUNT(*) as count FROM persisted_test_records")
            .fetch_one(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(row.try_get("count").unwrap_or(0))
    }


    async fn save_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
        sqlx::query(
            r#"
            INSERT INTO persisted_test_batches (
                batch_id, product_model, serial_number, customer_name, creation_time, completion_time,
                status_summary_text, total_points, tested_points, passed_points, failed_points, skipped_points,
                report_path, created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            "#
        )
        .bind(&batch.batch_id).bind(&batch.product_model).bind(&batch.serial_number)
        .bind(&batch.customer_name).bind(batch.creation_time.to_rfc3339())
        .bind(batch.completion_time.map(|dt| dt.to_rfc3339())).bind(&batch.status_summary_text)
        .bind(batch.total_points).bind(batch.tested_points).bind(batch.passed_points)
        .bind(batch.failed_points).bind(batch.skipped_points).bind(&batch.report_path)
        .bind(batch.created_at.to_rfc3339()).bind(batch.updated_at.to_rfc3339())
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }
    
    async fn update_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
        sqlx::query(
             r#"
            UPDATE persisted_test_batches SET
                product_model = ?, serial_number = ?, customer_name = ?, creation_time = ?, completion_time = ?,
                status_summary_text = ?, total_points = ?, tested_points = ?, passed_points = ?,
                failed_points = ?, skipped_points = ?, report_path = ?, updated_at = ?
            WHERE batch_id = ?
            "#
        )
        .bind(&batch.product_model).bind(&batch.serial_number).bind(&batch.customer_name)
        .bind(batch.creation_time.to_rfc3339()).bind(batch.completion_time.map(|dt| dt.to_rfc3339()))
        .bind(&batch.status_summary_text).bind(batch.total_points).bind(batch.tested_points)
        .bind(batch.passed_points).bind(batch.failed_points).bind(batch.skipped_points)
        .bind(&batch.report_path).bind(Utc::now().to_rfc3339()) // 更新 updated_at
        .bind(&batch.batch_id)
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }

    async fn get_test_batch_by_id(&self, batch_id: &str) -> Result<Option<PersistedTestBatch>, AppError> {
        sqlx::query_as::<_, PersistedTestBatch>(
            "SELECT * FROM persisted_test_batches WHERE batch_id = ?"
        )
        .bind(batch_id)
        .fetch_optional(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))
    }

    async fn list_historical_batches(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestBatch>, AppError> {
        // 简化实现，实际应根据criteria构建查询
        // 示例：查询特定时间范围的批次
        let mut sql = "SELECT * FROM persisted_test_batches WHERE 1=1".to_string();
        for filter in criteria.filters {
            if filter.field == "creation_time_gte" {
                if let FilterValue::String(dt_str) = filter.value {
                     sql.push_str(&format!(" AND creation_time >= '{}'", dt_str));
                }
            }
            if filter.field == "creation_time_lte" {
                 if let FilterValue::String(dt_str) = filter.value {
                     sql.push_str(&format!(" AND creation_time <= '{}'", dt_str));
                }
            }
            // 添加更多过滤条件
        }
        sql.push_str(" ORDER BY creation_time DESC");
        if let Some(limit) = criteria.limit {
            sql.push_str(&format!(" LIMIT {}", limit));
             if let Some(offset) = criteria.offset {
                sql.push_str(&format!(" OFFSET {}", offset));
            }
        }
        
        sqlx::query_as::<_, PersistedTestBatch>(&sql)
            .fetch_all(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))
    }
    
    async fn count_historical_batches(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        // 简化实现
        let row = sqlx::query("SELECT COUNT(*) as count FROM persisted_test_batches")
            .fetch_one(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(row.try_get("count").unwrap_or(0))
    }

    async fn delete_old_test_records(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        let result = sqlx::query("DELETE FROM persisted_test_records WHERE created_at < ?")
            .bind(older_than.to_rfc3339())
            .execute(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(result.rows_affected() as usize)
    }

    async fn delete_old_test_batches(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        // 注意：如果设置了级联删除，删除批次也会删除其下的记录。
        // 如果没有级联，需要先删除记录或处理孤立记录。
        let result = sqlx::query("DELETE FROM persisted_test_batches WHERE created_at < ?")
            .bind(older_than.to_rfc3339())
            .execute(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(result.rows_affected() as usize)
    }
}
```

##### 1.4.4 实现内存持久化Repository (`MemoryPersistentRepository`) - 用于测试和开发
```rust
// src/services/persistence/repositories/memory_persistent_repository.rs
// 或者 src/repositories/memory_persistent_repository.rs
use super::persistent_repository::*;
use std::sync::Arc;
use tokio::sync::RwLock;

pub struct MemoryPersistentRepository {
    records: Arc<RwLock<HashMap<String, PersistedTestRecord>>>,
    batches: Arc<RwLock<HashMap<String, PersistedTestBatch>>>,
}

impl MemoryPersistentRepository {
    pub fn new() -> Self {
        Self {
            records: Arc::new(RwLock::new(HashMap::new())),
            batches: Arc::new(RwLock::new(HashMap::new())),
        }
    }
}

#[async_trait]
impl IPersistentRepository for MemoryPersistentRepository {
    async fn initialize_schema(&self) -> Result<(), AppError> {
        // 内存实现不需要初始化表结构
        Ok(())
    }

    async fn save_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        let mut records = self.records.write().await;
        records.insert(record.record_id.clone(), record.clone());
        Ok(())
    }

    async fn get_test_record_by_id(&self, record_id: &str) -> Result<Option<PersistedTestRecord>, AppError> {
        let records = self.records.read().await;
        Ok(records.get(record_id).cloned())
    }
    
    async fn list_test_records_by_batch_id(&self, batch_id: &str) -> Result<Vec<PersistedTestRecord>, AppError> {
        let records = self.records.read().await;
        Ok(records.values().filter(|r| r.test_batch_id == batch_id).cloned().collect())
    }

    async fn query_test_records(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestRecord>, AppError> {
        let records = self.records.read().await;
        let mut results: Vec<PersistedTestRecord> = records.values().cloned().collect();
        // 实现过滤、排序、分页
        Ok(results)
    }
    
    async fn count_test_records(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        let records = self.records.read().await;
        Ok(records.len() as i64) // 简化
    }
    
    async fn update_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        let mut records = self.records.write().await;
        if records.contains_key(&record.record_id) {
            records.insert(record.record_id.clone(), record.clone());
            Ok(())
        } else {
            Err(AppError::RecordNotFound(record.record_id.clone()))
        }
    }

    async fn save_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
        let mut batches = self.batches.write().await;
        batches.insert(batch.batch_id.clone(), batch.clone());
        Ok(())
    }

    async fn get_test_batch_by_id(&self, batch_id: &str) -> Result<Option<PersistedTestBatch>, AppError> {
        let batches = self.batches.read().await;
        Ok(batches.get(batch_id).cloned())
    }
    
    async fn list_historical_batches(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestBatch>, AppError> {
        let batches = self.batches.read().await;
        let mut results: Vec<PersistedTestBatch> = batches.values().cloned().collect();
        // 实现过滤、排序、分页
        Ok(results)
    }

    async fn count_historical_batches(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        let batches = self.batches.read().await;
        Ok(batches.len() as i64) // 简化
    }
    
    async fn update_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
         let mut batches = self.batches.write().await;
        if batches.contains_key(&batch.batch_id) {
            batches.insert(batch.batch_id.clone(), batch.clone());
            Ok(())
        } else {
            Err(AppError::RecordNotFound(batch.batch_id.clone()))
        }
    }
    
    async fn delete_old_test_records(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        let mut records = self.records.write().await;
        let initial_len = records.len();
        records.retain(|_, record| record.created_at >= older_than);
        Ok(initial_len - records.len())
    }

    async fn delete_old_test_batches(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        let mut batches = self.batches.write().await;
        let initial_len = batches.len();
        batches.retain(|_, batch| batch.created_at >= older_than);
        Ok(initial_len - batches.len())
    }
}
```

#### 🧪 测试方案 (步骤 1.4)
测试将分别针对 `SqlitePersistentRepository` 和 `MemoryPersistentRepository`。
对于 `SqlitePersistentRepository`，测试时可以使用内存中的SQLite数据库 (`sqlite::memory:`) 或临时文件数据库，并在每次测试前后清理。

```rust
// src/services/persistence/repositories/tests/persistent_repository_tests.rs
// 或者 src/repositories/tests/persistent_repository_tests.rs
use crate::services::persistence::repositories::persistent_repository::*;
use crate::services::persistence::repositories::sqlite_persistent_repository::SqlitePersistentRepository;
use crate::services::persistence::repositories::memory_persistent_repository::MemoryPersistentRepository;
use crate::models::enums::{OverallTestStatus, TestResult, SubTestItem, ModuleType}; // 假设在models::enums中
use tokio;
use uuid::Uuid;
use chrono::{Utc, Duration};
use serde_json;
use std::collections::HashMap;

async fn persistent_repository_test_suite(repo_builder: impl Fn() -> Box<dyn IPersistentRepository>) {
    let repo = repo_builder();
    repo.initialize_schema().await.expect("Schema initialization failed"); // SQLite repo需要

    // 1. 测试批次 (PersistedTestBatch)
    let batch1_id = Uuid::new_v4().to_string();
    let batch1 = PersistedTestBatch {
        batch_id: batch1_id.clone(),
        product_model: Some("ModelX-Persist".to_string()),
        serial_number: Some("SN-PERSIST-001".to_string()),
        customer_name: Some("Customer Persist".to_string()),
        creation_time: Utc::now() - Duration::days(1),
        completion_time: Some(Utc::now()),
        status_summary_text: "Completed".to_string(),
        total_points: 10, tested_points: 10, passed_points: 8, failed_points: 1, skipped_points: 1,
        report_path: Some("/reports/batch1.pdf".to_string()),
        created_at: Utc::now() - Duration::days(1),
        updated_at: Utc::now(),
    };
    repo.save_test_batch(&batch1).await.expect("Failed to save batch1");

    let fetched_batch1 = repo.get_test_batch_by_id(&batch1_id).await.unwrap().expect("Batch1 not found");
    assert_eq!(fetched_batch1.product_model, batch1.product_model);

    // 2. 测试记录 (PersistedTestRecord)
    let record1_id = Uuid::new_v4().to_string();
    let sub_results: HashMap<SubTestItem, PersistedSubTestExecutionResult> = HashMap::from([
        (SubTestItem::HardPoint, PersistedSubTestExecutionResult { 
            result: TestResult::Passed, measured_value: Some(5.0), expected_value: Some(5.0), tolerance: Some(0.1), 
            timestamp: Utc::now(), error_message: None, duration_ms: Some(100)
        })
    ]);
    let record1 = PersistedTestRecord {
        record_id: record1_id.clone(),
        instance_id: Uuid::new_v4().to_string(),
        definition_id: Uuid::new_v4().to_string(),
        test_batch_id: batch1_id.clone(),
        product_model: batch1.product_model.clone(),
        serial_number: batch1.serial_number.clone(),
        overall_status_text: OverallTestStatus::TestCompletedPassed.to_string(),
        start_time: Some(Utc::now() - Duration::minutes(5)),
        final_test_time: Some(Utc::now()),
        total_test_duration_ms: Some(300000),
        error_message: None,
        sub_test_results_json: serde_json::to_string(&sub_results).unwrap(),
        tag: "AI_TAG_001_P".to_string(),
        variable_name: "Temperature Persisted".to_string(),
        plc_communication_address: "DB1.DBD0.P".to_string(),
        module_type_text: ModuleType::AI.to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    repo.save_test_record(&record1).await.expect("Failed to save record1");

    let fetched_record1 = repo.get_test_record_by_id(&record1_id).await.unwrap().expect("Record1 not found");
    assert_eq!(fetched_record1.tag, record1.tag);
    let deserialized_subs: HashMap<SubTestItem, PersistedSubTestExecutionResult> = serde_json::from_str(&fetched_record1.sub_test_results_json).unwrap();
    assert_eq!(deserialized_subs.len(), 1);
    
    // 3. 测试列表和查询
    let records_in_batch1 = repo.list_test_records_by_batch_id(&batch1_id).await.unwrap();
    assert_eq!(records_in_batch1.len(), 1);

    // 4. 测试更新
    let mut updated_batch1 = fetched_batch1.clone();
    updated_batch1.status_summary_text = "Completed with remarks".to_string();
    updated_batch1.updated_at = Utc::now(); // Manually update for memory repo, DB repo might auto-update
    repo.update_test_batch(&updated_batch1).await.expect("Failed to update batch1");
    let fetched_after_update_b1 = repo.get_test_batch_by_id(&batch1_id).await.unwrap().unwrap();
    assert_eq!(fetched_after_update_b1.status_summary_text, "Completed with remarks");

    // 5. 测试数据清理 (如果实现)
    let old_batch_id = Uuid::new_v4().to_string();
    let old_batch_time = Utc::now() - Duration::days(100);
    let old_batch = PersistedTestBatch { batch_id: old_batch_id.clone(), creation_time: old_batch_time, updated_at: old_batch_time, ..batch1.clone() };
    repo.save_test_batch(&old_batch).await.unwrap();
    
    let deleted_batches = repo.delete_old_test_batches(Utc::now() - Duration::days(90)).await.unwrap();
    assert_eq!(deleted_batches, 1);
    assert!(repo.get_test_batch_by_id(&old_batch_id).await.unwrap().is_none());

    // TODO: 更多QueryCriteria的测试
}

#[tokio::test]
async fn test_memory_persistent_repository() {
    persistent_repository_test_suite(|| Box::new(MemoryPersistentRepository::new())).await;
}

#[tokio::test]
async fn test_sqlite_persistent_repository() {
    // 使用内存SQLite进行测试，避免文件残留
    let db_url = "sqlite::memory:"; 
    // 或者使用临时文件: let temp_dir = tempfile::tempdir().unwrap(); let db_path = temp_dir.path().join("test_persist.db"); let db_url = format!("sqlite:{}", db_path.to_str().unwrap());
    
    let repo = SqlitePersistentRepository::new(&db_url).await.expect("Failed to create SQLite repo");
    persistent_repository_test_suite(|| Box::new(repo)).await; // `repo` needs to be cloneable or re-created
    // For non-memory DBs, ensure cleanup: // drop(temp_dir);
}

// 为 SqlitePersistentRepository 添加 Cloneable 包装或修改测试套件以接受 Future<Output = Repo>
struct TestSqliteRepoBuilder {
    db_url: String,
}
impl TestSqliteRepoBuilder {
    async fn build(&self) -> Box<dyn IPersistentRepository> {
        Box::new(SqlitePersistentRepository::new(&self.db_url).await.unwrap())
    }
}
#[tokio::test]
async fn test_sqlite_persistent_repository_v2() {
    let db_url = "sqlite::memory:".to_string();
    let builder = TestSqliteRepoBuilder { db_url };
    persistent_repository_test_suite(|| {
        // This is tricky because the builder is async and the closure is not.
        // A simpler way for tests is to just create it directly.
        // For now, the original test_sqlite_persistent_repository is okay if repo is created inside.
        // The test suite function itself needs to handle the creation.
        let repo = futures::executor::block_on(SqlitePersistentRepository::new("sqlite::memory:")).unwrap();
        Box::new(repo)
    }).await;
}


```

#### ✅ 预期结果/完成标准 (步骤 1.4)
1.  `IPersistentRepository` 接口、`PersistedTestRecord` 和 `PersistedTestBatch` 结构体定义完成。
2.  `SqlitePersistentRepository` 实现完成，能够使用 `sqlx` 与SQLite数据库进行交互，完成CRUD操作。
3.  `MemoryPersistentRepository` 实现完成，提供内存中的持久化模拟。
4.  SQLite数据库表结构设计完毕，并通过 `initialize_schema` 方法在 `SqlitePersistentRepository` 中实现自动创建。
5.  JSON序列化/反序列化 `sub_test_results_json` 字段工作正常。
6.  单元测试覆盖 `SqlitePersistentRepository` 和 `MemoryPersistentRepository` 的核心功能，包括数据保存、读取、查询和更新。
7.  代码符合项目规范。

---
### 步骤 1.5: Repository 集成与配置服务

#### 🎯 目标
1.  将新创建的 Repository（`IConfigurationRepository`, `IRuntimeRepository`, `IPersistentRepository`）集成到应用的状态管理或Tauri的 `AppState` 中，以便在整个应用中通过依赖注入访问。
2.  创建一个简单的配置服务（如果尚未存在），用于加载和管理应用级配置（例如数据库路径、日志级别等），这些配置可能存储在文件中（如 `config.toml`）。

#### 📝 具体实施

##### 1.5.1 更新 `AppState` (Tauri) 或服务构造函数
在 `src-tauri/src/main.rs` 或 `src-tauri/src/lib.rs` (取决于您的项目结构)，修改 `AppState` 或用于构建服务的结构体，以包含对新Repository实例的引用 (`Arc<dyn Trait>`)。

```rust
// 在 src-tauri/src/lib.rs 或 main.rs 中的 AppState (示例)
use std::sync::Arc;
use crate::services::persistence::repositories::{
    configuration_repository::{IConfigurationRepository, MemoryConfigurationRepository}, // 使用具体实现
    runtime_repository::{IRuntimeRepository, MemoryRuntimeRepository},
    persistent_repository::{IPersistentRepository, SqlitePersistentRepository, MemoryPersistentRepository}, // 根据环境选择
};
// ... 其他 use 语句 ...

pub struct AppState {
    pub config_repo: Arc<dyn IConfigurationRepository>,
    pub runtime_repo: Arc<dyn IRuntimeRepository>,
    pub persistent_repo: Arc<dyn IPersistentRepository>,
    // ... 其他服务 ...
}

impl AppState {
    pub async fn new() -> Result<Self, AppError> { // AppError 应包含初始化错误
        // 配置Repository (通常是内存实现)
        let config_repo = Arc::new(MemoryConfigurationRepository::new());
        // config_repo._populate_test_data().await; // 可选：填充初始测试数据

        // 运行时Repository (总是内存实现)
        let runtime_repo = Arc::new(MemoryRuntimeRepository::new());

        // 持久化Repository (SQLite实现)
        // 数据库路径应来自配置服务
        let db_path = std::env::var("APP_DB_PATH").unwrap_or_else(|_| "fat_test_storage.db".to_string());
        log::info!("数据库路径: {}", db_path);
        let persistent_repo = Arc::new(
            SqlitePersistentRepository::new(&format!("sqlite:{}?mode=rwc", db_path)).await?
        );
        // 或者在测试/开发环境中使用内存版
        // let persistent_repo = Arc::new(MemoryPersistentRepository::new());
        // persistent_repo.initialize_schema().await?; // 确保Memory版也有此方法(虽然是空操作)

        Ok(Self {
            config_repo,
            runtime_repo,
            persistent_repo,
            // ... 初始化其他服务 ...
        })
    }
}

// 在 Tauri setup 钩子中:
// .manage(AppState::new().await.expect("Failed to create AppState"))
```

##### 1.5.2 创建应用配置服务 (如果需要)
如果应用的配置（如数据库文件路径）需要从文件加载，可以创建一个简单的服务。

```rust
// src/services/app_config_service.rs
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use crate::utils::error::AppError;

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AppConfig {
    pub database_url: String, // 例如 "sqlite:fat_test_data.db"
    pub log_level: String,    // 例如 "info", "debug"
    pub max_concurrent_tests: usize,
    // ... 其他配置 ...
}

impl Default for AppConfig {
    fn default() -> Self {
        Self {
            database_url: "sqlite:./fat_test_app_data.sqlite".to_string(),
            log_level: "info".to_string(),
            max_concurrent_tests: 4,
        }
    }
}

pub fn load_config(config_path: Option<&str>) -> Result<AppConfig, AppError> {
    let path_str = config_path.unwrap_or("config.toml");
    let config_file_path = PathBuf::from(path_str);

    if !config_file_path.exists() {
        log::warn!("配置文件 {} 不存在, 将创建并使用默认配置。", path_str);
        let default_config = AppConfig::default();
        let toml_string = toml::to_string_pretty(&default_config)
            .map_err(|e| AppError::ConfigError(format!("序列化默认配置失败: {}", e)))?;
        std::fs::write(&config_file_path, toml_string)
            .map_err(|e| AppError::ConfigError(format!("写入默认配置文件失败: {}", e)))?;
        return Ok(default_config);
    }

    let config_content = std::fs::read_to_string(config_file_path)
        .map_err(|e| AppError::ConfigError(format!("读取配置文件失败: {}", e)))?;
    
    toml::from_str(&config_content)
        .map_err(|e| AppError::ConfigError(format!("解析配置文件失败: {}", e)))
}
```
**注意**: `AppError` 需要有 `ConfigError(String)` 变体。日志记录 (`log::warn`, `log::info`) 需要 `log` crate。

#### 🧪 测试方案 (步骤 1.5)
1.  **AppState 初始化测试**: 编写测试以确保 `AppState` 能够成功初始化所有Repository（包括处理数据库连接错误）。
2.  **配置加载测试**: 测试 `load_config` 函数能否正确加载配置文件，以及在文件不存在时能否创建默认配置。
3.  **依赖注入测试**: 在Tauri命令或服务的单元测试中，验证是否能从 `tauri::State<AppState>` 正确获取并使用Repository实例。

```rust
#[cfg(test)]
mod app_state_tests {
    use super::*; // 假设 AppState 和 AppError 在当前模块或父模块
    use crate::services::persistence::repositories::app_config_service; // 引入配置服务

    #[tokio::test]
    async fn test_app_state_creation() {
        // 为了测试，可能需要设置环境变量或使用临时配置文件路径
        // std::env::set_var("APP_DB_PATH", "test_app_state.db");
        // let _ = std::fs::remove_file("test_app_state.db"); // 清理旧文件
        
        // 使用配置服务加载配置
        let app_config = app_config_service::load_config(Some("test_config.toml")).unwrap_or_default();
        // 这里需要一种方法将 app_config.database_url 传递给 AppState::new()
        // 或者 AppState::new() 内部调用 load_config()
        // 为了简单，假设 AppState::new() 能处理好配置
        
        let app_state_result = AppState::new().await; // 假设 AppState::new 使用默认或可配置的DB路径
        assert!(app_state_result.is_ok(), "AppState创建失败: {:?}", app_state_result.err());
        
        let app_state = app_state_result.unwrap();
        // 简单验证repository是否被初始化 (不能是None)
        // 此处不能直接访问 Arc<dyn Trait> 的具体类型，但可以调用其方法
        let cfgs = app_state.config_repo.list_all_channel_definitions().await;
        assert!(cfgs.is_ok());

        // 清理测试数据库文件
        // let _ = std::fs::remove_file("test_app_state.db");
        let _ = std::fs::remove_file("test_config.toml"); // 清理测试配置文件
    }
}

#[cfg(test)]
mod app_config_service_tests {
    use super::app_config_service::*; // 假设在同一模块或通过super访问

    #[test]
    fn test_load_default_config_if_not_exists() {
        let test_cfg_path = "temp_test_config.toml";
        let _ = std::fs::remove_file(test_cfg_path); //确保文件不存在

        let config_result = load_config(Some(test_cfg_path));
        assert!(config_result.is_ok());
        let config = config_result.unwrap();
        assert_eq!(config.log_level, "info"); // 检查默认值

        assert!(PathBuf::from(test_cfg_path).exists(), "默认配置文件应已创建");
        let _ = std::fs::remove_file(test_cfg_path); //清理
    }

    #[test]
    fn test_load_existing_config() {
        let test_cfg_path = "temp_existing_config.toml";
        let test_content = r#"
            database_url = "sqlite:./my_custom_data.db"
            log_level = "debug"
            max_concurrent_tests = 8
        "#;
        std::fs::write(test_cfg_path, test_content).unwrap();

        let config_result = load_config(Some(test_cfg_path));
        assert!(config_result.is_ok());
        let config = config_result.unwrap();
        assert_eq!(config.database_url, "sqlite:./my_custom_data.db");
        assert_eq!(config.log_level, "debug");
        assert_eq!(config.max_concurrent_tests, 8);
        
        let _ = std::fs::remove_file(test_cfg_path); //清理
    }
}
```

#### ✅ 预期结果/完成标准 (步骤 1.5)
1.  `AppState` (或同等结构) 成功初始化并管理所有Repository的实例。
2.  `AppConfig` 及 `load_config` 函数 (或类似机制) 能够正确加载应用配置，特别是数据库路径。
3.  Tauri命令或应用服务能够通过依赖注入正确获取和使用Repository实例。
4.  相关的单元测试通过。

**Phase 1 完成标准总结**
*   所有Repository接口 (`IConfigurationRepository`, `IRuntimeRepository`, `IPersistentRepository`) 及其内存实现和SQLite实现（针对`IPersistentRepository`）均已完成。
*   Excel导入导出功能已规划或初步实现。
*   所有Repository都经过了充分的单元测试，包括CRUD操作、查询、批量操作和边界条件。
*   Repository实例已成功集成到应用的主状态管理 (`AppState`) 中。
*   应用级配置（如数据库路径）可以通过配置文件加载。
*   整个数据访问层与业务逻辑解耦，提高了模块化和可测试性。

---

## 🚀 Phase 2: 状态管理器重构 (State Management)

### 📌 重构原因 (Phase 2)
`ChannelTestInstance` 的状态转换是系统的核心业务逻辑之一。如果状态管理不严格，可能导致数据不一致、业务流程错误或难以追踪问题。当前可能存在：
*   状态变更逻辑分散。
*   缺乏统一的状态转换规则校验。
*   状态变更事件通知不完善。

重构状态管理器 (`ChannelStateManager`) 的目标是：
*   **集中控制**: 实现 `FAT-CSM-001`，`ChannelStateManager` 是唯一允许修改 `ChannelTestInstance` 状态的组件。
*   **规则强制**: 实现 `FAT-CSM-002`，所有状态转换必须符合预定义的业务逻辑规则，并记录时间戳。
*   **事件驱动**: 实现 `FAT-EVT-001`，重要状态变更必须发布事件给系统其他部分（如前端UI更新）。
*   **解耦和可测试性**: 使状态管理逻辑独立、清晰且易于测试。

### 步骤 2.1: 创建增强的状态管理器接口和实现

#### 🎯 目标
设计 `IChannelStateManager` 接口，并实现 `EnhancedChannelStateManager`，该实现将依赖 `IRuntimeRepository` 来获取和更新 `ChannelTestInstance` 的实时状态。它将包含严格的状态转换逻辑和事件发布机制。

#### 📝 具体实施

##### 2.1.1 定义状态管理器核心接口 (`IChannelStateManager`) 和辅助结构
```rust
// src/services/state_management/channel_state_manager.rs
// 或者 src/state_manager/mod.rs (根据您的项目结构调整)
use async_trait::async_trait;
use crate::models::runtime::{ChannelTestInstance, TestOutcome, ChannelRuntimeState, TestPhase, ErrorInfo, TimestampCollection, ProgressInfo}; // 从models::runtime引入
use crate::models::enums::{OverallTestStatus, SubTestItem, TestResult}; // 从models::enums引入
use crate::utils::error::AppError; // 使用项目统一的 AppError
use crate::services::persistence::repositories::runtime_repository::IRuntimeRepository; // 依赖运行时仓库
use std::sync::Arc;
use tokio::sync::broadcast; // 用于事件发布
use chrono::{DateTime, Utc};
use std::collections::HashMap;
use serde::{Serialize, Deserialize}; // 用于事件等

/// 状态转换记录 (主要用于内存中的运行时历史，持久化的最终状态在PersistedTestRecord)
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct StateTransition {
    pub transition_id: String, // 唯一ID
    pub instance_id: String,
    pub old_status: OverallTestStatus,
    pub new_status: OverallTestStatus,
    pub reason: String, // 转换原因，例如 "测试结果应用: HardPoint" 或 "用户强制操作"
    pub timestamp: DateTime<Utc>,
    // pub operator_info: Option<String>, // 操作者信息，根据您的决定，此处简化，不持久化操作者
}

/// 状态变更事件 (用于广播通知)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StateChangeEvent {
    pub instance_id: String,
    pub old_status: OverallTestStatus,
    pub new_status: OverallTestStatus,
    pub transition_reason: String,
    pub timestamp: DateTime<Utc>,
    // pub operator_info: Option<String>, // 同上，简化
    // 可以包含部分更新后的 ChannelTestInstance 数据，如果前端需要
    pub updated_instance_summary: Option<PartialChannelTestInstanceUpdate>,
}

/// 用于事件的部分实例更新数据 (按需定义)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PartialChannelTestInstanceUpdate {
    pub overall_status: OverallTestStatus,
    pub error_message: Option<String>,
    pub last_updated_time: DateTime<Utc>,
    // ... 其他前端可能直接需要的字段 ...
}


/// 状态管理器接口
#[async_trait]
pub trait IChannelStateManager: Send + Sync {
    /// 获取指定实例的当前运行时状态摘要
    async fn get_current_runtime_state(&self, instance_id: &str) -> Result<ChannelRuntimeState, AppError>;

    /// 检查是否可以从当前状态转换到目标状态 (不执行转换)
    async fn can_transition_to(&self, instance_id: &str, target_status: OverallTestStatus) -> Result<bool, AppError>;

    /// 获取指定实例的运行时状态转换历史 (内存中的短期历史)
    async fn get_runtime_transition_history(&self, instance_id: &str) -> Result<Vec<StateTransition>, AppError>;

    /// 应用测试结果并相应地转换状态 (主要的状态变更入口)
    /// 这是符合 FAT-CSM-001 的核心方法
    async fn apply_raw_outcome(&self, instance_id: &str, outcome: &TestOutcome) -> Result<StateTransition, AppError>;

    /// 强制将实例转换到目标状态 (应谨慎使用，例如管理员操作)
    async fn force_state_transition(&self, instance_id: &str, target_status: OverallTestStatus, reason: String /*, operator_info: Option<String> */) -> Result<StateTransition, AppError>;
    
    /// 重置实例状态以便重新测试
    async fn reset_instance_for_retest(&self, instance_id: &str /*, operator_info: Option<String> */) -> Result<StateTransition, AppError>;

    // 批量状态操作 (可选，根据需求)
    // async fn batch_apply_outcomes(&self, outcomes: Vec<(String, TestOutcome)>) -> Result<Vec<StateTransition>, AppError>;
    // async fn batch_reset_for_retest(&self, instance_ids: &[String]) -> Result<Vec<StateTransition>, AppError>;

    /// 订阅所有实例的状态变更事件
    fn subscribe_to_all_state_changes(&self) -> broadcast::Receiver<StateChangeEvent>;
    
    /// 订阅特定实例的状态变更事件
    /// (P2.1.2 细化)
    async fn subscribe_to_instance_state_changes(&self, instance_id: &str) -> Result<broadcast::Receiver<StateChangeEvent>, AppError>;
}
```

##### 2.1.2 定义状态转换规则 (`StateTransitionRules`)
```rust
// src/services/state_management/state_transition_rules.rs
// 或者在 channel_state_manager.rs 内部定义
use crate::models::enums::OverallTestStatus;
use std::collections::HashMap;

#[derive(Debug)]
pub struct StateTransitionRules {
    // 定义从一个状态可以合法转换到的状态列表
    allowed_transitions: HashMap<OverallTestStatus, Vec<OverallTestStatus>>,
}

impl StateTransitionRules {
    pub fn new() -> Self {
        let mut rules = HashMap::new();
        // 根据 FAT_TEST 项目的业务逻辑定义规则
        // 示例规则 (请根据您的实际需求调整，mainrules 中定义的 OverallTestStatus 较简单)
        // 假设 OverallTestStatus 有更多状态如: NotTested, WiringConfirmed, HardPointTesting, SubTesting, ManualTesting, TestCompletedPassed, TestCompletedFailed, Skipped
        rules.insert(OverallTestStatus::NotTested, vec![
            OverallTestStatus::WiringConfirmed, // 例如，如果有点表导入后的接线确认步骤
            OverallTestStatus::HardPointTesting, // 直接开始硬点测试
            OverallTestStatus::Skipped,          // 用户选择跳过
            OverallTestStatus::ManualTesting,    // 直接进入手动测试
        ]);
        rules.insert(OverallTestStatus::WiringConfirmed, vec![
            OverallTestStatus::HardPointTesting,
            OverallTestStatus::Skipped,
            OverallTestStatus::NotTested, // 允许返回
        ]);
        rules.insert(OverallTestStatus::HardPointTesting, vec![ // 硬点测试中或硬点测试完成，准备进入下一阶段
            OverallTestStatus::SubTesting,       // 进入子项测试 (如报警测试)
            OverallTestStatus::ManualTesting,    // 进入手动测试
            OverallTestStatus::TestCompletedPassed, // 如果硬点是最后一个测试且通过
            OverallTestStatus::TestCompletedFailed, // 硬点测试失败
            OverallTestStatus::NotTested,        // 重置/重测
            OverallTestStatus::Skipped,          // 当前测试被跳过
        ]);
        rules.insert(OverallTestStatus::SubTesting, vec![ // 子项（如报警）测试中
            OverallTestStatus::SubTesting,       // 另一个子项测试
            OverallTestStatus::ManualTesting,
            OverallTestStatus::TestCompletedPassed,
            OverallTestStatus::TestCompletedFailed,
            OverallTestStatus::NotTested,
            OverallTestStatus::Skipped,
        ]);
        rules.insert(OverallTestStatus::ManualTesting, vec![
            OverallTestStatus::TestCompletedPassed,
            OverallTestStatus::TestCompletedFailed,
            OverallTestStatus::NotTested,
        ]);
        rules.insert(OverallTestStatus::TestCompletedPassed, vec![
            OverallTestStatus::NotTested, // 允许重测
        ]);
        rules.insert(OverallTestStatus::TestCompletedFailed, vec![
            OverallTestStatus::NotTested, // 允许重测或修复后重测
            OverallTestStatus::ManualTesting, // 可能需要手动干预
        ]);
        rules.insert(OverallTestStatus::Skipped, vec![
            OverallTestStatus::NotTested, // 允许重测
            OverallTestStatus::HardPointTesting, // 从跳过状态重新开始测试
        ]);
        
        // 确保所有 OverallTestStatus 都作为key存在，即使它不能转换到任何其他状态 (value是空vec)
        // 例如：如果有一个终态 ErrorRecoveryPending，它可能不允许自动转换出去
        Self { allowed_transitions: rules }
    }

    pub fn is_valid(&self, from: OverallTestStatus, to: OverallTestStatus) -> bool {
        if from == to { // 通常允许停留在当前状态，或者某些操作后状态不变
            return true; 
        }
        self.allowed_transitions.get(&from).map_or(false, |allowed_next_states| {
            allowed_next_states.contains(&to)
        })
    }
}
```

##### 2.1.3 实现增强的状态管理器 (`EnhancedChannelStateManager`)
```rust
// 在 channel_state_manager.rs (续)
use uuid::Uuid;
use tokio::sync::Mutex; // 用于过滤的订阅者列表
use crate::services::state_management::state_transition_rules::StateTransitionRules; // 引入规则

const DEFAULT_EVENT_CHANNEL_CAPACITY: usize = 100;

pub struct EnhancedChannelStateManager {
    runtime_repo: Arc<dyn IRuntimeRepository>,
    // persistent_repo: Arc<dyn IPersistentRepository>, // 状态管理器不直接写持久层，那是应用服务或任务执行器的职责
    
    // 运行时状态转换历史 (内存中，每个实例一个列表)
    // Phase2中的第三个问题：当用户导入点表并开始测试的时候后续所有的操作都应该只操作同一个测试对象的实例集合体，
    // 所以内存增加的问题应该不会出现。对应的在各个节点将集合体进行入库和更新即可
    // 这个历史是运行时的，用于短期追溯或UI展示；长期的、最终的测试记录由 PersistedTestRecord 存储。
    runtime_histories: Arc<RwLock<HashMap<String, Vec<StateTransition>>>>,
    
    event_broadcaster: broadcast::Sender<StateChangeEvent>,
    transition_rules: Arc<StateTransitionRules>,

    // 用于特定实例事件订阅的过滤 (P2.1.2 细化)
    // 使用Mutex保护内部的 specific_instance_broadcasters，因为 broadcast::Sender 本身不是 Sync
    // 或者，更简单的方式是让订阅者自行过滤，但接口要求我们提供过滤后的。
    // 下面的方法是为每个被订阅的 instance_id 创建一个新的 broadcast channel，然后转发。
    // 这是一个可选的高级实现，如果简单实现（订阅者自行过滤）可接受，可以简化。
    // 为了性能和简化，通常让订阅者自行过滤更佳。但我们按接口要求尝试实现过滤广播。
    // 注意：为每个 instance_id 创建独立的 broadcaster 可能导致 broadcaster 数量过多。
    // 一个折中方案是，`subscribe_to_instance_state_changes` 返回一个包装了主 `Receiver` 的流，该流进行过滤。
    // 这里，我们先实现一个简单的基于主 broadcaster 的过滤流。
}

impl EnhancedChannelStateManager {
    pub fn new(runtime_repo: Arc<dyn IRuntimeRepository>) -> Self {
        let (event_broadcaster, _) = broadcast::channel(DEFAULT_EVENT_CHANNEL_CAPACITY);
        Self {
            runtime_repo,
            runtime_histories: Arc::new(RwLock::new(HashMap::new())),
            event_broadcaster,
            transition_rules: Arc::new(StateTransitionRules::new()),
        }
    }

    async fn record_and_publish_transition(
        &self, 
        instance: &ChannelTestInstance, // 传入更新后的实例用于获取部分信息
        old_status: OverallTestStatus, 
        new_status: OverallTestStatus, 
        reason: String
    ) -> Result<StateTransition, AppError> {
        let transition = StateTransition {
            transition_id: Uuid::new_v4().to_string(),
            instance_id: instance.instance_id.clone(),
            old_status,
            new_status,
            reason: reason.clone(),
            timestamp: Utc::now(),
        };

        // 记录运行时历史
        let mut histories = self.runtime_histories.write().await;
        histories.entry(instance.instance_id.clone()).or_default().push(transition.clone());

        // 发布事件
        // Phase2中的第二个问题：状态审计应该是不太需要。 operator_info 移除
        let event = StateChangeEvent {
            instance_id: instance.instance_id.clone(),
            old_status,
            new_status,
            transition_reason: reason,
            timestamp: transition.timestamp,
            updated_instance_summary: Some(PartialChannelTestInstanceUpdate { // 填充部分更新
                overall_status: new_status,
                error_message: instance.error_message.clone(),
                last_updated_time: instance.last_updated_time,
            })
        };
        
        if self.event_broadcaster.send(event).is_err() {
            log::warn!("状态变更事件发布失败 (instance_id: {}): 无订阅者或通道已满。", instance.instance_id);
            // 不应因事件发布失败而中断核心逻辑
        }
        Ok(transition)
    }
}

#[async_trait]
impl IChannelStateManager for EnhancedChannelStateManager {
    async fn get_current_runtime_state(&self, instance_id: &str) -> Result<ChannelRuntimeState, AppError> {
        let instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        
        // 此处应从 ChannelTestInstance 转换为 ChannelRuntimeState
        // 假设 ChannelRuntimeState 的字段可以从 ChannelTestInstance 计算或映射得到
        Ok(ChannelRuntimeState {
            instance_id: instance.instance_id.clone(),
            definition_id: instance.definition_id.clone(),
            test_batch_id: instance.test_batch_id.clone(),
            overall_status: instance.overall_status,
            current_phase: TestPhase::from_status(instance.overall_status), // 假设有此转换逻辑
            error_info: instance.error_message.map(ErrorInfo::new),
            timestamps: TimestampCollection::from_instance(&instance), // 假设有此转换逻辑
            progress_info: ProgressInfo::calculate(&instance), // 假设有此转换逻辑
            sub_test_results: instance.sub_test_results.clone(),
            // ... 其他所需字段
        })
    }

    async fn can_transition_to(&self, instance_id: &str, target_status: OverallTestStatus) -> Result<bool, AppError> {
        let instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        Ok(self.transition_rules.is_valid(instance.overall_status, target_status))
    }

    async fn get_runtime_transition_history(&self, instance_id: &str) -> Result<Vec<StateTransition>, AppError> {
        let histories = self.runtime_histories.read().await;
        Ok(histories.get(instance_id).cloned().unwrap_or_default())
    }

    async fn apply_raw_outcome(&self, instance_id: &str, outcome: &TestOutcome) -> Result<StateTransition, AppError> {
        let mut instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        let new_status: OverallTestStatus;

        // 核心状态决定逻辑 (基于 FAT_TEST重构优化方案.md 中的状态图或您的具体业务)
        match outcome.result {
            TestResult::Passed => {
                // 根据当前测试项和整体流程决定下一个状态
                // 例如，如果当前是HardPoint且通过，可能进入SubTesting或ManualTesting或直接CompletedPassed
                // 需要更详细的业务规则来精确定义
                match outcome.test_item {
                    SubTestItem::HardPoint => new_status = OverallTestStatus::HardPointTesting, // 或者 WiringConfirmed -> HardPointTesting
                    // SubTestItem::LowAlarm | SubTestItem::HighAlarm => {
                    //     // 检查是否所有子测试都已完成
                    //     // if all_subtests_done_for_current_phase(&instance, outcome.test_item) {
                    //     //    new_status = OverallTestStatus::TestCompletedPassed; // 或进入下一阶段
                    //     // } else {
                    //     //    new_status = OverallTestStatus::SubTesting; // 继续测其他子项
                    //     // }
                    // }
                    _ => new_status = OverallTestStatus::TestCompletedPassed, // 简化：假设其他通过则直接完成
                }
                // 如果上面设置为 HardPointTesting，这里可能需要根据具体流程图再次判断
                // 例如，若硬点测试后没有其他自动测试，则可能是 TestCompletedPassed
                // 此处逻辑需要非常精确地映射您的状态图
                if new_status == OverallTestStatus::HardPointTesting && !self.transition_rules.is_valid(old_status, new_status) {
                    // 尝试一个更合理的默认 "通过" 状态
                    new_status = OverallTestStatus::TestCompletedPassed;
                }
            }
            TestResult::Failed => {
                new_status = OverallTestStatus::TestCompletedFailed;
            }
            TestResult::Skipped => {
                new_status = OverallTestStatus::Skipped;
            }
            TestResult::InProgress => {
                // 根据当前测试项决定进行中的状态
                match outcome.test_item {
                    SubTestItem::HardPoint => new_status = OverallTestStatus::HardPointTesting,
                    // SubTestItem::LowAlarm | SubTestItem::HighAlarm => new_status = OverallTestStatus::SubTesting,
                    _ => new_status = OverallTestStatus::ManualTesting, // 默认其他进行中转为手动
                }
            }
        }

        if !self.transition_rules.is_valid(old_status, new_status) {
            return Err(AppError::StateTransitionError(format!(
                "从 {:?} 到 {:?} 的状态转换不允许 (测试项: {:?}, 结果: {:?})", 
                old_status, new_status, outcome.test_item, outcome.result
            )));
        }

        // 更新实例
        instance.overall_status = new_status;
        instance.last_updated_time = Utc::now();
        instance.error_message = outcome.error_message.clone(); // 保存错误信息
        
        // 更新或添加子测试结果 (确保 SubTestExecutionResult 与 TestOutcome 字段匹配)
        instance.sub_test_results.insert(outcome.test_item, SubTestExecutionResult {
            result: outcome.result,
            measured_value: outcome.measured_value,
            expected_value: outcome.expected_value,
            tolerance: outcome.tolerance,
            timestamp: Utc::now(),
            error_message: outcome.error_message.clone(),
            duration_ms: outcome.duration_ms,
        });
        if outcome.result == TestResult::Passed && instance.start_time.is_none() && new_status != OverallTestStatus::NotTested {
             instance.start_time = Some(Utc::now()); // 首次有效操作时记录开始时间
        }
        if new_status == OverallTestStatus::TestCompletedPassed || new_status == OverallTestStatus::TestCompletedFailed {
            instance.final_test_time = Some(Utc::now());
            if let Some(start) = instance.start_time {
                instance.total_test_duration_ms = Some((Utc::now() - start).num_milliseconds());
            }
        }


        self.runtime_repo.update_channel_instance(&instance).await?;
        
        self.record_and_publish_transition(&instance, old_status, new_status, 
            format!("测试结果应用: {:?} ({:?})", outcome.test_item, outcome.result)
        ).await
    }

    async fn force_state_transition(&self, instance_id: &str, target_status: OverallTestStatus, reason: String) -> Result<StateTransition, AppError> {
        let mut instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        // 对于强制转换，我们仍然可以检查规则，但通常是绕过它或有一套特殊的“强制”规则
        // log::warn!("强制状态转换: {} 从 {:?} 到 {:?}，原因: {}", instance_id, old_status, target_status, reason);

        instance.overall_status = target_status;
        instance.last_updated_time = Utc::now();
        instance.error_message = Some(format!("强制状态转换: {}", reason)); // 记录原因

        self.runtime_repo.update_channel_instance(&instance).await?;
        self.record_and_publish_transition(&instance, old_status, target_status, reason).await
    }
    
    async fn reset_instance_for_retest(&self, instance_id: &str) -> Result<StateTransition, AppError> {
        let mut instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;

        let old_status = instance.overall_status;
        let target_status = OverallTestStatus::NotTested; // 重置目标状态

        if !self.transition_rules.is_valid(old_status, target_status) && old_status != target_status { // 如果已经是NotTested则无需报错
             log::warn!("尝试从 {:?} 重置到 {:?}，规则上可能不允许，但将继续执行重置逻辑。", old_status, target_status);
        }

        instance.overall_status = target_status;
        instance.current_step_details = None;
        instance.error_message = None;
        instance.start_time = None;
        instance.final_test_time = None;
        instance.total_test_duration_ms = None;
        instance.sub_test_results.clear();
        instance.hardpoint_readings = None;
        instance.manual_test_current_value_input = None;
        instance.manual_test_current_value_output = None;
        instance.last_updated_time = Utc::now();

        self.runtime_repo.update_channel_instance(&instance).await?;
        self.record_and_publish_transition(&instance, old_status, target_status, "重置以进行重测".to_string()).await
    }

    fn subscribe_to_all_state_changes(&self) -> broadcast::Receiver<StateChangeEvent> {
        self.event_broadcaster.subscribe()
    }
    
    // P2.1.2 细化: 订阅特定实例事件
    // 实现方式1：返回一个过滤流 (推荐，更高效，避免管理多个broadcaster)
    async fn subscribe_to_instance_state_changes(&self, instance_id: &str) -> Result<broadcast::Receiver<StateChangeEvent>, AppError> {
        // 注意：broadcast::Receiver 本身不能直接被过滤然后返回一个新的 Receiver。
        // 调用者获取主 Receiver 后，需要自行使用如 `tokio_stream::StreamExt::filter` 来处理。
        // 为了符合接口签名并“提供”过滤，一个方法是创建一个新的 channel，并在一个任务中从主 channel 接收、过滤、转发。
        // 但这会为每个订阅者创建一个任务和 channel，开销较大。
        
        // 简化和推荐的做法是：调用者获取主 Receiver，然后自己过滤。
        // 如果接口设计强制要求服务进行过滤并返回一个“已过滤”的 Receiver，那么实现会复杂很多。
        // 这里我们返回主 Receiver，并在文档/注释中说明调用者需要过滤。
        // 或者，我们可以返回一个包装类型，它内部持有 Receiver 并实现 Stream trait 进行过滤。
        
        // **最简单的符合接口签名的方式（但不是最高效的，也不是真正的独立过滤channel）：**
        // 返回主广播器的订阅者，并明确告知调用方需要自行过滤。
        // 如果确实需要服务端过滤，应该修改接口返回类型为类似 `impl Stream<Item = StateChangeEvent>`
        log::debug!("为实例 {} 创建状态变更订阅 (订阅者需自行过滤)", instance_id);
        Ok(self.event_broadcaster.subscribe())
        // 要实现真正的过滤后 Receiver，需要更复杂的机制，如为每个 instance_id 维护一个 mpsc::channel，
        // 然后有一个后台任务监听主 broadcast，并向匹配的 mpsc::channel 发送。
        // 这超出了当前步骤的典型实现复杂度。
        // 最符合当前 Rust生态的做法是让调用者使用 Stream API 进行过滤。
    }
}
```

#### 🧪 测试方案 (步骤 2.1)
```rust
// src/services/state_management/tests/enhanced_channel_state_manager_tests.rs
// 或者 src/state_manager/tests.rs
use crate::services::state_management::channel_state_manager::*;
use crate::services::persistence::repositories::runtime_repository::{MemoryRuntimeRepository, IRuntimeRepository};
use crate::models::runtime::{ChannelTestInstance, TestOutcome};
use crate::models::enums::{OverallTestStatus, SubTestItem, TestResult};
use std::sync::Arc;
use tokio;
use uuid::Uuid;
use chrono::Utc;

async fn setup_manager_and_instance(initial_status: OverallTestStatus) -> (Arc<EnhancedChannelStateManager>, String) {
    let runtime_repo = Arc::new(MemoryRuntimeRepository::new());
    let manager = Arc::new(EnhancedChannelStateManager::new(runtime_repo.clone()));
    
    let instance_id = Uuid::new_v4().to_string();
    let instance = ChannelTestInstance {
        instance_id: instance_id.clone(),
        definition_id: Uuid::new_v4().to_string(),
        test_batch_id: "batch_sm_test".to_string(),
        overall_status: initial_status,
        last_updated_time: Utc::now(),
        // ... 其他字段初始化 ...
        current_step_details: None, error_message: None, start_time: None, final_test_time: None,
        total_test_duration_ms: None, sub_test_results: HashMap::new(), hardpoint_readings: None,
        manual_test_current_value_input: None, manual_test_current_value_output: None,
    };
    runtime_repo.save_channel_instance(&instance).await.unwrap();
    (manager, instance_id)
}

#[tokio::test]
async fn test_sm_initial_state_and_valid_transition() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;

    let state = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state.overall_status, OverallTestStatus::NotTested);

    let can_transition = manager.can_transition_to(&instance_id, OverallTestStatus::HardPointTesting).await.unwrap();
    assert!(can_transition, "Should be able to transition from NotTested to HardPointTesting");
    
    let cannot_transition = manager.can_transition_to(&instance_id, OverallTestStatus::TestCompletedPassed).await.unwrap();
    assert!(!cannot_transition, "Should not be able to directly transition from NotTested to TestCompletedPassed without intermediate steps");
}

#[tokio::test]
async fn test_sm_apply_outcome_passed() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    let outcome = TestOutcome {
        test_item: SubTestItem::HardPoint,
        result: TestResult::Passed,
        // ... 其他 outcome 字段 ...
        measured_value: None, expected_value: None, tolerance: None, duration_ms: None, error_message: None,
    };

    let transition = manager.apply_raw_outcome(&instance_id, &outcome).await.unwrap();
    // 基于StateTransitionRules，从NotTested通过HardPoint测试，可能进入HardPointTesting或TestCompletedPassed
    // 此处假设进入 HardPointTesting (表示硬点测试这个阶段已通过，但可能还有后续)
    // 如果规则是从NotTested通过HardPoint直接到TestCompletedPassed，则修改期望值
    assert_eq!(transition.new_status, OverallTestStatus::HardPointTesting); 

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::HardPointTesting);
    assert!(state_after.sub_test_results.contains_key(&SubTestItem::HardPoint));
}

#[tokio::test]
async fn test_sm_apply_outcome_failed() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::HardPointTesting).await;
    let outcome = TestOutcome {
        test_item: SubTestItem::HardPoint, // 假设是硬点测试失败
        result: TestResult::Failed,
        error_message: Some("Sensor reading out of range".to_string()),
        // ...
        measured_value: None, expected_value: None, tolerance: None, duration_ms: None,
    };

    let transition = manager.apply_raw_outcome(&instance_id, &outcome).await.unwrap();
    assert_eq!(transition.new_status, OverallTestStatus::TestCompletedFailed);

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::TestCompletedFailed);
    assert_eq!(state_after.error_info.unwrap().message, "Sensor reading out of range");
}


#[tokio::test]
async fn test_sm_invalid_transition_via_apply_outcome() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::TestCompletedPassed).await;
     let outcome = TestOutcome { // 尝试从未允许的状态转换
        test_item: SubTestItem::HardPoint,
        result: TestResult::InProgress, // TestCompletedPassed -> HardPointTesting (InProgress) 通常不允许
        measured_value: None, expected_value: None, tolerance: None, duration_ms: None, error_message: None,
    };
    let result = manager.apply_raw_outcome(&instance_id, &outcome).await;
    assert!(result.is_err());
    if let Err(AppError::StateTransitionError(msg)) = result {
        println!("捕获到预期的状态转换错误: {}", msg);
    } else {
        panic!("未捕获到预期的StateTransitionError，实际错误: {:?}", result.err());
    }
}


#[tokio::test]
async fn test_sm_force_transition() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    let reason = "管理员操作".to_string();
    
    let transition = manager.force_state_transition(&instance_id, OverallTestStatus::Skipped, reason.clone()).await.unwrap();
    assert_eq!(transition.new_status, OverallTestStatus::Skipped);
    assert_eq!(transition.reason, reason);

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::Skipped);
}

#[tokio::test]
async fn test_sm_reset_for_retest() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::TestCompletedFailed).await;
    
    // 给实例添加一些历史数据
    let mut inst = manager.runtime_repo.get_channel_instance(&instance_id).await.unwrap().unwrap();
    inst.error_message = Some("Previous error".to_string());
    inst.sub_test_results.insert(SubTestItem::HardPoint, SubTestExecutionResult::default());
    manager.runtime_repo.update_channel_instance(&inst).await.unwrap();
    
    let transition = manager.reset_instance_for_retest(&instance_id).await.unwrap();
    assert_eq!(transition.new_status, OverallTestStatus::NotTested);

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::NotTested);
    assert!(state_after.error_info.is_none());
    assert!(state_after.sub_test_results.is_empty());
}

#[tokio::test]
async fn test_sm_event_subscription_and_filtering() {
    let (manager, instance1_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    let (_, instance2_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await; // 第二个实例

    let mut rx_all = manager.subscribe_to_all_state_changes();
    // P2.1.2: 接口要求返回 Receiver，实际过滤由调用者完成
    let mut rx_inst1 = manager.subscribe_to_instance_state_changes(&instance1_id).await.unwrap();

    let outcome = TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() };
    
    // 触发instance1的事件
    manager.apply_raw_outcome(&instance1_id, &outcome).await.unwrap();
    // 触发instance2的事件
    manager.apply_raw_outcome(&instance2_id, &outcome).await.unwrap();

    let mut events_for_all_count = 0;
    let mut events_for_inst1_count = 0;

    // 从 rx_all 接收所有事件
    for _ in 0..2 { // 期望收到两个事件
        if let Ok(event) = tokio::time::timeout(std::time::Duration::from_secs(1), rx_all.recv()).await {
            events_for_all_count +=1;
            println!("rx_all received: {:?}", event.unwrap().instance_id);
        } else {
            break;
        }
    }
    assert_eq!(events_for_all_count, 2, "rx_all should receive events from both instances");
    
    // 从 rx_inst1 接收事件并过滤
    // 由于 rx_inst1 实际是主广播的拷贝，它也会收到两个事件，需要手动过滤
    let mut actual_inst1_events = 0;
     for _ in 0..2 { // 尝试接收两个事件
        if let Ok(Ok(event)) = tokio::time::timeout(std::time::Duration::from_secs(1), rx_inst1.recv()).await {
             if event.instance_id == instance1_id {
                events_for_inst1_count += 1;
                println!("rx_inst1 (filtered) received: {:?}", event.instance_id);
             }
        } else {
            break; // 超时或通道关闭
        }
    }
    assert_eq!(events_for_inst1_count, 1, "rx_inst1 (after filtering) should only count event for instance1_id");
}


#[tokio::test]
async fn test_sm_runtime_history() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    
    let outcome1 = TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::InProgress, ..Default::default() };
    manager.apply_raw_outcome(&instance_id, &outcome1).await.unwrap();
    
    let outcome2 = TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() };
    manager.apply_raw_outcome(&instance_id, &outcome2).await.unwrap();

    let history = manager.get_runtime_transition_history(&instance_id).await.unwrap();
    assert_eq!(history.len(), 2);
    assert_eq!(history[0].old_status, OverallTestStatus::NotTested);
    // 假设 InProgress 会转为 HardPointTesting
    assert_eq!(history[0].new_status, OverallTestStatus::HardPointTesting); 
    assert_eq!(history[1].old_status, OverallTestStatus::HardPointTesting);
    // 假设 Passed 会转为 TestCompletedPassed (或取决于规则，可能是HardPointTesting的完成)
    assert_eq!(history[1].new_status, OverallTestStatus::TestCompletedPassed); 
}
```

#### ✅ 预期结果/完成标准 (步骤 2.1)
1.  `IChannelStateManager` 接口、`EnhancedChannelStateManager` 实现、`StateTransitionRules` 和相关事件/辅助结构定义完成。
2.  状态转换严格遵循 `StateTransitionRules`，非法转换被阻止。
3.  `apply_raw_outcome` 作为主要状态变更入口，正确处理测试结果并更新实例状态。
4.  强制转换和重置功能按预期工作。
5.  状态变更事件通过 `tokio::sync::broadcast` 正确发布，订阅者可以接收。
6.  `subscribe_to_instance_state_changes` 能提供针对特定实例的事件流（通过调用者过滤主 `Receiver`）。
7.  运行时状态转换历史被正确记录在内存中。
8.  单元测试覆盖核心功能，包括各种状态转换场景、事件发布和历史记录。
9.  代码符合项目规范。

---

## 🚀 Phase 3: 任务调度器与执行器重构 (Task Scheduling & Execution)

### 📌 重构原因 (Phase 3)
自动化测试系统需要一个强大的任务调度和执行核心来管理和运行测试序列。当前可能缺乏：
*   灵活的任务优先级和依赖管理。
*   精细的并发控制（`FAT-TTM-001`）。
*   标准化的测试步骤执行接口（`FAT-CTK-001`）。
*   清晰的任务生命周期管理（暂停、恢复、取消、重试）。
*   任务执行过程中的事件通知和状态反馈。

此阶段的目标是设计并实现 `ITaskScheduler`（任务调度器）和 `ISpecificTestStepExecutor`（具体测试步骤执行器）体系，参考 `TestTaskManager.cs` 的优秀设计，并结合Rust异步生态进行优化。

### 步骤 3.1: 定义任务调度器和执行器接口

#### 🎯 目标
定义 `ITaskScheduler` 接口用于管理和调度测试任务，`ISpecificTestStepExecutor` 接口用于封装单个具体测试步骤的执行逻辑。

#### 📝 具体实施

##### 3.1.1 定义任务相关的数据结构
```rust
// src/services/task_scheduling/task_models.rs (或类似模块)
use crate::models::enums::{SubTestItem, TaskPriority, TaskStatus};
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition, TestOutcome}; // 假设这些已定义
use crate::utils::error::AppError;
use chrono::{DateTime, Utc};
use std::collections::HashMap;
use serde::{Serialize, Deserialize};
use uuid::Uuid;
use std::sync::Arc;
use crate::services::plc_communication::IPlcCommunicationService; // PLC服务接口

/// 测试任务定义 (由应用服务层创建，交给调度器)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestTask {
    pub task_id: String,              // 唯一任务ID
    pub instance_id: String,          //关联的 ChannelTestInstance ID
    pub definition_id: String,        // 关联的 ChannelPointDefinition ID
    pub batch_id: String,             // 所属批次ID
    pub sub_test_item: SubTestItem,   // 当前任务要执行的具体测试项
    pub priority: TaskPriority,
    pub created_at: DateTime<Utc>,
    pub max_retries: u32,             // 最大重试次数
    pub timeout_ms: Option<u64>,      // 任务执行超时
    // pub dependencies: Vec<String>, // 依赖的其他task_id，简化：当前版本不实现复杂依赖
    pub metadata: Option<HashMap<String, String>>, // 其他元数据
}

impl TestTask {
    pub fn new(instance_id: &str, definition_id: &str, batch_id: &str, sub_test_item: SubTestItem) -> Self {
        Self {
            task_id: Uuid::new_v4().to_string(),
            instance_id: instance_id.to_string(),
            definition_id: definition_id.to_string(),
            batch_id: batch_id.to_string(),
            sub_test_item,
            priority: TaskPriority::Normal,
            created_at: Utc::now(),
            max_retries: 1, // 默认重试1次
            timeout_ms: Some(30000), // 默认30秒超时
            metadata: None,
        }
    }
}


/// 任务句柄 (调度器返回给调用者，用于后续操作)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct TaskHandle(pub String); // 使用String类型的task_id

/// 任务运行时信息 (调度器内部或查询时使用)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskRuntimeInfo {
    pub handle: TaskHandle,
    pub task_definition: TestTask, // 原始任务定义
    pub status: TaskStatus,
    pub current_retry_count: u32,
    pub scheduled_at: DateTime<Utc>,
    pub started_at: Option<DateTime<Utc>>,
    pub completed_at: Option<DateTime<Utc>>,
    pub error_message: Option<String>,
    // pub progress_percentage: f64, // 对于单个测试项任务，进度可能只是0或100
}

/// 任务事件类型
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum TaskEventType {
    Scheduled,
    Started,
    AttemptFailed, // 一次尝试失败 (可能重试)
    CompletedSuccessfully,
    CompletedWithFailure, // 所有重试后最终失败
    Cancelled,
    // Paused, Resumed, // Phase3中的第三个问题：简化，暂不实现暂停/恢复单个任务
}

/// 任务事件 (由调度器发布)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskExecutionEvent {
    pub task_handle: TaskHandle,
    pub instance_id: String,
    pub batch_id: String,
    pub sub_test_item: SubTestItem,
    pub event_type: TaskEventType,
    pub timestamp: DateTime<Utc>,
    pub details: Option<String>, // 例如错误信息
    pub outcome: Option<TestOutcome>, // 任务完成时，包含执行结果
}
```

##### 3.1.2 定义 `ISpecificTestStepExecutor` 接口
```rust
// src/services/task_scheduling/test_executors.rs (或类似模块)
use async_trait::async_trait;
// (引入上面定义的 TestTask, TaskRuntimeInfo, TestOutcome 等)
// (引入 ChannelTestInstance, ChannelPointDefinition, IPlcCommunicationService, AppError)
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition, TestOutcome};
use crate::models::enums::SubTestItem;
use crate::utils::error::AppError;
use crate::services::plc_communication::IPlcCommunicationService;
use std::sync::Arc;


/// 具体测试步骤执行器接口 (FAT-CTK-001)
/// 每个实现类负责执行一个特定类型的 SubTestItem。
#[async_trait]
pub trait ISpecificTestStepExecutor: Send + Sync {
    /// 返回此执行器处理的 SubTestItem 类型
    fn item_type(&self) -> SubTestItem;

    /// 执行测试步骤
    /// - `task`: 当前执行的任务定义。
    /// - `instance`: 目标 ChannelTestInstance 的当前状态 (可变引用，允许执行器在某些情况下更新临时状态，但最终状态应由StateManager处理)。
    /// - `definition`: 目标 ChannelPointDefinition。
    /// - `plc_service`: 用于与PLC通信的共享服务实例。
    /// 返回 TestOutcome，包含测试结果和相关数据。
    async fn execute(
        &self,
        task: &TestTask, // 包含 instance_id, definition_id, sub_test_item 等
        instance_snapshot: &ChannelTestInstance, // 执行前的实例快照，只读
        definition: &ChannelPointDefinition,
        plc_service: Arc<dyn IPlcCommunicationService>, // 具体的PLC通信服务
    ) -> Result<TestOutcome, AppError>; // TestOutcome 应包含足够信息供 StateManager 更新状态
}
```

##### 3.1.3 定义 `ITaskScheduler` 接口
```rust
// src/services/task_scheduling/scheduler.rs (或类似模块)
use async_trait::async_trait;
// (引入上面定义的 TestTask, TaskHandle, TaskRuntimeInfo, TaskExecutionEvent 等)
// (引入 AppError, TaskPriority)
use crate::services::task_scheduling::task_models::{TestTask, TaskHandle, TaskRuntimeInfo, TaskExecutionEvent};
use crate::utils::error::AppError;
use crate::models::enums::TaskPriority;
use tokio::sync::broadcast;


/// 任务调度器接口 (FAT-TTM-001)
#[async_trait]
pub trait ITaskScheduler: Send + Sync {
    /// 提交单个测试任务到调度队列
    async fn schedule_task(&self, task: TestTask) -> Result<TaskHandle, AppError>;

    /// 批量提交测试任务
    async fn schedule_tasks_batch(&self, tasks: Vec<TestTask>) -> Result<Vec<TaskHandle>, AppError>;
    
    /// 取消一个待处理或正在运行的任务
    /// Phase3中的第四个问题：简化取消逻辑
    async fn cancel_task(&self, task_handle: &TaskHandle) -> Result<(), AppError>;

    /// 取消指定批次下的所有待处理或正在运行的任务
    async fn cancel_tasks_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError>; // 返回取消的任务数量

    /// 获取任务的当前运行时信息 (状态、进度等)
    async fn get_task_runtime_info(&self, task_handle: &TaskHandle) -> Result<Option<TaskRuntimeInfo>, AppError>;

    /// 获取指定批次下所有任务的运行时信息
    async fn list_tasks_by_batch_id(&self, batch_id: &str) -> Result<Vec<TaskRuntimeInfo>, AppError>;
    
    /// 获取当前活动的任务数量 (Pending + Running)
    async fn get_active_task_count(&self) -> Result<usize, AppError>;

    /// 订阅任务执行事件
    fn subscribe_to_task_events(&self) -> broadcast::Receiver<TaskExecutionEvent>;

    /// 设置最大并发测试数 (FAT-TTM-001)
    async fn set_max_concurrent_tasks(&self, limit: usize) -> Result<(), AppError>;
    
    /// 获取当前最大并发数
    async fn get_max_concurrent_tasks(&self) -> Result<usize, AppError>;

    /// 优雅地关闭调度器，等待活动任务完成（在超时范围内）
    async fn shutdown(&self, timeout_ms: Option<u64>) -> Result<(), AppError>;
}
```

#### 🧪 测试方案 (步骤 3.1)
此步骤主要定义接口和数据结构，直接的单元测试较少。测试重点在于：
1.  **编译检查**: 确保所有接口、结构体定义正确，类型匹配。
2.  **数据结构序列化/反序列化**: 如果这些结构体需要在网络上传输或存储（例如 `TestTask` 可能从外部传入），测试其 `serde` 功能。
3.  **文档和清晰度**: 审查接口和结构体定义的注释是否清晰，用途是否明确。

#### ✅ 预期结果/完成标准 (步骤 3.1)
1.  `TestTask`, `TaskHandle`, `TaskRuntimeInfo`, `TaskExecutionEvent` 等核心数据结构定义完成。
2.  `ISpecificTestStepExecutor` 接口定义完成，明确了执行单个测试步骤的契约。
3.  `ITaskScheduler` 接口定义完成，明确了任务调度、控制和查询的各项功能。
4.  所有定义符合项目代码规范。

---
### 步骤 3.2: 实现具体测试步骤执行器 (`ISpecificTestStepExecutor` 的实现类)

#### 🎯 目标
根据 `FAT-CTK-001`（每个执行器处理单一测试步骤），为核心的 `SubTestItem`（例如 `HardPoint`，以及后续的报警测试如 `LowAlarm`, `HighAlarm` 等）创建具体的实现类。这些执行器将封装与PLC交互的逻辑，执行测试并返回 `TestOutcome`。

#### 📝 具体实施

##### 3.2.1 实现硬点测试执行器 (`HardPointTestExecutor`)
硬点测试通常涉及读取PLC中某个地址的模拟量或数字量，并与预期范围（可能来自 `ChannelPointDefinition` 或 `TestParameterSet`）进行比较。

```rust
// src/services/task_scheduling/executors/hardpoint_test_executor.rs
use crate::services::task_scheduling::task_models::{TestTask, TestOutcome}; // 从 3.1.1 引入
use crate::services::task_scheduling::test_executors::ISpecificTestStepExecutor; // 从 3.1.2 引入
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition};
use crate::models::enums::{SubTestItem, TestResult, PointDataType}; // 假设PointDataType已定义
use crate::utils::error::AppError;
use crate::services::plc_communication::IPlcCommunicationService; // PLC服务接口
use std::sync::Arc;
use chrono::Utc;
use async_trait::async_trait;

pub struct HardPointTestExecutor;

impl HardPointTestExecutor {
    pub fn new() -> Self { Self }
}

#[async_trait]
impl ISpecificTestStepExecutor for HardPointTestExecutor {
    fn item_type(&self) -> SubTestItem {
        SubTestItem::HardPoint
    }

    async fn execute(
        &self,
        task: &TestTask,
        instance_snapshot: &ChannelTestInstance, // 只读快照
        definition: &ChannelPointDefinition,
        plc_service: Arc<dyn IPlcCommunicationService>,
    ) -> Result<TestOutcome, AppError> {
        log::info!("开始执行硬点测试: instance_id={}, task_id={}, plc_addr={}",
            task.instance_id, task.task_id, definition.plc_communication_address);

        let start_time = Utc::now();
        let mut outcome = TestOutcome {
            test_item: self.item_type(),
            result: TestResult::InProgress, // 初始状态
            measured_value: None,
            expected_value: definition.range_lower_limit, // 简化：期望值可能更复杂或来自参数集
            tolerance: None, // 应从 TestParameterSet 获取
            duration_ms: None,
            error_message: None,
            timestamp: start_time,
        };

        // 1. 从 TestParameterSet (通过 definition.module_type 查询 ConfigurationRepository) 获取容差等参数
        //    (此处简化，假设容差已知或不在此处处理)
        let tolerance = definition.engineering_unit.as_ref().map_or(0.1, |_| 0.1); // 示例容差

        // 2. 根据 definition.data_type 和 definition.plc_communication_address 读取PLC值
        let read_value: f64; // 标准化为 f64 便于比较

        match definition.data_type {
            PointDataType::Bool | PointDataType::Digital => {
                let plc_bool_val = plc_service.read_bool(&definition.plc_communication_address).await
                    .map_err(|e| {
                        outcome.result = TestResult::Failed;
                        outcome.error_message = Some(format!("PLC读取布尔值失败: {}", e));
                        AppError::PlcCommunicationError(format!("HardPoint ReadBool Error: {}", e))
                    })?;
                read_value = if plc_bool_val { 1.0 } else { 0.0 };
                // 对于数字量，预期值和范围可能不同，此处简化
                outcome.expected_value = Some(1.0); // 假设期望硬点为ON
            }
            PointDataType::Float | PointDataType::Analog => {
                read_value = plc_service.read_f32(&definition.plc_communication_address).await
                    .map_err(|e| {
                        outcome.result = TestResult::Failed;
                        outcome.error_message = Some(format!("PLC读取浮点数失败: {}", e));
                        AppError::PlcCommunicationError(format!("HardPoint ReadF32 Error: {}", e))
                    })? as f64;
            }
            PointDataType::Int16 | PointDataType::Int32 | PointDataType::Integer => {
                 read_value = plc_service.read_i32(&definition.plc_communication_address).await // 假设有 read_i32
                    .map_err(|e| {
                        outcome.result = TestResult::Failed;
                        outcome.error_message = Some(format!("PLC读取整数失败: {}", e));
                        AppError::PlcCommunicationError(format!("HardPoint ReadInt Error: {}", e))
                    })? as f64;
            }
            _ => {
                outcome.result = TestResult::Skipped; // 或 Failed
                outcome.error_message = Some(format!("不支持的数据类型进行硬点测试: {:?}", definition.data_type));
                 return Err(AppError::InvalidInput(format!("HardPoint: Unsupported data type {:?}", definition.data_type)));
            }
        }
        
        outcome.measured_value = Some(read_value);

        // 3. 比较读取值与预期值/范围
        // 对于模拟量硬点，通常是检查值是否在一个预期的小范围内，或者是否稳定。
        // 此处简化为检查是否在量程内，或者与一个固定的期望点比较。
        // 实际硬点测试可能更复杂，例如：确保AI通道的值在一个标定点附近。
        // 假设硬点测试是检查值是否落在量程定义的 min/max 之间 (这更像是范围检查而非精确硬点)
        // 或者，如果TestParameterSet中定义了具体的硬点测试期望值，则用那个值。
        
        let mut test_passed = false;
        if let (Some(min), Some(max)) = (definition.range_lower_limit, definition.range_upper_limit) {
            if definition.data_type != PointDataType::Bool && definition.data_type != PointDataType::Digital { // 模拟量检查范围
                if read_value >= (min - tolerance) && read_value <= (max + tolerance) {
                    test_passed = true;
                    outcome.expected_value = Some(min); // 简化，实际期望可能是某个特定点
                } else {
                    outcome.error_message = Some(format!("测量值 {:.2} 超出预期范围 [{:.2}, {:.2}] (含容差 {:.2})", read_value, min - tolerance, max + tolerance, tolerance));
                }
            }
        }
        // 对于数字量硬点
        if definition.data_type == PointDataType::Bool || definition.data_type == PointDataType::Digital {
            // 假设期望值为1.0 (ON)
            if (read_value - 1.0).abs() < tolerance { // 比较是否为1.0
                test_passed = true;
            } else {
                 outcome.error_message = Some(format!("数字量硬点期望为ON (1.0)，实际为 {:.0}", read_value));
            }
        }


        if test_passed {
            outcome.result = TestResult::Passed;
            log::info!("硬点测试通过: instance_id={}, task_id={}, measured_value={:?}",
                task.instance_id, task.task_id, outcome.measured_value);
        } else {
            outcome.result = TestResult::Failed;
            log::warn!("硬点测试失败: instance_id={}, task_id={}, measured_value={:?}, error={:?}",
                task.instance_id, task.task_id, outcome.measured_value, outcome.error_message);
        }
        
        let end_time = Utc::now();
        outcome.duration_ms = Some((end_time - start_time).num_milliseconds());
        outcome.timestamp = end_time;

        Ok(outcome)
    }
}
```
**注意**:
*   `IPlcCommunicationService` 需要有如 `read_bool`, `read_f32`, `read_i32` 等方法。
*   错误处理：当PLC通信失败时，应将 `TestOutcome.result` 设置为 `Failed` 并填充 `error_message`，同时返回 `AppError::PlcCommunicationError`。
*   `TestParameterSet` 的获取逻辑：在实际场景中，`TestOrchestrationService` 或 `TaskScheduler` 在创建 `TestTask` 时，应已从 `IConfigurationRepository` 加载相关的 `TestParameterSet` 并将其部分信息（如容差、具体测试点）传递给 `TestTask` 或使其可被 `ISpecificTestStepExecutor` 访问。此处为简化，直接在执行器内假设或硬编码了部分参数。

##### 3.2.2 实现其他测试执行器 (例如报警测试，可选)
类似的，可以为 `LowAlarm`, `HighAlarm`, `DigitalOutputTest` 等创建执行器。
例如，`LowAlarmTestExecutor`:
1.  读取当前模拟量值。
2.  通过PLC服务写入一个低于低报警设定值的值到过程变量（或模拟输入）。
3.  等待一小段时间。
4.  读取PLC中对应的低报警状态位。
5.  验证报警状态是否为ON。
6.  恢复过程变量的值。
7.  返回 `TestOutcome`。

#### 🧪 测试方案 (步骤 3.2)
对每个具体的测试步骤执行器进行单元测试，需要Mock `IPlcCommunicationService`。

```rust
// src/services/task_scheduling/tests/hardpoint_test_executor_tests.rs
use crate::services::task_scheduling::executors::hardpoint_test_executor::HardPointTestExecutor;
use crate::services::task_scheduling::test_executors::ISpecificTestStepExecutor;
use crate::services::task_scheduling::task_models::TestTask;
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition, TestOutcome};
use crate::models::enums::{SubTestItem, TestResult, PointDataType, ModuleType, OverallTestStatus};
use crate::services::plc_communication::{MockIPlcCommunicationService, IPlcCommunicationService}; // 需要创建Mock
use crate::utils::error::AppError;
use std::sync::Arc;
use mockall::predicate::*;
use chrono::Utc;

fn create_test_task_for_executor(item: SubTestItem) -> TestTask {
    TestTask {
        task_id: "task_exec_test".to_string(),
        instance_id: "inst_exec_test".to_string(),
        definition_id: "def_exec_test".to_string(),
        batch_id: "batch_exec_test".to_string(),
        sub_test_item: item,
        priority: Default::default(),
        created_at: Utc::now(),
        max_retries: 0,
        timeout_ms: None,
        metadata: None,
    }
}

fn create_test_definition(data_type: PointDataType, low: Option<f64>, high: Option<f64>) -> ChannelPointDefinition {
    ChannelPointDefinition {
        id: "def_exec_test".to_string(),
        tag: "HP_TEST_TAG".to_string(),
        plc_communication_address: "PLC_ADDR_HP".to_string(),
        data_type,
        range_lower_limit: low,
        range_upper_limit: high,
        module_type: ModuleType::AI, // 示例
        // ... 其他字段
        variable_name: String::new(), variable_description: String::new(), station_name: String::new(),
        module_name: String::new(), channel_tag_in_module: String::new(), power_supply_type: String::new(),
        wire_system: String::new(), plc_absolute_address: None, engineering_unit: None,
        sll_set_value: None, sll_set_point_address: None, sll_feedback_address: None,
        sl_set_value: None, sl_set_point_address: None, sl_feedback_address: None,
        sh_set_value: None, sh_set_point_address: None, sh_feedback_address: None,
        shh_set_value: None, shh_set_point_address: None, shh_feedback_address: None,
        maintenance_value_set_point_address: None, maintenance_enable_switch_point_address: None,
        access_property: None, save_history: None, power_failure_protection: None, test_rig_plc_address: None,
    }
}

fn create_test_instance_snapshot() -> ChannelTestInstance {
    // 对于执行器，实例快照主要是参考，不应被修改
    ChannelTestInstance {
        instance_id: "inst_exec_test".to_string(),
        definition_id: "def_exec_test".to_string(),
        test_batch_id: "batch_exec_test".to_string(),
        overall_status: OverallTestStatus::HardPointTesting, // 假设测试前状态
        // ...
        current_step_details: None, error_message: None, start_time: None, last_updated_time: Utc::now(),
        final_test_time: None, total_test_duration_ms: None, sub_test_results: Default::default(),
        hardpoint_readings: None, manual_test_current_value_input: None, manual_test_current_value_output: None,
    }
}


#[tokio::test]
async fn test_hardpoint_executor_ai_passed() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    let definition = create_test_definition(PointDataType::Float, Some(0.0), Some(100.0));
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_f32()
        .with(eq("PLC_ADDR_HP"))
        .times(1)
        .returning(|_| Ok(50.0_f32)); // PLC返回50.0

    let outcome = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await.unwrap();
    
    assert_eq!(outcome.test_item, SubTestItem::HardPoint);
    assert_eq!(outcome.result, TestResult::Passed);
    assert_eq!(outcome.measured_value, Some(50.0));
    assert!(outcome.error_message.is_none());
}

#[tokio::test]
async fn test_hardpoint_executor_ai_failed_out_of_range() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    let definition = create_test_definition(PointDataType::Float, Some(0.0), Some(100.0));
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_f32()
        .with(eq("PLC_ADDR_HP"))
        .times(1)
        .returning(|_| Ok(150.0_f32)); // PLC返回150.0 (超出范围)

    let outcome = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await.unwrap();
    
    assert_eq!(outcome.result, TestResult::Failed);
    assert_eq!(outcome.measured_value, Some(150.0));
    assert!(outcome.error_message.is_some());
    assert!(outcome.error_message.unwrap().contains("超出预期范围"));
}

#[tokio::test]
async fn test_hardpoint_executor_di_passed() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    // 对于DI，range_lower/upper_limit 可能不适用或有不同含义，这里假设期望值为1 (ON)
    let definition = create_test_definition(PointDataType::Bool, Some(0.0), Some(1.0)); 
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_bool()
        .with(eq("PLC_ADDR_HP"))
        .times(1)
        .returning(|_| Ok(true)); // PLC返回true (ON)

    let outcome = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await.unwrap();
    
    assert_eq!(outcome.result, TestResult::Passed);
    assert_eq!(outcome.measured_value, Some(1.0)); // true 映射为 1.0
}

#[tokio::test]
async fn test_hardpoint_executor_plc_communication_error() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    let definition = create_test_definition(PointDataType::Float, Some(0.0), Some(100.0));
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_f32()
        .times(1)
        .returning(|_| Err(AppError::PlcCommunicationError("Simulated PLC conn error".to_string())));

    // execute本身应返回AppError，TestOutcome内部也应标记失败
    let result = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await;
    assert!(result.is_err());
    if let Err(AppError::PlcCommunicationError(msg)) = result {
         assert!(msg.contains("Simulated PLC conn error"));
    } else {
        panic!("Expected PlcCommunicationError, got {:?}", result);
    }
    // 如果要检查TestOutcome内部，需要让execute在PLC错误时不panic而是返回Ok(TestOutcome{result:Failed})
    // 当前 ISpecificTestStepExecutor 定义是返回 Result<TestOutcome, AppError>
    // 所以，如果PLC通信出错，execute方法本身会返回Err。
    // 如果希望execute总是返回Ok(TestOutcome)，则需要在其内部捕获PLC错误并设置outcome.result=Failed。
    // 按照当前定义，外部(调度器)应处理execute返回的Err。
}
```
**创建 `MockIPlcCommunicationService`**:
您需要使用 `mockall` crate 来为 `IPlcCommunicationService` 创建一个 mock 实现。
```rust
// src/services/plc_communication.rs (或者一个专门的 mock 文件)
// ... (IPlcCommunicationService trait 定义) ...

#[cfg(test)]
use mockall::mock;

#[cfg(test)]
mock! {
    pub PlcCommunicationService {} // 名称可以任意，通常与trait名相似
    #[async_trait::async_trait]
    impl IPlcCommunicationService for PlcCommunicationService {
        async fn connect(&self, plc_id: &str, config_json: &str) -> Result<(), AppError>;
        async fn disconnect(&self, plc_id: &str) -> Result<(), AppError>;
        async fn read_bool(&self, plc_id: &str, address: &str) -> Result<bool, AppError>;
        async fn write_bool(&self, plc_id: &str, address: &str, value: bool) -> Result<(), AppError>;
        async fn read_f32(&self, plc_id: &str, address: &str) -> Result<f32, AppError>;
        async fn write_f32(&self, plc_id: &str, address: &str, value: f32) -> Result<(), AppError>;
        async fn read_i32(&self, plc_id: &str, address: &str) -> Result<i32, AppError>;
        async fn write_i32(&self, plc_id: &str, address: &str, value: i32) -> Result<(), AppError>;
        // 添加其他你需要 mock 的方法
    }
}
// 注意: mockall生成的Mock默认不是线程安全的(Send+Sync)，如果异步trait方法需要在多线程环境中使用，
// 可能需要为expect_...方法添加 .once().returning(...) 等，或者确保测试在单线程运行时(如 current_thread runtime)。
// 对于 async_trait，mockall 通常能很好地处理。
```
您需要根据 `IPlcCommunicationService` 的实际定义来调整 `mock!` 宏。
在测试中，`plc_service: Arc<dyn IPlcCommunicationService>` 参数中的 `plc_id` 暂时被忽略了，因为执行器直接使用了 `address`。如果 `IPlcCommunicationService` 的方法签名确实需要 `plc_id`（例如，管理多个PLC连接），那么 `TestTask` 或 `ChannelPointDefinition` 需要包含此信息，并传递给PLC服务方法。为简化，当前 `IPlcCommunicationService` 的 mock 和测试执行器调用都假设地址本身已足够唯一，或者 `plc_id` 由外部管理。

#### ✅ 预期结果/完成标准 (步骤 3.2)
1.  至少为 `SubTestItem::HardPoint` 实现了 `ISpecificTestStepExecutor` (即 `HardPointTestExecutor`)。
2.  执行器能够正确地与 (mocked) `IPlcCommunicationService` 交互，读取/写入PLC数据。
3.  执行器根据读取到的值和定义/参数，正确判断测试结果 (Passed/Failed/Skipped) 并构建 `TestOutcome`。
4.  错误处理完善，PLC通信故障或无效参数能被正确处理并反映在 `TestOutcome` 和/或返回的 `AppError` 中。
5.  单元测试覆盖各种场景（通过、失败、PLC错误、无效数据类型等）。
6.  代码符合项目规范。

---
### 步骤 3.3: 实现高级任务调度器 (`AdvancedTaskScheduler`)

#### 🎯 目标
基于 `ITaskScheduler` 接口，实现 `AdvancedTaskScheduler`。它将负责：
*   管理任务队列（支持优先级）。
*   使用 `tokio::sync::Semaphore` 控制并发执行的任务数量 (`FAT-TTM-001`)。
*   在独立的tokio任务中执行 `TestTask`，通过查找并调用相应的 `ISpecificTestStepExecutor`。
*   处理任务的生命周期：调度、执行、重试（基于 `TestTask.max_retries` 和 `TestOutcome`）、完成、取消。
*   收集 `TestOutcome` 并通过 `IChannelStateManager` 更新 `ChannelTestInstance` 状态。
*   发布 `TaskExecutionEvent`。

#### 📝 具体实施

##### 3.3.1 `AdvancedTaskScheduler` 结构体和初始化
```rust
// src/services/task_scheduling/scheduler.rs (续)
use super::task_models::*;
use super::test_executors::ISpecificTestStepExecutor;
use crate::services::state_management::IChannelStateManager;
use crate::services::persistence::repositories::configuration_repository::IConfigurationRepository;
use crate::services::persistence::repositories::runtime_repository::IRuntimeRepository;
use crate::services::plc_communication::IPlcCommunicationService; // 引入PLC服务trait
use std::sync::Arc;
use tokio::sync::{Semaphore, Mutex, RwLock, broadcast, watch};
use tokio::task::JoinHandle;
use std::collections::{BinaryHeap, HashMap, VecDeque}; // BinaryHeap for priority queue
use std::cmp::Ordering;
use chrono::Utc;
use uuid::Uuid;

const DEFAULT_SCHEDULER_EVENT_CAPACITY: usize = 256;
const DEFAULT_MAX_CONCURRENT_TASKS: usize = 4; // 默认并发数

// 用于优先级队列的包装项
#[derive(Debug, Clone)]
struct ScheduledTaskItem {
    task: TestTask,
    handle: TaskHandle,
    scheduled_at: DateTime<Utc>, // 用于处理相同优先级时的FIFO
    current_retry_count: u32,
}

// 为BinaryHeap实现Ord (Min-Heap，所以比较时反转优先级)
impl Ord for ScheduledTaskItem {
    fn cmp(&self, other: &Self) -> Ordering {
        other.task.priority.cmp(&self.task.priority) // Higher numeric priority means higher actual priority
            .then_with(|| self.scheduled_at.cmp(&other.scheduled_at)) // FIFO for same priority
    }
}
impl PartialOrd for ScheduledTaskItem {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}
impl PartialEq for ScheduledTaskItem {
    fn eq(&self, other: &Self) -> bool {
        self.handle == other.handle && self.scheduled_at == other.scheduled_at
    }
}
impl Eq for ScheduledTaskItem {}


pub struct AdvancedTaskScheduler {
    // 依赖
    state_manager: Arc<dyn IChannelStateManager>,
    config_repo: Arc<dyn IConfigurationRepository>, // 用于获取ChannelPointDefinition
    runtime_repo: Arc<dyn IRuntimeRepository>,   // 用于获取ChannelTestInstance快照
    plc_service_factory: Arc<dyn Fn() -> Arc<dyn IPlcCommunicationService> + Send + Sync>, // PLC服务工厂或共享实例
    executors: Arc<HashMap<SubTestItem, Arc<dyn ISpecificTestStepExecutor>>>,

    // 内部状态
    task_queue: Arc<Mutex<BinaryHeap<ScheduledTaskItem>>>, // 优先级队列
    active_tasks: Arc<RwLock<HashMap<TaskHandle, TaskRuntimeInfo>>>, // 正在运行或最近完成的任务信息
    running_task_handles: Arc<RwLock<HashMap<TaskHandle, JoinHandle<()>>>>, // Tokio任务句柄，用于取消

    concurrency_semaphore: Arc<Semaphore>,
    max_concurrent_tasks: Arc<RwLock<usize>>, // 允许动态调整

    event_broadcaster: broadcast::Sender<TaskExecutionEvent>,
    
    // 优雅关闭控制
    shutdown_signal_tx: watch::Sender<bool>,
    shutdown_signal_rx: watch::Receiver<bool>,
}

impl AdvancedTaskScheduler {
    pub fn new(
        state_manager: Arc<dyn IChannelStateManager>,
        config_repo: Arc<dyn IConfigurationRepository>,
        runtime_repo: Arc<dyn IRuntimeRepository>,
        plc_service_factory: Arc<dyn Fn() -> Arc<dyn IPlcCommunicationService> + Send + Sync>,
        executors: HashMap<SubTestItem, Arc<dyn ISpecificTestStepExecutor>>,
        initial_max_concurrent_tasks: Option<usize>,
    ) -> Arc<Self> {
        let (event_tx, _) = broadcast::channel(DEFAULT_SCHEDULER_EVENT_CAPACITY);
        let (shutdown_tx, shutdown_rx) = watch::channel(false); // false = not shutting down
        
        let max_tasks = initial_max_concurrent_tasks.unwrap_or(DEFAULT_MAX_CONCURRENT_TASKS);

        Arc::new(Self {
            state_manager,
            config_repo,
            runtime_repo,
            plc_service_factory,
            executors: Arc::new(executors),
            task_queue: Arc::new(Mutex::new(BinaryHeap::new())),
            active_tasks: Arc::new(RwLock::new(HashMap::new())),
            running_task_handles: Arc::new(RwLock::new(HashMap::new())),
            concurrency_semaphore: Arc::new(Semaphore::new(max_tasks)),
            max_concurrent_tasks: Arc::new(RwLock::new(max_tasks)),
            event_broadcaster: event_tx,
            shutdown_signal_tx: shutdown_tx,
            shutdown_signal_rx: shutdown_rx,
        })
    }

    /// 启动调度器的主处理循环 (应在一个独立的tokio任务中运行)
    pub fn start_processing_loop(self: Arc<Self>) {
        tokio::spawn(async move {
            log::info!("AdvancedTaskScheduler处理循环已启动。最大并发数: {}", self.concurrency_semaphore.available_permits());
            loop {
                // 检查关闭信号
                if *self.shutdown_signal_rx.borrow() {
                    log::info!("AdvancedTaskScheduler检测到关闭信号，正在退出处理循环...");
                    // 可以选择等待现有任务完成，或直接退出
                    // 此处简单退出，shutdown方法负责更复杂的逻辑
                    break;
                }

                // 1. 获取并发许可
                //    tokio::select! 允许同时等待信号和许可
                let permit = tokio::select! {
                    biased; // 优先检查关闭信号
                    _ = self.shutdown_signal_rx.changed() => { // changed() 会在信号改变时唤醒
                        if *self.shutdown_signal_rx.borrow() { continue; } // 再次检查，如果是关闭则循环
                        // 如果不是关闭信号（例如，只是初始值被读取），则尝试获取许可
                        // 但直接 continue 可能导致死循环，所以最好是明确处理关闭
                        // 这里简化：如果 changed 且不是关闭，就尝试获取许可。
                        // 或者，让 acquire 在超时后返回，然后检查 shutdown_signal_rx
                        match self.concurrency_semaphore.try_acquire_owned() {
                            Ok(p) => p,
                            Err(_) => { tokio::time::sleep(std::time::Duration::from_millis(50)).await; continue; } // 没有可用许可，稍后重试
                        }
                    },
                    permit_result = self.concurrency_semaphore.acquire_owned() => {
                        match permit_result {
                            Ok(p) => p,
                            Err(_) => { // Semaphore被关闭 (通常在shutdown时发生)
                                log_warn!("并发信号量已关闭，处理循环可能即将停止。");
                                continue; // 或 break;
                            }
                        }
                    }
                };
                
                // 2. 从队列中获取任务
                let scheduled_item_opt: Option<ScheduledTaskItem>;
                { // 限制 MutexGuard 的作用域
                    let mut queue = self.task_queue.lock().await;
                    scheduled_item_opt = queue.pop();
                }

                if let Some(scheduled_item) = scheduled_item_opt {
                    let task = scheduled_item.task.clone();
                    let handle = scheduled_item.handle;
                    log::info!("从队列取出任务: {:?}, ID: {}", task.sub_test_item, task.task_id);

                    // 更新任务信息为 Running
                    let runtime_info = TaskRuntimeInfo {
                        handle,
                        task_definition: task.clone(),
                        status: TaskStatus::Running,
                        current_retry_count: scheduled_item.current_retry_count,
                        scheduled_at: scheduled_item.scheduled_at,
                        started_at: Some(Utc::now()),
                        completed_at: None,
                        error_message: None,
                    };
                    self.active_tasks.write().await.insert(handle, runtime_info.clone());
                    
                    // 发布 Started 事件
                    self.publish_event(TaskExecutionEvent {
                        task_handle: handle, instance_id: task.instance_id.clone(), batch_id: task.batch_id.clone(),
                        sub_test_item: task.sub_test_item, event_type: TaskEventType::Started,
                        timestamp: Utc::now(), details: None, outcome: None,
                    }).await;

                    // 3. 异步执行任务
                    let self_clone = self.clone(); // Clone Arc for the new task
                    let task_join_handle = tokio::spawn(async move {
                        // permit 在此作用域结束时会自动释放
                        let _permit_guard = permit; 
                        self_clone.execute_and_process_task(scheduled_item).await;
                    });
                    self.running_task_handles.write().await.insert(handle, task_join_handle);

                } else {
                    // 队列为空，释放许可，稍后重试
                    drop(permit); // 明确释放
                    tokio::time::sleep(std::time::Duration::from_millis(100)).await; // 避免忙等待
                }
            }
            log::info!("AdvancedTaskScheduler处理循环已停止。");
        });
    }

    /// 内部函数：执行单个任务并处理其结果
    async fn execute_and_process_task(&self, scheduled_item: ScheduledTaskItem) {
        let task = scheduled_item.task;
        let handle = scheduled_item.handle;
        let mut current_retry_count = scheduled_item.current_retry_count;
        
        let final_outcome: TestOutcome;
        let mut execution_error: Option<AppError> = None;

        loop { // 重试循环
            // a. 获取执行器
            let executor = match self.executors.get(&task.sub_test_item) {
                Some(exec) => exec.clone(),
                None => {
                    let err_msg = format!("未找到任务项 {:?} 的执行器", task.sub_test_item);
                    log::error!("{}", err_msg);
                    final_outcome = TestOutcome::new_failed(task.sub_test_item, Some(err_msg.clone()));
                    execution_error = Some(AppError::ExecutorNotFound(err_msg));
                    break;
                }
            };

            // b. 获取依赖数据 (Definition, Instance Snapshot)
            let definition_res = self.config_repo.get_channel_definition_by_id(&task.definition_id).await;
            let instance_snapshot_res = self.runtime_repo.get_channel_instance(&task.instance_id).await;

            match (definition_res, instance_snapshot_res) {
                (Ok(Some(def)), Ok(Some(inst_snapshot))) => {
                    // c. 执行测试步骤
                    let plc_service = (self.plc_service_factory)(); // 获取PLC服务实例
                    let outcome_res = executor.execute(&task, &inst_snapshot, &def, plc_service).await;

                    match outcome_res {
                        Ok(outcome) => {
                            if outcome.result == TestResult::Passed || outcome.result == TestResult::Skipped {
                                final_outcome = outcome; // 成功或跳过，结束重试
                                break;
                            } else { // Failed or InProgress (InProgress不应到此，executor应返回最终结果)
                                if current_retry_count < task.max_retries {
                                    current_retry_count += 1;
                                    log::warn!("任务 {:?} (ID: {}) 第 {} 次尝试失败，将重试。错误: {:?}", 
                                        task.sub_test_item, task.task_id, current_retry_count, outcome.error_message);
                                    
                                    self.publish_event(TaskExecutionEvent {
                                        task_handle: handle, instance_id: task.instance_id.clone(), batch_id: task.batch_id.clone(),
                                        sub_test_item: task.sub_test_item, event_type: TaskEventType::AttemptFailed,
                                        timestamp: Utc::now(), details: outcome.error_message.clone(), outcome: Some(outcome.clone()),
                                    }).await;
                                    // TODO: 实现重试延迟策略
                                    tokio::time::sleep(std::time::Duration::from_secs(1)).await; // 简单延迟
                                    continue; // 进入下一次重试
                                } else {
                                    log::error!("任务 {:?} (ID: {}) 已达最大重试次数 ({})，最终失败。", 
                                        task.sub_test_item, task.task_id, task.max_retries);
                                    final_outcome = outcome; // 达到最大重试次数，以此结果为准
                                    break;
                                }
                            }
                        }
                        Err(app_err) => { // 执行器内部错误 (例如PLC通信严重故障)
                            log::error!("任务 {:?} (ID: {}) 执行器返回错误: {:?}", task.sub_test_item, task.task_id, app_err);
                            final_outcome = TestOutcome::new_failed(task.sub_test_item, Some(app_err.to_string()));
                            execution_error = Some(app_err);
                            break; 
                        }
                    }
                }
                (Err(e), _) | (_, Err(e)) => {
                    let err_msg = format!("获取任务依赖数据失败 (def_id: {}, inst_id: {}): {:?}", task.definition_id, task.instance_id, e);
                    log::error!("{}", err_msg);
                    final_outcome = TestOutcome::new_failed(task.sub_test_item, Some(err_msg.clone()));
                    execution_error = Some(AppError::RepositoryError(err_msg));
                    break;
                }
                (Ok(None), _) => { /* def not found */ execution_error = Some(AppError::RecordNotFound(task.definition_id.clone())); final_outcome = TestOutcome::new_skipped(task.sub_test_item, Some("Definition not found".to_string())); break; }
                (_, Ok(None)) => { /* instance not found */ execution_error = Some(AppError::InstanceNotFound(task.instance_id.clone())); final_outcome = TestOutcome::new_skipped(task.sub_test_item, Some("Instance not found".to_string())); break; }
            }
        } // end retry loop

        // d. 更新 ChannelTestInstance 状态 (通过 StateManager)
        match self.state_manager.apply_raw_outcome(&task.instance_id, &final_outcome).await {
            Ok(_) => log::info!("任务 {:?} (ID: {}) 结果已成功应用到状态管理器。", task.sub_test_item, task.task_id),
            Err(e) => log::error!("任务 {:?} (ID: {}) 结果应用到状态管理器失败: {:?}", task.sub_test_item, task.task_id, e),
        }
        
        // e. 更新任务运行时信息为 Completed/Failed
        let final_status = if final_outcome.result == TestResult::Passed || final_outcome.result == TestResult::Skipped {
            TaskStatus::Completed
        } else {
            TaskStatus::Failed
        };
        
        let event_type = if final_status == TaskStatus::Completed {
            TaskEventType::CompletedSuccessfully
        } else {
            TaskEventType::CompletedWithFailure
        };

        if let Some(mut info) = self.active_tasks.write().await.get_mut(&handle) {
            info.status = final_status;
            info.completed_at = Some(Utc::now());
            info.error_message = execution_error.map(|e| e.to_string()).or(final_outcome.error_message.clone());
            // info.progress_percentage = 100.0;
        }
        
        // f. 发布 Completed/Failed 事件
        self.publish_event(TaskExecutionEvent {
            task_handle: handle, instance_id: task.instance_id.clone(), batch_id: task.batch_id.clone(),
            sub_test_item: task.sub_test_item, event_type,
            timestamp: Utc::now(), details: final_outcome.error_message.clone(), outcome: Some(final_outcome),
        }).await;

        // g. 从 active_tasks 和 running_task_handles 中移除
        self.active_tasks.write().await.remove(&handle);
        self.running_task_handles.write().await.remove(&handle);
        log::info!("任务 {:?} (ID: {}) 执行完毕，状态: {:?}.", task.sub_test_item, task.task_id, final_status);
    }

    async fn publish_event(&self, event: TaskExecutionEvent) {
        if self.event_broadcaster.send(event.clone()).is_err() {
            log::warn!("任务事件 {:?} (Task ID: {}) 发布失败: 无订阅者或通道已满。", event.event_type, event.task_handle.0);
        }
    }
}
```

##### 3.3.2 `ITaskScheduler` 接口实现
```rust
// src/services/task_scheduling/scheduler.rs (续)
#[async_trait]
impl ITaskScheduler for AdvancedTaskScheduler {
    async fn schedule_task(&self, task: TestTask) -> Result<TaskHandle, AppError> {
        let handle = TaskHandle(task.task_id.clone()); // 使用 task_id 作为句柄
        let scheduled_item = ScheduledTaskItem {
            task,
            handle,
            scheduled_at: Utc::now(),
            current_retry_count: 0,
        };

        self.task_queue.lock().await.push(scheduled_item);
        log::info!("任务已调度: ID={}, Item={:?}", handle.0, self.task_queue.lock().await.peek().unwrap().task.sub_test_item);
        
        // 初始任务信息
        let runtime_info = TaskRuntimeInfo {
            handle,
            task_definition: self.task_queue.lock().await.peek().unwrap().task.clone(), // 从队列中获取最新的task定义
            status: TaskStatus::Pending,
            current_retry_count: 0,
            scheduled_at: Utc::now(),
            started_at: None, completed_at: None, error_message: None,
        };
        self.active_tasks.write().await.insert(handle, runtime_info);

        self.publish_event(TaskExecutionEvent {
            task_handle: handle, instance_id: self.task_queue.lock().await.peek().unwrap().task.instance_id.clone(),
            batch_id: self.task_queue.lock().await.peek().unwrap().task.batch_id.clone(),
            sub_test_item: self.task_queue.lock().await.peek().unwrap().task.sub_test_item,
            event_type: TaskEventType::Scheduled, timestamp: Utc::now(),
            details: None, outcome: None,
        }).await;
        Ok(handle)
    }

    async fn schedule_tasks_batch(&self, tasks: Vec<TestTask>) -> Result<Vec<TaskHandle>, AppError> {
        let mut handles = Vec::new();
        for task in tasks {
            handles.push(self.schedule_task(task).await?);
        }
        Ok(handles)
    }
    
    // Phase3中的第四个问题：简化取消逻辑。因为测试速度快，复杂取消机制（如中断IO）可能不需要。
    // 标记为取消，如果任务尚未开始，则从队列移除。如果已开始，则不强制中断，允许其自然结束。
    // 但执行器在关键步骤（如长时间等待或循环前）应检查此任务是否已被请求取消。
    async fn cancel_task(&self, task_handle: &TaskHandle) -> Result<(), AppError> {
        // 1. 尝试从活动任务中标记为取消，并获取 JoinHandle 以尝试中止
        let mut was_running = false;
        if let Some(mut info) = self.active_tasks.write().await.get_mut(task_handle) {
            if info.status == TaskStatus::Running || info.status == TaskStatus::Pending { // 理论上active_tasks主要存Running
                info.status = TaskStatus::Cancelled; // 标记为取消
                was_running = true; // 假设在active_tasks就是曾经或正在运行
                log::info!("任务 {} 标记为取消 (原状态: Running/Pending in active_tasks).", task_handle.0);
            }
        }
        if let Some(join_handle) = self.running_task_handles.write().await.remove(task_handle) {
             log::info!("尝试中止正在运行的任务 {}", task_handle.0);
             join_handle.abort(); // 尝试中止 Tokio 任务
             was_running = true; // 确认是在运行并尝试中止
        }

        // 2. 尝试从待处理队列中移除
        let mut removed_from_queue = false;
        let mut queue = self.task_queue.lock().await;
        let mut temp_heap = BinaryHeap::new(); // 用于暂存不被删除的任务
        while let Some(item) = queue.pop() {
            if item.handle == *task_handle {
                removed_from_queue = true;
                log::info!("任务 {} 从待处理队列中移除.", task_handle.0);
                // 不再放回 item
            } else {
                temp_heap.push(item);
            }
        }
        *queue = temp_heap; // 将未删除的任务放回原队列

        if was_running || removed_from_queue {
            self.publish_event(TaskExecutionEvent {
                task_handle: *task_handle,
                // 以下字段可能需要从 active_tasks 或其他地方获取，如果任务信息已不在
                instance_id: "N/A_cancelled".to_string(), 
                batch_id: "N/A_cancelled".to_string(),
                sub_test_item: SubTestItem::Unknown, // 需要一种方式获取这些信息
                event_type: TaskEventType::Cancelled,
                timestamp: Utc::now(),
                details: Some("任务被请求取消".to_string()),
                outcome: None,
            }).await;
             // 从 active_tasks 中彻底移除（如果仅标记而未移除）
            self.active_tasks.write().await.remove(task_handle);
            Ok(())
        } else {
            log::warn!("尝试取消任务 {}，但在运行列表或队列中均未找到可操作项。", task_handle.0);
            Err(AppError::TaskNotFound(task_handle.0.clone()))
        }
    }

    async fn cancel_tasks_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError> {
        let mut cancelled_count = 0;
        let mut tasks_to_cancel = Vec::new();

        // 从 active_tasks 中收集属于该批次的任务句柄
        let active_tasks_read = self.active_tasks.read().await;
        for (handle, info) in active_tasks_read.iter() {
            if info.task_definition.batch_id == batch_id && 
               (info.status == TaskStatus::Pending || info.status == TaskStatus::Running) {
                tasks_to_cancel.push(*handle);
            }
        }
        drop(active_tasks_read); // 释放读锁

        // 从 task_queue 中收集属于该批次的任务句柄
        let mut queue = self.task_queue.lock().await;
        let mut temp_heap_for_batch_cancel = BinaryHeap::new();
        let mut handles_in_queue = Vec::new();
        while let Some(item) = queue.pop() {
            if item.task.batch_id == batch_id {
                handles_in_queue.push(item.handle); // 收集待取消的句柄
            } else {
                temp_heap_for_batch_cancel.push(item); // 保留不相关的任务
            }
        }
        *queue = temp_heap_for_batch_cancel; // 更新队列
        drop(queue); // 释放锁

        tasks_to_cancel.extend(handles_in_queue);
        tasks_to_cancel.sort_unstable();
        tasks_to_cancel.dedup(); // 去重

        for handle in tasks_to_cancel {
            if self.cancel_task(&handle).await.is_ok() {
                cancelled_count += 1;
            }
        }
        log::info!("批次 {} 下共取消 {} 个任务。", batch_id, cancelled_count);
        Ok(cancelled_count)
    }


    async fn get_task_runtime_info(&self, task_handle: &TaskHandle) -> Result<Option<TaskRuntimeInfo>, AppError> {
        Ok(self.active_tasks.read().await.get(task_handle).cloned())
    }

    async fn list_tasks_by_batch_id(&self, batch_id: &str) -> Result<Vec<TaskRuntimeInfo>, AppError> {
        let active_tasks_map = self.active_tasks.read().await;
        let mut results = Vec::new();
        for info in active_tasks_map.values() {
            if info.task_definition.batch_id == batch_id {
                results.push(info.clone());
            }
        }
        // 还应考虑队列中的任务
        let queue = self.task_queue.lock().await;
        for item in queue.iter() {
            if item.task.batch_id == batch_id {
                 results.push(TaskRuntimeInfo { // 从ScheduledTaskItem转换
                    handle: item.handle,
                    task_definition: item.task.clone(),
                    status: TaskStatus::Pending, // 队列中的都是Pending
                    current_retry_count: item.current_retry_count,
                    scheduled_at: item.scheduled_at,
                    started_at: None, completed_at: None, error_message: None,
                });
            }
        }
        results.sort_by_key(|info| info.scheduled_at); // 按调度时间排序
        Ok(results)
    }
    
    async fn get_active_task_count(&self) -> Result<usize, AppError> {
        let running_count = self.active_tasks.read().await.values().filter(|info| info.status == TaskStatus::Running).count();
        let pending_count = self.task_queue.lock().await.len();
        Ok(running_count + pending_count)
    }

    fn subscribe_to_task_events(&self) -> broadcast::Receiver<TaskExecutionEvent> {
        self.event_broadcaster.subscribe()
    }

    async fn set_max_concurrent_tasks(&self, limit: usize) -> Result<(), AppError> {
        if limit == 0 {
            return Err(AppError::InvalidInput("最大并发数不能为0".to_string()));
        }
        //当前的 Semaphore 不支持动态调整 permits 数量。
        //一种做法是重新创建一个新的 Semaphore，但这会比较复杂，尤其是在已有任务获取了旧许可时。
        //另一种是，在获取许可的逻辑中，额外检查一个AtomicUsize类型的限制。
        //或者，更简单的是在创建调度器时设置，后续不允许修改，或重启调度器来应用新限制。
        //此处我们仅更新内部的 usize 记录，并在Semaphore创建时使用这个值。
        //如果需要动态调整，需要更复杂的信号量管理或自定义信号量。
        let mut max_tasks_guard = self.max_concurrent_tasks.write().await;
        *max_tasks_guard = limit;
        // 注意：这不会改变现有 Semaphore 的许可数，只影响新创建的 Semaphore 或自定义的许可逻辑。
        // 为了真正动态调整，需要在 self.concurrency_semaphore.acquire_owned() 外面加一层逻辑
        // 或者在创建时就固定。此处仅更新配置值。
        log::warn!("set_max_concurrent_tasks 仅更新配置值，不会动态调整运行中的信号量。如需调整请重启调度器或实现更复杂的信号量管理。新的配置值为: {}", limit);
        Ok(())
    }
    
    async fn get_max_concurrent_tasks(&self) -> Result<usize, AppError> {
        Ok(*self.max_concurrent_tasks.read().await)
    }

    async fn shutdown(&self, timeout_ms: Option<u64>) -> Result<(), AppError> {
        log::info!("开始关闭 AdvancedTaskScheduler...");
        // 1. 发送关闭信号，停止接受新任务和处理循环拾取新任务
        self.shutdown_signal_tx.send(true).map_err(|e| AppError::InternalError(format!("发送关闭信号失败: {}", e)))?;
        
        // 2. 清空任务队列 (可选，取决于是否希望已调度的任务被取消)
        self.task_queue.lock().await.clear();
        log::info!("任务队列已清空。");

        // 3. 等待当前正在运行的任务完成或超时
        let active_handles: Vec<TaskHandle> = self.running_task_handles.read().await.keys().cloned().collect();
        let mut join_handles_to_wait = Vec::new();
        
        let mut running_tasks_guard = self.running_task_handles.write().await;
        for handle in active_handles {
            if let Some(join_handle) = running_tasks_guard.remove(&handle) {
                 join_handles_to_wait.push(join_handle);
            }
        }
        drop(running_tasks_guard);

        if !join_handles_to_wait.is_empty() {
            log::info!("等待 {} 个正在运行的任务完成...", join_handles_to_wait.len());
            let timeout_duration = Duration::from_millis(timeout_ms.unwrap_or(30000)); // 默认30秒超时
            
            for jh in join_handles_to_wait {
                match tokio::time::timeout(timeout_duration, jh).await {
                    Ok(Ok(_)) => log::debug!("一个任务在关闭期间正常完成。"),
                    Ok(Err(e)) => log::warn!("一个任务在关闭期间panic: {:?}", e), // task panicked
                    Err(_) => log::warn!("一个任务在关闭期间超时，可能被强制终止。"), // timeout
                }
            }
        }
        
        // 关闭信号量，以唤醒任何在 acquire_owned() 上阻塞的等待者
        self.concurrency_semaphore.close();

        log::info!("AdvancedTaskScheduler 已成功关闭。");
        Ok(())
    }
}
```

#### 🧪 测试方案 (步骤 3.3)
测试 `AdvancedTaskScheduler` 需要 Mock `IChannelStateManager`, `IConfigurationRepository`, `IRuntimeRepository`, `IPlcCommunicationService` (通过工厂) 和 `ISpecificTestStepExecutor`。

```rust
// src/services/task_scheduling/tests/advanced_task_scheduler_tests.rs (续)
use crate::services::task_scheduling::scheduler::*;
use crate::services::task_scheduling::task_models::*;
use crate::services::task_scheduling::test_executors::ISpecificTestStepExecutor;
use crate::services::state_management::{MockIChannelStateManager, IChannelStateManager}; // Mock
use crate::services::persistence::repositories::configuration_repository::{MockIConfigurationRepository, IConfigurationRepository}; // Mock
use crate::services::persistence::repositories::runtime_repository::{MockIRuntimeRepository, IRuntimeRepository}; // Mock
use crate::services::plc_communication::{MockIPlcCommunicationService, IPlcCommunicationService}; // Mock
use crate::models::enums::{TaskPriority, TaskStatus, SubTestItem, TestResult, OverallTestStatus, ModuleType};
use crate::models::runtime::{ChannelPointDefinition, ChannelTestInstance, TestOutcome};
use std::sync::Arc;
use tokio::sync::Mutex as TokioMutex; // Tokio Mutex for shared test state
use std::collections::HashMap;
use mockall::predicate::*;
use chrono::Utc;


// Mock SpecificTestStepExecutor
mock! {
    MyTestExecutor {}
    #[async_trait::async_trait]
    impl ISpecificTestStepExecutor for MyTestExecutor {
        fn item_type(&self) -> SubTestItem;
        async fn execute(&self, task: &TestTask, instance_snapshot: &ChannelTestInstance, definition: &ChannelPointDefinition, plc_service: Arc<dyn IPlcCommunicationService>) -> Result<TestOutcome, AppError>;
    }
}


#[tokio::test]
async fn test_scheduler_schedule_and_execute_task_successfully() {
    let mut mock_state_manager = MockIChannelStateManager::new();
    let mut mock_config_repo = MockIConfigurationRepository::new();
    let mut mock_runtime_repo = MockIRuntimeRepository::new();
    let mut mock_executor = MockMyTestExecutor::new();

    let task_def_id = "def_sched_test".to_string();
    let task_inst_id = "inst_sched_test".to_string();

    // Executor Mocks
    mock_executor.expect_item_type().return_const(SubTestItem::HardPoint);
    mock_executor.expect_execute()
        .times(1)
        .returning(|_task, _inst, _def, _plc| {
            Ok(TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() })
        });
    
    // Config Repo Mock
    mock_config_repo.expect_get_channel_definition_by_id()
        .with(eq(task_def_id.clone()))
        .times(1)
        .returning(move |_| Ok(Some(ChannelPointDefinition { id: task_def_id.clone(), module_type: ModuleType::AI, ..Default::default() })));

    // Runtime Repo Mock
    mock_runtime_repo.expect_get_channel_instance()
        .with(eq(task_inst_id.clone()))
        .times(1)
        .returning(move |_| Ok(Some(ChannelTestInstance { instance_id: task_inst_id.clone(), ..Default::default() })));

    // State Manager Mock
    mock_state_manager.expect_apply_raw_outcome()
        .withf(move |inst_id, outcome| inst_id == task_inst_id && outcome.result == TestResult::Passed)
        .times(1)
        .returning(|_, _| Ok(Default::default())); // Default StateTransition


    let mut executors_map = HashMap::new();
    executors_map.insert(SubTestItem::HardPoint, Arc::new(mock_executor) as Arc<dyn ISpecificTestStepExecutor>);

    let plc_factory = Arc::new(|| Arc::new(MockIPlcCommunicationService::new()) as Arc<dyn IPlcCommunicationService>);

    let scheduler = AdvancedTaskScheduler::new(
        Arc::new(mock_state_manager),
        Arc::new(mock_config_repo),
        Arc::new(mock_runtime_repo),
        plc_factory,
        executors_map,
        Some(1) // Max 1 concurrent task for predictable testing
    );
    scheduler.clone().start_processing_loop(); // Start the loop

    let task_to_schedule = TestTask {
        task_id: "task1".to_string(), instance_id: task_inst_id.clone(), definition_id: task_def_id.clone(),
        batch_id: "batch1".to_string(), sub_test_item: SubTestItem::HardPoint,
        priority: TaskPriority::Normal, created_at: Utc::now(), max_retries: 0, timeout_ms: None, metadata: None,
    };
    
    let mut event_rx = scheduler.subscribe_to_task_events();
    let handle = scheduler.schedule_task(task_to_schedule).await.unwrap();

    // Wait for events: Scheduled, Started, CompletedSuccessfully
    let mut received_event_types = Vec::new();
    for _ in 0..3 { // Expect 3 events
        match tokio::time::timeout(std::time::Duration::from_secs(5), event_rx.recv()).await {
            Ok(Ok(event)) if event.task_handle == handle => {
                received_event_types.push(event.event_type);
            }
            Ok(Ok(other_event)) => println!("Received event for other task: {:?}", other_event),
            Ok(Err(e)) => panic!("Event recv error: {:?}", e),
            Err(_) => panic!("Timeout waiting for task event"),
        }
    }
    assert!(received_event_types.contains(&TaskEventType::Scheduled));
    assert!(received_event_types.contains(&TaskEventType::Started));
    assert!(received_event_types.contains(&TaskEventType::CompletedSuccessfully));

    let info_opt = scheduler.get_task_runtime_info(&handle).await.unwrap();
    // After completion, task info might be moved from active_tasks.
    // The test needs to be adjusted based on how final status is stored/queried.
    // For this test, the mocks ensure it goes through, and events confirm it.
    
    scheduler.shutdown(Some(100)).await.unwrap();
}


#[tokio::test]
async fn test_scheduler_task_retry_then_success() {
    let mut mock_state_manager = MockIChannelStateManager::new();
    let mut mock_config_repo = MockIConfigurationRepository::new();
    let mut mock_runtime_repo = MockIRuntimeRepository::new();
    let mut mock_executor = MockMyTestExecutor::new();

    let task_def_id = "def_retry".to_string();
    let task_inst_id = "inst_retry".to_string();

    // Executor: first call fails, second call passes
    let attempt_count = Arc::new(TokioMutex::new(0));
    mock_executor.expect_item_type().return_const(SubTestItem::HardPoint);
    mock_executor.expect_execute()
        .times(2) // Expect two calls due to retry
        .returning({
            let ac = attempt_count.clone();
            move |_task, _inst, _def, _plc| {
                let mut count = futures::executor::block_on(ac.lock());
                *count += 1;
                if *count == 1 {
                    Ok(TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Failed, error_message: Some("First attempt failed".to_string()), ..Default::default() })
                } else {
                    Ok(TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() })
                }
            }
        });
    
    mock_config_repo.expect_get_channel_definition_by_id().returning(move |_| Ok(Some(ChannelPointDefinition { id: task_def_id.clone(), module_type: ModuleType::AI, ..Default::default() })));
    mock_runtime_repo.expect_get_channel_instance().returning(move |_| Ok(Some(ChannelTestInstance { instance_id: task_inst_id.clone(), ..Default::default() })));
    // StateManager: expect apply_raw_outcome for the failure, then for the success
    mock_state_manager.expect_apply_raw_outcome().times(2).returning(|_, _| Ok(Default::default()));


    let mut executors_map = HashMap::new();
    executors_map.insert(SubTestItem::HardPoint, Arc::new(mock_executor) as Arc<dyn ISpecificTestStepExecutor>);
    let plc_factory = Arc::new(|| Arc::new(MockIPlcCommunicationService::new()) as Arc<dyn IPlcCommunicationService>);

    let scheduler = AdvancedTaskScheduler::new(
        Arc::new(mock_state_manager), Arc::new(mock_config_repo), Arc::new(mock_runtime_repo),
        plc_factory, executors_map, Some(1)
    );
    scheduler.clone().start_processing_loop();

    let task_to_schedule = TestTask {
        task_id: "task_retry".to_string(), instance_id: task_inst_id.clone(), definition_id: task_def_id.clone(),
        batch_id: "batch_retry".to_string(), sub_test_item: SubTestItem::HardPoint,
        priority: TaskPriority::Normal, created_at: Utc::now(), 
        max_retries: 1, // Allow 1 retry
        timeout_ms: None, metadata: None,
    };
    
    let mut event_rx = scheduler.subscribe_to_task_events();
    let handle = scheduler.schedule_task(task_to_schedule).await.unwrap();

    // Events: Scheduled, Started, AttemptFailed, Started (retry), CompletedSuccessfully
    let mut received_event_types = Vec::new();
    for _ in 0..5 { 
        match tokio::time::timeout(std::time::Duration::from_secs(5), event_rx.recv()).await {
            Ok(Ok(event)) if event.task_handle == handle => { received_event_types.push(event.event_type); }
            _ => break,
        }
    }
    assert!(received_event_types.contains(&TaskEventType::Scheduled));
    assert_eq!(received_event_types.iter().filter(|&&e| e == TaskEventType::Started).count(), 2); // Started twice
    assert!(received_event_types.contains(&TaskEventType::AttemptFailed));
    assert!(received_event_types.contains(&TaskEventType::CompletedSuccessfully));
    
    scheduler.shutdown(Some(100)).await.unwrap();
}


#[tokio::test]
async fn test_scheduler_concurrency_limit() {
    let mut mock_config_repo = MockIConfigurationRepository::new();
    let mut mock_runtime_repo = MockIRuntimeRepository::new();
    let mock_state_manager = Arc::new(MockIChannelStateManager::new()); // Not strictly needed for this test focus

    let active_task_counter = Arc::new(TokioMutex::new(0));
    let max_concurrent_seen = Arc::new(TokioMutex::new(0));
    
    // Mock executor that simulates work and tracks active tasks
    let mut mock_executors: HashMap<SubTestItem, Arc<dyn ISpecificTestStepExecutor>> = HashMap::new();

    for i in 0..5 { // Create 5 types of items to schedule 5 tasks
        let item_type = match i {
            0 => SubTestItem::HardPoint, 1 => SubTestItem::LowAlarm, 2 => SubTestItem::HighAlarm,
            3 => SubTestItem::LowLowAlarm, _ => SubTestItem::HighHighAlarm,
        };
        
        let mut exec = MockMyTestExecutor::new();
        exec.expect_item_type().return_const(item_type);
        exec.expect_execute().returning({
            let counter_clone = active_task_counter.clone();
            let max_seen_clone = max_concurrent_seen.clone();
            move |_task, _inst, _def, _plc| {
                let cc = counter_clone.clone();
                let msc = max_seen_clone.clone();
                async move { // mockall needs this async block for async trait methods
                    let mut current_active = cc.lock().await;
                    *current_active += 1;
                    let mut max_s = msc.lock().await;
                    if *current_active > *max_s {
                        *max_s = *current_active;
                    }
                    drop(current_active); // release lock before sleep
                    drop(max_s);

                    tokio::time::sleep(std::time::Duration::from_millis(200)).await; // Simulate work

                    let mut current_active_after = cc.lock().await;
                    *current_active_after -= 1;
                    drop(current_active_after);
                    Ok(TestOutcome { test_item: item_type, result: TestResult::Passed, ..Default::default() })
                }.tokio_test_scope() // Helper for async blocks in mockall if needed
            }
        });
        mock_executors.insert(item_type, Arc::new(exec));
    }


    mock_config_repo.expect_get_channel_definition_by_id().returning(|id| Ok(Some(ChannelPointDefinition { id: id.to_string(), module_type: ModuleType::AI, ..Default::default() })));
    mock_runtime_repo.expect_get_channel_instance().returning(|id| Ok(Some(ChannelTestInstance { instance_id: id.to_string(), ..Default::default() })));
    // State manager apply_raw_outcome will be called, mock it minimally
    let mut state_manager_mock_for_concurrency = MockIChannelStateManager::new();
    state_manager_mock_for_concurrency.expect_apply_raw_outcome().returning(|_,_| Ok(Default::default()));


    let plc_factory = Arc::new(|| Arc::new(MockIPlcCommunicationService::new()) as Arc<dyn IPlcCommunicationService>);
    let scheduler = AdvancedTaskScheduler::new(
        Arc::new(state_manager_mock_for_concurrency), Arc::new(mock_config_repo), Arc::new(mock_runtime_repo),
        plc_factory, mock_executors, Some(2) // Max 2 concurrent tasks
    );
    scheduler.clone().start_processing_loop();

    let mut event_rx = scheduler.subscribe_to_task_events();
    let mut task_handles = Vec::new();

    let items_to_schedule = [SubTestItem::HardPoint, SubTestItem::LowAlarm, SubTestItem::HighAlarm, SubTestItem::LowLowAlarm, SubTestItem::HighHighAlarm];
    for (i, &item) in items_to_schedule.iter().enumerate() {
        let task = TestTask {
            task_id: format!("task_conc_{}", i), instance_id: format!("inst_conc_{}", i), definition_id: format!("def_conc_{}", i),
            batch_id: "batch_conc".to_string(), sub_test_item: item,
            priority: TaskPriority::Normal, created_at: Utc::now(), max_retries: 0, timeout_ms: None, metadata: None,
        };
        task_handles.push(scheduler.schedule_task(task).await.unwrap());
    }

    // Wait for all tasks to complete (5 tasks * 1 event type (CompletedSuccessfully))
    let