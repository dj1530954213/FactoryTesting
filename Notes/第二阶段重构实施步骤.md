# FAT_TEST ç³»ç»Ÿé‡æ„è¯¦ç»†å®æ–½æ­¥éª¤

## ğŸ“‹ é‡æ„å®æ–½æ¦‚è§ˆ

### ğŸ¯ å®æ–½åŸåˆ™
1.  **åˆ†é˜¶æ®µå®æ–½**: ç¡®ä¿æ¯ä¸ªé˜¶æ®µå¯ç‹¬ç«‹éªŒè¯ï¼Œé™ä½é£é™©ã€‚
2.  **å‘åå…¼å®¹**: æ–°ç»„ä»¶åœ¨è®¾è®¡ä¸Šåº”è€ƒè™‘é€æ­¥æ›¿æ¢æ—§å®ç°çš„å¯èƒ½æ€§ã€‚
3.  **æµ‹è¯•é©±åŠ¨**: æ¯ä¸ªæ ¸å¿ƒç»„ä»¶å’Œä¸šåŠ¡é€»è¾‘éƒ½åº”æœ‰å®Œæ•´çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•è¦†ç›–ã€‚
4.  **æŒç»­éªŒè¯**: æ¯ä¸ªé˜¶æ®µå®Œæˆåè¿›è¡Œä¸¥æ ¼çš„é›†æˆæµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•ã€‚
5.  **éµå¾ªè§„èŒƒ**: ä¸¥æ ¼éµå®ˆé¡¹ç›® `mainrules` ä¸­å®šä¹‰çš„æŠ€æœ¯æ ˆã€æ¶æ„è®¾è®¡å’Œä»£ç è§„èŒƒã€‚

### ğŸ—“ï¸ å®æ–½è®¡åˆ’ (4ä¸ªé˜¶æ®µ)

#### Phase 1: æ•°æ®è®¿é—®å±‚é‡æ„ (Repository Layer)
*   **ç›®æ ‡**: å»ºç«‹ç»Ÿä¸€ã€ç±»å‹å®‰å…¨ã€å¼‚æ­¥çš„æ•°æ®è®¿é—®æ¥å£ï¼Œå°†æ•°æ®å­˜å‚¨ç»†èŠ‚ä¸ä¸šåŠ¡é€»è¾‘è§£è€¦ã€‚å®ç°é…ç½®æ•°æ®ã€è¿è¡Œæ—¶æ•°æ®å’ŒæŒä¹…åŒ–æ•°æ®çš„åˆ†ç¦»ç®¡ç†ã€‚
*   **å·¥æœŸ**: 2-3å‘¨
*   **å…³é”®äº§å‡º**:
    *   `IRepository` åŸºç¡€æ¥å£ã€‚
    *   `IConfigurationRepository` æ¥å£å’Œå†…å­˜/Excelå®ç°ã€‚
    *   `IRuntimeRepository` æ¥å£å’Œå†…å­˜å®ç°ã€‚
    *   `IPersistentRepository` æ¥å£å’ŒSQLite (`sqlx`) åŠå†…å­˜å®ç°ã€‚
    *   å®Œæ•´çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ã€‚

#### Phase 2: çŠ¶æ€ç®¡ç†å™¨é‡æ„ (State Management)
*   **ç›®æ ‡**: å»ºç«‹ä¸¥æ ¼ã€ä¸€è‡´ä¸”äº‹ä»¶é©±åŠ¨çš„ `ChannelTestInstance` çŠ¶æ€ç®¡ç†æœºåˆ¶ï¼Œéµå¾ª `FAT-CSM-001` å’Œ `FAT-CSM-002` è§„åˆ™ã€‚
*   **å·¥æœŸ**: 1-2å‘¨
*   **å…³é”®äº§å‡º**:
    *   `IChannelStateManager` æ¥å£ã€‚
    *   `EnhancedChannelStateManager` å®ç°ï¼Œé›†æˆ `IRuntimeRepository`ã€‚
    *   åŸºäº `tokio::sync::broadcast` çš„çŠ¶æ€å˜æ›´äº‹ä»¶ç³»ç»Ÿ (`FAT-EVT-001`)ã€‚
    *   è¯¦ç»†çš„çŠ¶æ€è½¬æ¢è§„åˆ™ (`StateTransitionRules`)ã€‚
    *   å®Œæ•´çš„å•å…ƒæµ‹è¯•ã€‚

#### Phase 3: ä»»åŠ¡è°ƒåº¦å™¨ä¸æ‰§è¡Œå™¨é‡æ„ (Task Scheduling & Execution)
*   **ç›®æ ‡**: è®¾è®¡å’Œå®ç°ä¸€ä¸ªå¥å£®ã€é«˜æ•ˆã€å¯æ§çš„æµ‹è¯•ä»»åŠ¡è°ƒåº¦ä¸æ‰§è¡Œå¼•æ“ï¼Œéµå¾ª `FAT-TTM-001` å’Œ `FAT-CTK-001` è§„åˆ™ã€‚
*   **å·¥æœŸ**: 2-3å‘¨
*   **å…³é”®äº§å‡º**:
    *   `ITaskScheduler` æ¥å£ã€‚
    *   `AdvancedTaskScheduler` å®ç°ï¼Œæ”¯æŒå¹¶å‘æ§åˆ¶ã€ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
    *   `ITestExecutor` æ¥å£ã€‚
    *   é’ˆå¯¹æ ¸å¿ƒ `SubTestItem` (å¦‚ `HardPoint`) çš„ `ISpecificTestStepExecutor` å®ç°ã€‚
    *   ä»»åŠ¡äº‹ä»¶ç³»ç»Ÿã€‚
    *   å®Œæ•´çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ã€‚

#### Phase 4: åº”ç”¨æœåŠ¡å±‚ä¸Tauriæ¥å£é‡æ„ (Application Services & Tauri Commands)
*   **ç›®æ ‡**: é‡æ„åº”ç”¨æœåŠ¡å±‚ï¼Œé‡‡ç”¨æœåŠ¡ç»„åˆæ¨¡å¼å°è£…ä¸šåŠ¡æµç¨‹ã€‚ä¼˜åŒ–TauriæŒ‡ä»¤ï¼Œç¡®ä¿å‰åç«¯é€šä¿¡é«˜æ•ˆä¸”ç±»å‹å®‰å…¨ã€‚
*   **å·¥æœŸ**: 2-3å‘¨
*   **å…³é”®äº§å‡º**:
    *   `ITestOrchestrationService` ç­‰æ ¸å¿ƒåº”ç”¨æœåŠ¡æ¥å£åŠå®ç°ã€‚
    *   `IDataManagementService` å’Œ `ISystemManagementService` æ¥å£åŠå®ç°ï¼ˆåŸºäºç°æœ‰åŠŸèƒ½ä¼˜åŒ–ï¼‰ã€‚
    *   é‡æ„åçš„Tauri `#[tauri::command]` å‡½æ•°ï¼Œç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæ•°æ®æ ¼å¼ã€‚
    *   å‰ç«¯ `TauriApiService` çš„å¯¹åº”è°ƒæ•´ã€‚
    *   ç«¯åˆ°ç«¯æµ‹è¯•ã€‚

---

## ğŸš€ Phase 1: æ•°æ®è®¿é—®å±‚é‡æ„ (Repository Layer)

### ğŸ“Œ é‡æ„åŸå›  (Phase 1)
å½“å‰ç³»ç»Ÿä¸­ï¼Œæ•°æ®è®¿é—®é€»è¾‘å¯èƒ½æ•£å¸ƒåœ¨ä¸åŒæ¨¡å—ï¼Œæˆ–è€…ä¸ä¸šåŠ¡é€»è¾‘è€¦åˆè¾ƒæ·±ã€‚ç¼ºä¹ç»Ÿä¸€çš„æ•°æ®è®¿é—®æŠ½è±¡å±‚ä¼šå¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š
*   **éš¾ä»¥ç»´æŠ¤å’Œæ›¿æ¢å­˜å‚¨å®ç°**: å¦‚æœéœ€è¦ä»JSONæ–‡ä»¶åˆ‡æ¢åˆ°æ•°æ®åº“ï¼Œæˆ–æ›´æ¢æ•°æ®åº“ç±»å‹ï¼Œå°†æ¶‰åŠå¤§é‡ä»£ç ä¿®æ”¹ã€‚
*   **æµ‹è¯•å›°éš¾**: ä¸šåŠ¡é€»è¾‘ç›´æ¥ä¾èµ–å…·ä½“æ•°æ®å­˜å‚¨å®ç°ï¼Œéš¾ä»¥è¿›è¡Œå•å…ƒæµ‹è¯•å’ŒMockã€‚
*   **æ•°æ®ä¸€è‡´æ€§é£é™©**: ä¸åŒæ¨¡å—å¯èƒ½ä»¥ä¸åŒæ–¹å¼æ“ä½œæ•°æ®ï¼Œå¢åŠ æ•°æ®ä¸ä¸€è‡´çš„é£é™©ã€‚
*   **ä»£ç é‡å¤**: ç±»ä¼¼çš„æ•°æ®æŸ¥è¯¢å’Œæ“ä½œé€»è¾‘å¯èƒ½åœ¨å¤šå¤„é‡å¤ã€‚

é€šè¿‡å¼•å…¥Repositoryæ¨¡å¼ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæŠ½è±¡å±‚æ¥å°è£…æ•°æ®è®¿é—®çš„ç»†èŠ‚ï¼Œä½¿å¾—ä¸Šå±‚ä¸šåŠ¡é€»è¾‘åªä¾èµ–äºæ¥å£ï¼Œä»è€Œè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæé«˜ç³»ç»Ÿçš„æ¨¡å—åŒ–ã€å¯æµ‹è¯•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

### æ­¥éª¤ 1.1: åˆ›å»ºRepositoryåŸºç¡€æ¥å£

#### ğŸ¯ ç›®æ ‡
å»ºç«‹é€šç”¨çš„æ•°æ®è®¿é—®æŠ½è±¡ `IRepository<T, K>`ï¼Œä¸ºæ‰€æœ‰æ•°æ®å®ä½“çš„åŸºæœ¬CRUDæ“ä½œæä¾›ä¸€è‡´çš„æ¥å£ã€‚åŒæ—¶å®šä¹‰ç»Ÿä¸€çš„æŸ¥è¯¢æ¡ä»¶ç»“æ„å’ŒRepositoryå±‚é”™è¯¯ç±»å‹ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.1.1 åˆ›å»ºåŸºç¡€Repositoryæ¥å£ (`IRepository`)
```rust
// src/services/persistence/repositories/base.rs
// æˆ–è€… src/repositories/base.rs (æ ¹æ®æ‚¨çš„é¡¹ç›®ç»“æ„è°ƒæ•´)
use async_trait::async_trait;
use serde::{Serialize, de::DeserializeOwned};
use std::fmt::Debug;
use crate::utils::error::AppError; // ä½¿ç”¨é¡¹ç›®ç»Ÿä¸€çš„ AppError

/// é€šç”¨æŸ¥è¯¢æ¡ä»¶
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryCriteria {
    pub filters: Vec<Filter>,
    pub sort_by: Option<SortDescriptor>,
    pub limit: Option<usize>,
    pub offset: Option<usize>,
}

/// è¿‡æ»¤æ¡ä»¶
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Filter {
    pub field: String,
    pub operator: FilterOperator,
    pub value: FilterValue,
}

/// è¿‡æ»¤æ“ä½œç¬¦
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum FilterOperator {
    Equal,
    NotEqual,
    GreaterThan,
    LessThan,
    GreaterThanOrEqual,
    LessThanOrEqual,
    Contains,
    In,
    IsNull,
    IsNotNull,
}

/// è¿‡æ»¤å€¼ (ä½¿ç”¨serde_json::Valueä»¥æ”¯æŒå¤šç§ç±»å‹)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FilterValue {
    String(String),
    Number(f64), // å¯ä»¥ç”¨ serde_json::Number æ›´çµæ´»
    Boolean(bool),
    List(Vec<String>), // å¯¹äº IN æ“ä½œç¬¦ï¼Œå€¼å¯ä»¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
    Json(serde_json::Value), // é€šç”¨JSONå€¼
}

/// æ’åºæè¿°ç¬¦
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SortDescriptor {
    pub field: String,
    pub direction: SortDirection,
}

/// æ’åºæ–¹å‘
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SortDirection {
    Ascending,
    Descending,
}

impl QueryCriteria {
    pub fn new() -> Self {
        Self {
            filters: Vec::new(),
            sort_by: None,
            limit: None,
            offset: None,
        }
    }

    pub fn add_filter(mut self, field: &str, operator: FilterOperator, value: FilterValue) -> Self {
        self.filters.push(Filter {
            field: field.to_string(),
            operator,
            value,
        });
        self
    }

    pub fn set_sort(mut self, field: &str, direction: SortDirection) -> Self {
        self.sort_by = Some(SortDescriptor {
            field: field.to_string(),
            direction,
        });
        self
    }

    pub fn set_limit(mut self, limit: usize) -> Self {
        self.limit = Some(limit);
        self
    }

    pub fn set_offset(mut self, offset: usize) -> Self {
        self.offset = Some(offset);
        self
    }
}


/// åŸºç¡€Repositoryæ¥å£å®šä¹‰
/// T: å®ä½“ç±»å‹, K: å®ä½“ä¸»é”®ç±»å‹
#[async_trait]
pub trait IRepository<T, K>: Send + Sync
where
    T: Send + Sync + Clone + Debug + Serialize + DeserializeOwned,
    K: Send + Sync + Clone + Debug + Serialize + DeserializeOwned,
{
    /// æ ¹æ®ä¸»é”®è·å–å•ä¸ªå®ä½“
    async fn get_by_id(&self, id: &K) -> Result<Option<T>, AppError>;

    /// è·å–æ‰€æœ‰å®ä½“
    async fn list_all(&self) -> Result<Vec<T>, AppError>;

    /// æ ¹æ®æŸ¥è¯¢æ¡ä»¶è·å–å®ä½“åˆ—è¡¨
    async fn query(&self, criteria: QueryCriteria) -> Result<Vec<T>, AppError>;
    
    /// æ ¹æ®æŸ¥è¯¢æ¡ä»¶ç»Ÿè®¡å®ä½“æ•°é‡
    async fn count(&self, criteria: QueryCriteria) -> Result<i64, AppError>;

    /// åˆ›å»ºæ–°å®ä½“
    async fn create(&self, entity: &T) -> Result<T, AppError>;

    /// æ›´æ–°ç°æœ‰å®ä½“
    async fn update(&self, entity: &T) -> Result<T, AppError>;

    /// æ ¹æ®ä¸»é”®åˆ é™¤å®ä½“
    async fn delete_by_id(&self, id: &K) -> Result<bool, AppError>;

    /// æ£€æŸ¥å…·æœ‰ç»™å®šä¸»é”®çš„å®ä½“æ˜¯å¦å­˜åœ¨
    async fn exists_by_id(&self, id: &K) -> Result<bool, AppError>;
}
```
**æ³¨æ„**: `AppError` åº”åŒ…å«é€‚ç”¨äºRepositoryæ“ä½œçš„é”™è¯¯å˜ä½“ï¼Œå¦‚ `AppError::RecordNotFound`, `AppError::PersistenceError(String)`, `AppError::InvalidInput(String)` ç­‰ã€‚è¿™äº›åº”åœ¨ `src/utils/error.rs` ä¸­å®šä¹‰ã€‚

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 1.1)
ç”±äº `IRepository` æ˜¯ä¸€ä¸ªé€šç”¨æ¥å£ï¼Œå…¶æµ‹è¯•å°†åœ¨å…·ä½“å®ç°è¯¥æ¥å£çš„Repositoryï¼ˆå¦‚ `MemoryConfigurationRepository` æˆ– `SqlitePersistentRepository`ï¼‰ä¸­è¿›è¡Œã€‚è¿™é‡Œå¯ä»¥è§„åˆ’ä¸€ä¸ªé€šç”¨çš„æµ‹è¯•å¥—ä»¶è¾…åŠ©traitï¼Œä¾›å…·ä½“å®ç°ä½¿ç”¨ã€‚

```rust
// src/services/persistence/repositories/tests/repository_test_suite.rs
// æˆ–è€… src/repositories/tests/repository_test_suite.rs
#[async_trait::async_trait]
pub trait RepositoryTestSuite<T, K, R>
where
    T: Send + Sync + Clone + Debug + PartialEq + Serialize + DeserializeOwned + Default, // Default ç”¨äºè½»æ¾åˆ›å»ºå®ä¾‹
    K: Send + Sync + Clone + Debug + Serialize + DeserializeOwned + PartialEq,
    R: IRepository<T, K> + Send + Sync,
{
    /// åˆ›å»ºRepositoryçš„å®ä¾‹ä»¥ä¾›æµ‹è¯•
    async fn create_repository() -> R;

    /// åˆ›å»ºä¸€ä¸ªæœ‰æ•ˆçš„æµ‹è¯•å®ä½“ï¼Œä¸åŒ…å«ID (IDåº”ç”±createæ–¹æ³•ç”Ÿæˆæˆ–æ‰‹åŠ¨è®¾ç½®)
    fn create_sample_entity_to_create() -> T;
    
    /// è·å–å·²åˆ›å»ºå®ä½“çš„ID
    fn get_id_from_entity(entity: &T) -> K;
    
    /// ä¿®æ”¹å®ä½“ä»¥ä¾›æ›´æ–°æµ‹è¯•
    fn modify_entity_for_update(entity: &mut T);

    async fn run_all_tests() {
        Self::test_create_and_get().await;
        Self::test_update_entity().await;
        Self::test_delete_entity().await;
        Self::test_list_all_and_query().await;
        Self::test_exists_by_id().await;
        Self::test_count().await;
        Self::test_get_non_existent().await;
        Self::test_delete_non_existent().await;
    }

    async fn test_create_and_get() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();

        // æµ‹è¯•åˆ›å»º
        let created_entity = repo.create(&sample_entity).await.expect("åˆ›å»ºå®ä½“å¤±è´¥");
        let entity_id = Self::get_id_from_entity(&created_entity);

        // æµ‹è¯•é€šè¿‡IDè·å–
        let fetched_entity = repo.get_by_id(&entity_id).await.expect("é€šè¿‡IDè·å–å®ä½“å¤±è´¥").expect("å®ä½“æœªæ‰¾åˆ°");
        assert_eq!(created_entity, fetched_entity, "åˆ›å»ºå’Œè·å–çš„å®ä½“åº”è¯¥ç›¸åŒ");
    }

    async fn test_update_entity() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();
        let mut created_entity = repo.create(&sample_entity).await.expect("åˆ›å»ºå®ä½“å¤±è´¥");
        let entity_id = Self::get_id_from_entity(&created_entity);

        Self::modify_entity_for_update(&mut created_entity);
        let updated_entity = repo.update(&created_entity).await.expect("æ›´æ–°å®ä½“å¤±è´¥");
        assert_eq!(created_entity, updated_entity, "æ›´æ–°åçš„å®ä½“ä¸é¢„æœŸä¸ç¬¦");

        let fetched_after_update = repo.get_by_id(&entity_id).await.expect("è·å–æ›´æ–°åå®ä½“å¤±è´¥").expect("æ›´æ–°åå®ä½“æœªæ‰¾åˆ°");
        assert_eq!(updated_entity, fetched_after_update, "è·å–çš„æ›´æ–°åå®ä½“ä¸é¢„æœŸä¸ç¬¦");
    }

    async fn test_delete_entity() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();
        let created_entity = repo.create(&sample_entity).await.expect("åˆ›å»ºå®ä½“å¤±è´¥");
        let entity_id = Self::get_id_from_entity(&created_entity);

        let deleted = repo.delete_by_id(&entity_id).await.expect("åˆ é™¤å®ä½“å¤±è´¥");
        assert!(deleted, "åˆ é™¤æ“ä½œåº”è¯¥è¿”å›true");

        let should_be_none = repo.get_by_id(&entity_id).await.expect("åˆ é™¤åè·å–å®ä½“å¤±è´¥");
        assert!(should_be_none.is_none(), "åˆ é™¤åå®ä½“åº”è¯¥ä¸å­˜åœ¨");
    }
    
    async fn test_list_all_and_query() {
        let repo = Self::create_repository().await;
        // æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§æ•°æ®æˆ–ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•æ•°æ®åº“/è¡¨
        
        let mut entity1 = Self::create_sample_entity_to_create();
        // ä¸ºäº†æŸ¥è¯¢ï¼Œå¯èƒ½éœ€è¦ç»™å®ä½“è®¾ç½®ä¸€äº›å¯åŒºåˆ†çš„å­—æ®µå€¼
        // (å‡è®¾Tæœ‰å¯ä¾›æŸ¥è¯¢çš„å­—æ®µï¼Œæˆ–è€…QueryCriteriaæ”¯æŒç‰¹æ®ŠæŸ¥è¯¢)
        repo.create(&entity1).await.expect("åˆ›å»ºå®ä½“1å¤±è´¥");
        
        let mut entity2 = Self::create_sample_entity_to_create();
        Self::modify_entity_for_update(&mut entity2); // ä½¿å…¶ä¸entity1ä¸åŒ
        repo.create(&entity2).await.expect("åˆ›å»ºå®ä½“2å¤±è´¥");

        let all_entities = repo.list_all().await.expect("åˆ—å‡ºæ‰€æœ‰å®ä½“å¤±è´¥");
        assert!(all_entities.len() >= 2, "è‡³å°‘åº”æœ‰ä¸¤ä¸ªå®ä½“");

        // æ­¤å¤„éœ€è¦å…·ä½“çš„æŸ¥è¯¢æ¡ä»¶ï¼Œå–å†³äºå®ä½“Tçš„ç»“æ„å’Œæµ‹è¯•ç›®æ ‡
        // ä¾‹å¦‚ï¼š let criteria = QueryCriteria::new().add_filter("some_field", FilterOperator::Equal, FilterValue::String("value1".to_string()));
        // let queried_entities = repo.query(criteria).await.expect("æŸ¥è¯¢å®ä½“å¤±è´¥");
        // assert_eq!(queried_entities.len(), 1);
    }

    async fn test_exists_by_id() {
        let repo = Self::create_repository().await;
        let sample_entity = Self::create_sample_entity_to_create();
        let created_entity = repo.create(&sample_entity).await.expect("åˆ›å»ºå®ä½“å¤±è´¥");
        let entity_id = Self::get_id_from_entity(&created_entity);
        
        let exists = repo.exists_by_id(&entity_id).await.expect("æ£€æŸ¥å­˜åœ¨æ€§å¤±è´¥");
        assert!(exists, "å·²åˆ›å»ºçš„å®ä½“åº”è¯¥å­˜åœ¨");

        // å‡è®¾ä¸€ä¸ªä¸å­˜åœ¨çš„ID
        // let non_existent_id: K = ...; // éœ€è¦ä¸€ç§æ–¹æ³•åˆ›å»ºæˆ–è·å–ä¸€ä¸ªä¿è¯ä¸å­˜åœ¨çš„Kç±»å‹ID
        // let not_exists = repo.exists_by_id(&non_existent_id).await.expect("æ£€æŸ¥ä¸å­˜åœ¨æ€§å¤±è´¥");
        // assert!(!not_exists, "ä¸å­˜åœ¨çš„å®ä½“ä¸åº”è¯¥å­˜åœ¨");
    }
    
    async fn test_count() {
        let repo = Self::create_repository().await;
        // æ¸…ç†æˆ–ç¡®ä¿ç¯å¢ƒå¹²å‡€
        let initial_count = repo.count(QueryCriteria::new()).await.expect("åˆå§‹è®¡æ•°å¤±è´¥");

        let entity1 = Self::create_sample_entity_to_create();
        repo.create(&entity1).await.expect("åˆ›å»ºå®ä½“1å¤±è´¥");
        let count_after_one = repo.count(QueryCriteria::new()).await.expect("åˆ›å»ºåè®¡æ•°å¤±è´¥");
        assert_eq!(count_after_one, initial_count + 1, "è®¡æ•°åº”å¢åŠ 1");

        // æ­¤å¤„å¯ä»¥æ·»åŠ å¸¦æ¡ä»¶çš„è®¡æ•°æµ‹è¯•
    }
    
    async fn test_get_non_existent() {
        let repo = Self::create_repository().await;
        // å‡è®¾ä¸€ä¸ªä¸å­˜åœ¨çš„ID
        // let non_existent_id: K = ...;
        // let result = repo.get_by_id(&non_existent_id).await.expect("è·å–ä¸å­˜åœ¨å®ä½“å¤±è´¥");
        // assert!(result.is_none(), "è·å–ä¸å­˜åœ¨çš„å®ä½“åº”è¿”å›None");
    }

    async fn test_delete_non_existent() {
        let repo = Self::create_repository().await;
        // å‡è®¾ä¸€ä¸ªä¸å­˜åœ¨çš„ID
        // let non_existent_id: K = ...;
        // let deleted = repo.delete_by_id(&non_existent_id).await.expect("åˆ é™¤ä¸å­˜åœ¨å®ä½“å¤±è´¥");
        // assert!(!deleted, "åˆ é™¤ä¸å­˜åœ¨çš„å®ä½“åº”è¿”å›false");
    }
}
```

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 1.1)
1.  `IRepository` æ¥å£åŠå…¶ç›¸å…³çš„ `QueryCriteria`, `Filter`, `SortDescriptor` ç­‰è¾…åŠ©ç»“æ„åœ¨ä»£ç åº“ä¸­å®šä¹‰å®Œæ¯•ã€‚
2.  `AppError` ä¸­å·²åŒ…å« Repository æ“ä½œå¯èƒ½äº§ç”Ÿçš„é”™è¯¯ç±»å‹ (å¦‚ `RecordNotFound`, `PersistenceError`)ã€‚
3.  `RepositoryTestSuite` è¾…åŠ© trait å®šä¹‰å®Œæˆï¼Œå¯ä¾›åç»­å…·ä½“ Repository å®ç°ä½¿ç”¨ã€‚
4.  ä»£ç é€šè¿‡ç¼–è¯‘ï¼Œç¬¦åˆé¡¹ç›®ä»£ç è§„èŒƒã€‚

---

### æ­¥éª¤ 1.2: åˆ›å»ºé…ç½®æ•°æ®Repository (`IConfigurationRepository`)

#### ğŸ¯ ç›®æ ‡
å®ç°ä¸“é—¨ç®¡ç†é…ç½®æ•°æ®çš„Repositoryï¼ŒåŒ…æ‹¬é€šé“ç‚¹ä½å®šä¹‰ (`ChannelPointDefinition`) å’Œæµ‹è¯•å‚æ•°é›† (`TestParameterSet`)ã€‚æä¾›ä»Excelå¯¼å…¥/å¯¼å‡ºç‚¹ä½å®šä¹‰çš„åŠŸèƒ½ï¼Œä»¥åŠé…ç½®é›†çš„ç®¡ç†ã€‚æ­¤Repositoryå°†ä¸»è¦ä½¿ç”¨å†…å­˜å®ç°ï¼Œå› ä¸ºé…ç½®æ•°æ®é€šå¸¸åœ¨åº”ç”¨å¯åŠ¨æ—¶åŠ è½½ä¸”å˜åŠ¨ä¸é¢‘ç¹ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.2.1 å®šä¹‰é…ç½®Repositoryæ¥å£ (`IConfigurationRepository`)
```rust
// src/services/persistence/repositories/configuration_repository.rs
// æˆ–è€… src/repositories/configuration_repository.rs
use async_trait::async_trait;
use std::collections::HashMap;
use crate::models::config::{ChannelPointDefinition, TestParameterSet, ExcelImportConfig}; // å‡è®¾è¿™äº›å·²åœ¨models::configä¸­å®šä¹‰
use crate::models::enums::ModuleType; // å‡è®¾å·²å®šä¹‰
use crate::utils::error::AppError;
use super::base::QueryCriteria; // ä» Step 1.1 å¼•å…¥

/// éªŒè¯é—®é¢˜è¯¦æƒ…
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct ValidationIssue {
    pub severity: ValidationSeverity,
    pub message: String,
    pub field: Option<String>,    // ä¾‹å¦‚ "tag", "range_lower_limit"
    pub row_number: Option<usize>, // Excelå¯¼å…¥æ—¶ä½¿ç”¨
    pub suggestion: Option<String>,
}

/// éªŒè¯ä¸¥é‡çº§åˆ«
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum ValidationSeverity {
    Error,   // é˜»æ­¢å¯¼å…¥æˆ–ä¿å­˜
    Warning, // å¯å¯¼å…¥ä½†æç¤ºç”¨æˆ·
    Info,
}

/// é…ç½®æ•°æ®ä¸€è‡´æ€§æŠ¥å‘Š
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConsistencyReport {
    pub total_definitions_checked: usize,
    pub duplicate_tags: Vec<String>, // é‡å¤çš„ä½å·
    pub issues: Vec<ValidationIssue>, // å…¶ä»–ä¸€è‡´æ€§é—®é¢˜
}

/// é…ç½®æ•°æ®Repositoryæ¥å£
#[async_trait]
pub trait IConfigurationRepository: Send + Sync {
    // å•ä¸ªç‚¹ä½å®šä¹‰ç®¡ç†
    async fn get_channel_definition_by_id(&self, id: &str) -> Result<Option<ChannelPointDefinition>, AppError>;
    async fn get_channel_definition_by_tag(&self, tag: &str) -> Result<Option<ChannelPointDefinition>, AppError>;
    async fn save_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError>; // è¿”å›ä¿å­˜åçš„å®ä½“ (å¯èƒ½åŒ…å«ç”Ÿæˆçš„ID)
    async fn update_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError>;
    async fn delete_channel_definition(&self, id: &str) -> Result<bool, AppError>;
    async fn list_all_channel_definitions(&self) -> Result<Vec<ChannelPointDefinition>, AppError>;
    async fn query_channel_definitions(&self, criteria: QueryCriteria) -> Result<Vec<ChannelPointDefinition>, AppError>;

    // æ‰¹é‡æ“ä½œç‚¹ä½å®šä¹‰
    async fn save_channel_definitions_batch(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ChannelPointDefinition>, AppError>;
    async fn delete_channel_definitions_batch(&self, ids: &[String]) -> Result<usize, AppError>; // è¿”å›åˆ é™¤çš„æ•°é‡

    // Excel å¯¼å…¥/å¯¼å‡º
    async fn import_definitions_from_excel(&self, file_path: &str, import_config: &ExcelImportConfig) -> Result<(Vec<ChannelPointDefinition>, Vec<ValidationIssue>), AppError>;
    async fn export_definitions_to_excel(&self, definitions: &[ChannelPointDefinition], file_path: &str) -> Result<(), AppError>;

    // é…ç½®é›†ç®¡ç† (ä¾‹å¦‚ï¼Œä¸€ä¸ªç‰¹å®šé¡¹ç›®æˆ–äº§å“å‹å·çš„ç‚¹ä½è¡¨)
    async fn save_configuration_set(&self, name: &str, definition_ids: &[String]) -> Result<(), AppError>;
    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, AppError>; // è¿”å›è¯¥é…ç½®é›†åŒ…å«çš„æ‰€æœ‰ç‚¹ä½å®šä¹‰
    async fn list_configuration_sets(&self) -> Result<Vec<String>, AppError>; // è¿”å›æ‰€æœ‰é…ç½®é›†åç§°
    async fn delete_configuration_set(&self, name: &str) -> Result<bool, AppError>;
    async fn add_definition_to_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError>;
    async fn remove_definition_from_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError>;

    // æµ‹è¯•å‚æ•°ç®¡ç† (ä¾‹å¦‚ï¼ŒAIæ¨¡å—çš„æµ‹è¯•å®¹å·®ã€æµ‹è¯•ç‚¹)
    async fn get_test_parameters(&self, module_type: ModuleType) -> Result<Option<TestParameterSet>, AppError>;
    async fn save_test_parameters(&self, module_type: ModuleType, params: &TestParameterSet) -> Result<(), AppError>;
    async fn list_all_test_parameters(&self) -> Result<HashMap<ModuleType, TestParameterSet>, AppError>;

    // æ•°æ®éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥
    async fn validate_definitions_list(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ValidationIssue>, AppError>;
    async fn check_overall_consistency(&self) -> Result<ConsistencyReport, AppError>;
}
```
**æ³¨æ„**: `ChannelPointDefinition`, `TestParameterSet`, `ExcelImportConfig` ç­‰ç»“æ„ä½“éœ€è¦åœ¨ `src/models/config.rs` æˆ–ç±»ä¼¼æ¨¡å—ä¸­è¯¦ç»†å®šä¹‰ã€‚`ExcelImportConfig` å¯ä»¥åŒ…å«å¦‚å·¥ä½œè¡¨åç§°ã€èµ·å§‹è¡Œã€åˆ—æ˜ å°„ç­‰é…ç½®ã€‚

##### 1.2.2 å®ç°å†…å­˜é…ç½®Repository (`MemoryConfigurationRepository`)
```rust
// src/services/persistence/repositories/memory_configuration_repository.rs
// æˆ–è€… src/repositories/memory_configuration_repository.rs
use super::configuration_repository::*;
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;
use crate::models::enums::PointDataType; // å‡è®¾å·²å®šä¹‰

pub struct MemoryConfigurationRepository {
    // ä½¿ç”¨IDä½œä¸ºä¸»é”®
    definitions_by_id: Arc<RwLock<HashMap<String, ChannelPointDefinition>>>,
    // è¾…åŠ©ç´¢å¼•ï¼Œä½å· -> ID
    definitions_by_tag: Arc<RwLock<HashMap<String, String>>>,
    // é…ç½®é›†åç§° -> ç‚¹ä½IDåˆ—è¡¨
    configuration_sets: Arc<RwLock<HashMap<String, Vec<String>>>>,
    // æ¨¡å—ç±»å‹ -> æµ‹è¯•å‚æ•°
    test_parameters: Arc<RwLock<HashMap<ModuleType, TestParameterSet>>>,
}

impl MemoryConfigurationRepository {
    pub fn new() -> Self {
        Self {
            definitions_by_id: Arc::new(RwLock::new(HashMap::new())),
            definitions_by_tag: Arc::new(RwLock::new(HashMap::new())),
            configuration_sets: Arc::new(RwLock::new(HashMap::new())),
            test_parameters: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    // è¾…åŠ©å‡½æ•°ï¼Œç”¨äºé¢„å¡«å……æµ‹è¯•æ•°æ®
    pub async fn _populate_test_data(&self) {
        let def1 = ChannelPointDefinition {
            id: Uuid::new_v4().to_string(),
            tag: "AI_TEMP_001".to_string(),
            variable_name: "ååº”é‡œæ¸©åº¦".to_string(),
            variable_description: "ç¬¬ä¸€ååº”é‡œæ¸©åº¦ç›‘æµ‹ç‚¹".to_string(),
            module_type: ModuleType::AI,
            data_type: PointDataType::Float,
            plc_communication_address: "DB100.DBD0".to_string(),
            range_lower_limit: Some(0.0),
            range_upper_limit: Some(200.0),
            engineering_unit: Some("C".to_string()),
            // ... å…¶ä»–å­—æ®µæ ¹æ® ChannelPointDefinition è¡¥å…¨
            station_name: "Station A".to_string(),
            module_name: "AI_Module_1".to_string(),
            channel_tag_in_module: "CH1".to_string(),
            power_supply_type: "24VDC".to_string(),
            wire_system: "2-wire".to_string(),
            plc_absolute_address: None,
            sll_set_value: None,
            sll_set_point_address: None,
            sll_feedback_address: None,
            sl_set_value: None,
            sl_set_point_address: None,
            sl_feedback_address: None,
            sh_set_value: None,
            sh_set_point_address: None,
            sh_feedback_address: None,
            shh_set_value: None,
            shh_set_point_address: None,
            shh_feedback_address: None,
            maintenance_value_set_point_address: None,
            maintenance_enable_switch_point_address: None,
            access_property: Some("RO".to_string()),
            save_history: Some(true),
            power_failure_protection: Some(false),
            test_rig_plc_address: None,
        };
        self.save_channel_definition(&def1).await.unwrap();

        let params_ai = TestParameterSet {
            default_range: Some((0.0, 100.0)),
            test_points: vec![0.0, 25.0, 50.0, 75.0, 100.0],
            tolerance: 0.5,
            test_sequence: vec![/* SubTestItem::HardPoint, ... */], // éœ€è¦ SubTestItem å®šä¹‰
        };
        self.save_test_parameters(ModuleType::AI, &params_ai).await.unwrap();
    }
}

#[async_trait]
impl IConfigurationRepository for MemoryConfigurationRepository {
    async fn get_channel_definition_by_id(&self, id: &str) -> Result<Option<ChannelPointDefinition>, AppError> {
        let defs = self.definitions_by_id.read().await;
        Ok(defs.get(id).cloned())
    }

    async fn get_channel_definition_by_tag(&self, tag: &str) -> Result<Option<ChannelPointDefinition>, AppError> {
        let tags_to_ids = self.definitions_by_tag.read().await;
        if let Some(id) = tags_to_ids.get(tag) {
            let defs = self.definitions_by_id.read().await;
            Ok(defs.get(id).cloned())
        } else {
            Ok(None)
        }
    }

    async fn save_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError> {
        // æ£€æŸ¥ä½å·å”¯ä¸€æ€§
        if self.get_channel_definition_by_tag(&definition.tag).await?.is_some() {
            return Err(AppError::ValidationFailed(format!("ä½å· '{}' å·²å­˜åœ¨", definition.tag)));
        }
        
        let mut def_to_save = definition.clone();
        if def_to_save.id.is_empty() || Uuid::try_parse(&def_to_save.id).is_err() { // å¦‚æœIDä¸ºç©ºæˆ–æ— æ•ˆï¼Œåˆ™ç”Ÿæˆæ–°ID
            def_to_save.id = Uuid::new_v4().to_string();
        }

        let mut defs_by_id = self.definitions_by_id.write().await;
        let mut tags_to_ids = self.definitions_by_tag.write().await;

        defs_by_id.insert(def_to_save.id.clone(), def_to_save.clone());
        tags_to_ids.insert(def_to_save.tag.clone(), def_to_save.id.clone());
        
        Ok(def_to_save)
    }

    async fn update_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<ChannelPointDefinition, AppError> {
        let mut defs_by_id = self.definitions_by_id.write().await;
        let mut tags_to_ids = self.definitions_by_tag.write().await;

        if let Some(existing_def) = defs_by_id.get_mut(&definition.id) {
            // å¦‚æœä½å·å‘ç”Ÿæ”¹å˜ï¼Œéœ€è¦æ›´æ–°tagç´¢å¼•
            if existing_def.tag != definition.tag {
                // æ£€æŸ¥æ–°ä½å·æ˜¯å¦å·²å­˜åœ¨ (ä¸”ä¸å±äºå½“å‰æ›´æ–°çš„è¿™ä¸ªç‚¹)
                if let Some(id_for_new_tag) = tags_to_ids.get(&definition.tag) {
                    if id_for_new_tag != &definition.id {
                        return Err(AppError::ValidationFailed(format!("ä½å· '{}' å·²è¢«å…¶ä»–ç‚¹ä½å ç”¨", definition.tag)));
                    }
                }
                tags_to_ids.remove(&existing_def.tag);
                tags_to_ids.insert(definition.tag.clone(), definition.id.clone());
            }
            *existing_def = definition.clone();
            Ok(definition.clone())
        } else {
            Err(AppError::RecordNotFound(format!("ç‚¹ä½å®šä¹‰ ID: {} æœªæ‰¾åˆ°", definition.id)))
        }
    }
    
    async fn delete_channel_definition(&self, id: &str) -> Result<bool, AppError> {
        let mut defs_by_id = self.definitions_by_id.write().await;
        if let Some(removed_def) = defs_by_id.remove(id) {
            let mut tags_to_ids = self.definitions_by_tag.write().await;
            tags_to_ids.remove(&removed_def.tag);
            
            // ä»æ‰€æœ‰é…ç½®é›†ä¸­ç§»é™¤è¯¥ç‚¹ä½
            let mut sets = self.configuration_sets.write().await;
            for def_ids in sets.values_mut() {
                def_ids.retain(|def_id| def_id != id);
            }
            Ok(true)
        } else {
            Ok(false)
        }
    }

    async fn list_all_channel_definitions(&self) -> Result<Vec<ChannelPointDefinition>, AppError> {
        let defs = self.definitions_by_id.read().await;
        Ok(defs.values().cloned().collect())
    }

    async fn query_channel_definitions(&self, criteria: QueryCriteria) -> Result<Vec<ChannelPointDefinition>, AppError> {
        // å†…å­˜å®ç°çš„æŸ¥è¯¢é€»è¾‘ (ç®€åŒ–ç‰ˆï¼Œå¯æ ¹æ®QueryCriteriaæ‰©å±•)
        let defs = self.definitions_by_id.read().await;
        let mut results: Vec<ChannelPointDefinition> = defs.values().cloned().collect();

        for filter in &criteria.filters {
            results.retain(|def| {
                match filter.field.as_str() {
                    "tag" => if let FilterValue::String(v) = &filter.value { def.tag.contains(v) } else { false },
                    "module_type" => if let FilterValue::String(v_str) = &filter.value {
                        if let Ok(mt) = v_str.parse::<ModuleType>() { def.module_type == mt } else { false }
                    } else { false },
                    // æ·»åŠ æ›´å¤šå­—æ®µè¿‡æ»¤
                    _ => true,
                }
            });
        }
        // å®ç°æ’åºã€åˆ†é¡µç­‰
        Ok(results)
    }

    async fn save_channel_definitions_batch(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ChannelPointDefinition>, AppError> {
        let mut saved_definitions = Vec::new();
        for def in definitions {
            // è¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„ç‚¹ä½ï¼Œæˆ–è€…è¿”å›é”™è¯¯ã€‚å½“å‰å®ç°æ˜¯è¦†ç›–ã€‚
            // ä¸ºäº†æ›´å®‰å…¨ï¼Œå¯ä»¥å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼Œæˆ–è€…æä¾›ä¸€ä¸ª overwrite æ ‡å¿—ã€‚
            // å½“å‰save_channel_definitionä¼šå¤„ç†IDç”Ÿæˆå’Œä½å·å”¯ä¸€æ€§æ£€æŸ¥ã€‚
            match self.save_channel_definition(def).await {
                 Ok(saved_def) => saved_definitions.push(saved_def),
                 Err(AppError::ValidationFailed(msg)) if msg.contains("å·²å­˜åœ¨") => {
                    // å¦‚æœæ˜¯å› ä¸ºä½å·å·²å­˜åœ¨è€Œä¿å­˜å¤±è´¥ï¼Œå°è¯•æ›´æ–°ï¼ˆå¦‚æœä¸šåŠ¡é€»è¾‘å…è®¸ï¼‰
                    // æˆ–è€…æ”¶é›†è¿™äº›é”™è¯¯ç»Ÿä¸€è¿”å›
                    // ä¸ºç®€åŒ–ï¼Œè¿™é‡Œç›´æ¥è¿”å›é”™è¯¯
                    return Err(AppError::ValidationFailed(format!("æ‰¹é‡ä¿å­˜å¤±è´¥ï¼š{}", msg)));
                 }
                 Err(e) => return Err(e),
            }
        }
        Ok(saved_definitions)
    }
    
    async fn delete_channel_definitions_batch(&self, ids: &[String]) -> Result<usize, AppError> {
        let mut deleted_count = 0;
        for id in ids {
            if self.delete_channel_definition(id).await? {
                deleted_count += 1;
            }
        }
        Ok(deleted_count)
    }

    // Excel å¯¼å…¥/å¯¼å‡º (æ­¤ä¸ºå¤æ‚åŠŸèƒ½ï¼Œéœ€è¦å¼•å…¥Excelå¤„ç†åº“å¦‚ calamine, rust_xlsxwriter)
    // ä»¥ä¸‹ä¸ºä¼ªä»£ç /é«˜çº§æ­¥éª¤ï¼Œå…·ä½“å®ç°ä¼šæ¯”è¾ƒé•¿
    async fn import_definitions_from_excel(&self, file_path: &str, import_config: &ExcelImportConfig) -> Result<(Vec<ChannelPointDefinition>, Vec<ValidationIssue>), AppError> {
        log::info!("å¼€å§‹ä»Excelå¯¼å…¥ç‚¹ä½å®šä¹‰: {}", file_path);
        // 1. ä½¿ç”¨ calamine æ‰“å¼€å’Œè¯»å–Excelæ–‡ä»¶ (workbook, worksheet)
        // 2. æ ¹æ® import_config (èµ·å§‹è¡Œ, åˆ—æ˜ å°„) éå†è¡Œ
        // 3. å¯¹æ¯ä¸€è¡Œæ•°æ®:
        //    a. è§£æå•å…ƒæ ¼æ•°æ®åˆ° ChannelPointDefinition ç»“æ„ä½“çš„å­—æ®µ
        //    b. è¿›è¡Œåˆæ­¥çš„æ•°æ®ç±»å‹è½¬æ¢å’Œæ ¼å¼æ ¡éªŒ
        //    c. å¦‚æœæœ‰è§£æé”™è¯¯ï¼Œè®°å½•åˆ° ValidationIssue (Errorçº§åˆ«)
        // 4. æ”¶é›†æ‰€æœ‰æˆåŠŸè§£æçš„ ChannelPointDefinition
        // 5. å¯¹è§£ææˆåŠŸçš„åˆ—è¡¨è¿›è¡Œä¸šåŠ¡é€»è¾‘éªŒè¯ (ä¾‹å¦‚ï¼Œé€šè¿‡ validate_definitions_list)
        // 6. å¦‚æœæ²¡æœ‰Errorçº§åˆ«çš„ValidationIssueï¼Œåˆ™å¯ä»¥è€ƒè™‘ä¿å­˜è¿™äº›ç‚¹ä½ (ä¾‹å¦‚ï¼Œé€šè¿‡ save_channel_definitions_batch)
        // 7. è¿”å›æˆåŠŸå¯¼å…¥çš„ç‚¹ä½åˆ—è¡¨å’Œæ‰€æœ‰ValidationIssue (åŒ…æ‹¬Errorå’ŒWarning)
        
        // ç¤ºä¾‹ï¼š
        // let definitions_from_excel = parse_excel(file_path, import_config)?; // parse_excelæ˜¯éœ€è¦å®ç°çš„è¾…åŠ©å‡½æ•°
        // let validation_issues = self.validate_definitions_list(&definitions_from_excel).await?;
        // if validation_issues.iter().any(|iss| iss.severity == ValidationSeverity::Error) {
        //     return Ok((vec![], validation_issues)); // ä¸å¯¼å…¥ï¼Œä»…è¿”å›é—®é¢˜
        // }
        // let saved_definitions = self.save_channel_definitions_batch(&definitions_from_excel).await?;
        // Ok((saved_definitions, validation_issues))
        Err(AppError::NotImplemented("Excelå¯¼å…¥åŠŸèƒ½å°šæœªå®ç°".to_string())) // æ›¿æ¢ä¸ºå®é™…å®ç°
    }

    async fn export_definitions_to_excel(&self, definitions: &[ChannelPointDefinition], file_path: &str) -> Result<(), AppError> {
        log::info!("å¼€å§‹å¯¼å‡ºç‚¹ä½å®šä¹‰åˆ°Excel: {}", file_path);
        // 1. ä½¿ç”¨ rust_xlsxwriter åˆ›å»ºæ–°çš„Excelå·¥ä½œç°¿å’Œå·¥ä½œè¡¨
        // 2. å†™å…¥è¡¨å¤´ (æ ¹æ® ChannelPointDefinition çš„å­—æ®µ)
        // 3. éå† definitions åˆ—è¡¨
        // 4. å°†æ¯ä¸ª ChannelPointDefinition çš„å­—æ®µå†™å…¥åˆ°å¯¹åº”çš„å•å…ƒæ ¼
        // 5. ä¿å­˜å·¥ä½œç°¿åˆ° file_path
        Err(AppError::NotImplemented("Excelå¯¼å‡ºåŠŸèƒ½å°šæœªå®ç°".to_string())) // æ›¿æ¢ä¸ºå®é™…å®ç°
    }

    // é…ç½®é›†ç®¡ç†
    async fn save_configuration_set(&self, name: &str, definition_ids: &[String]) -> Result<(), AppError> {
        let mut sets = self.configuration_sets.write().await;
        // éªŒè¯æ‰€æœ‰definition_idæ˜¯å¦å­˜åœ¨
        let defs_by_id = self.definitions_by_id.read().await;
        for id in definition_ids {
            if !defs_by_id.contains_key(id) {
                return Err(AppError::RecordNotFound(format!("ç‚¹ä½ ID: {} ä¸å­˜åœ¨ï¼Œæ— æ³•æ·»åŠ åˆ°é…ç½®é›† '{}'", id, name)));
            }
        }
        sets.insert(name.to_string(), definition_ids.to_vec());
        Ok(())
    }

    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, AppError> {
        let sets = self.configuration_sets.read().await;
        if let Some(ids) = sets.get(name) {
            let defs_by_id = self.definitions_by_id.read().await;
            let mut result_defs = Vec::new();
            for id in ids {
                if let Some(def) = defs_by_id.get(id) {
                    result_defs.push(def.clone());
                } else {
                    log::warn!("é…ç½®é›† '{}' åŒ…å«ä¸€ä¸ªå­¤ç«‹çš„ç‚¹ä½ID: {}", name, id);
                }
            }
            Ok(result_defs)
        } else {
            Err(AppError::RecordNotFound(format!("é…ç½®é›† '{}' æœªæ‰¾åˆ°", name)))
        }
    }
    
    async fn list_configuration_sets(&self) -> Result<Vec<String>, AppError> {
        let sets = self.configuration_sets.read().await;
        Ok(sets.keys().cloned().collect())
    }

    async fn delete_configuration_set(&self, name: &str) -> Result<bool, AppError> {
        let mut sets = self.configuration_sets.write().await;
        Ok(sets.remove(name).is_some())
    }
    
    async fn add_definition_to_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError> {
        let mut sets = self.configuration_sets.write().await;
        if let Some(ids) = sets.get_mut(set_name) {
            if !self.definitions_by_id.read().await.contains_key(definition_id) {
                 return Err(AppError::RecordNotFound(format!("ç‚¹ä½ ID: {} ä¸å­˜åœ¨", definition_id)));
            }
            if !ids.contains(&definition_id.to_string()) {
                ids.push(definition_id.to_string());
            }
            Ok(())
        } else {
            Err(AppError::RecordNotFound(format!("é…ç½®é›† '{}' æœªæ‰¾åˆ°", set_name)))
        }
    }

    async fn remove_definition_from_set(&self, set_name: &str, definition_id: &str) -> Result<(), AppError> {
        let mut sets = self.configuration_sets.write().await;
        if let Some(ids) = sets.get_mut(set_name) {
            ids.retain(|id| id != definition_id);
            Ok(())
        } else {
            Err(AppError::RecordNotFound(format!("é…ç½®é›† '{}' æœªæ‰¾åˆ°", set_name)))
        }
    }

    // æµ‹è¯•å‚æ•°ç®¡ç†
    async fn get_test_parameters(&self, module_type: ModuleType) -> Result<Option<TestParameterSet>, AppError> {
        let params = self.test_parameters.read().await;
        Ok(params.get(&module_type).cloned())
    }

    async fn save_test_parameters(&self, module_type: ModuleType, params: &TestParameterSet) -> Result<(), AppError> {
        let mut param_map = self.test_parameters.write().await;
        param_map.insert(module_type, params.clone());
        Ok(())
    }

    async fn list_all_test_parameters(&self) -> Result<HashMap<ModuleType, TestParameterSet>, AppError> {
        let params = self.test_parameters.read().await;
        Ok(params.clone())
    }
    
    // æ•°æ®éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥
    async fn validate_definitions_list(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ValidationIssue>, AppError> {
        let mut issues = Vec::new();
        let mut existing_tags = HashMap::new(); // ç”¨äºæ£€æŸ¥åˆ—è¡¨å†…éƒ¨çš„é‡å¤ä½å·

        for (index, def) in definitions.iter().enumerate() {
            // æ£€æŸ¥å¿…å¡«é¡¹
            if def.tag.is_empty() {
                issues.push(ValidationIssue {
                    severity: ValidationSeverity::Error, message: "ä½å·ä¸èƒ½ä¸ºç©º".to_string(),
                    field: Some("tag".to_string()), row_number: Some(index + 1), suggestion: None,
                });
            } else {
                if let Some(first_occurrence_index) = existing_tags.get(&def.tag) {
                     issues.push(ValidationIssue {
                        severity: ValidationSeverity::Error,
                        message: format!("åˆ—è¡¨ä¸­å­˜åœ¨é‡å¤ä½å·: {}", def.tag),
                        field: Some("tag".to_string()), row_number: Some(index + 1),
                        suggestion: Some(format!("é¦–æ¬¡å‡ºç°äºè¡Œ {}", first_occurrence_index)),
                    });
                } else {
                    existing_tags.insert(def.tag.clone(), index + 1);
                }
            }
            if def.plc_communication_address.is_empty() {
                 issues.push(ValidationIssue {
                    severity: ValidationSeverity::Error, message: "PLCé€šè®¯åœ°å€ä¸èƒ½ä¸ºç©º".to_string(),
                    field: Some("plc_communication_address".to_string()), row_number: Some(index + 1), suggestion: None,
                });
            }
            // æ£€æŸ¥é‡ç¨‹
            if let (Some(low), Some(high)) = (def.range_lower_limit, def.range_upper_limit) {
                if low >= high {
                    issues.push(ValidationIssue {
                        severity: ValidationSeverity::Error,
                        message: format!("é‡ç¨‹ä¸‹é™ ({}) ä¸èƒ½å¤§äºæˆ–ç­‰äºä¸Šé™ ({})", low, high),
                        field: Some("range".to_string()), row_number: Some(index + 1), suggestion: None,
                    });
                }
            }
            // TODO: æ·»åŠ æ›´å¤šéªŒè¯è§„åˆ™ (ä¾‹å¦‚åœ°å€æ ¼å¼ï¼Œæšä¸¾å€¼æœ‰æ•ˆæ€§ç­‰)
        }
        Ok(issues)
    }

    async fn check_overall_consistency(&self) -> Result<ConsistencyReport, AppError> {
        let defs = self.definitions_by_id.read().await;
        let mut duplicate_tags = Vec::new();
        // å†…å­˜å®ç°ä¸­ï¼Œé€šè¿‡save/updateæ—¶çš„æ£€æŸ¥ï¼Œç†è®ºä¸Šä¸ä¼šæœ‰é‡å¤ä½å·å­˜å…¥ã€‚
        // ä½†æ­¤æ£€æŸ¥å¯ä»¥ç”¨äºéªŒè¯æ•°æ®å®Œæ•´æ€§ï¼Œæˆ–åœ¨ä»å¤–éƒ¨æºåŠ è½½æ•°æ®åä½¿ç”¨ã€‚
        // æ­¤å¤„ç®€åŒ–ï¼Œå› ä¸ºå†…å­˜ç‰ˆåœ¨å†™å…¥æ—¶å·²æ£€æŸ¥ã€‚
        
        Ok(ConsistencyReport {
            total_definitions_checked: defs.len(),
            duplicate_tags,
            issues: vec![], // å¯æ·»åŠ æ›´å¤šæ£€æŸ¥ï¼Œå¦‚å­¤ç«‹çš„é…ç½®é›†å¼•ç”¨ç­‰
        })
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 1.2)
```rust
// src/services/persistence/repositories/tests/memory_configuration_repository_tests.rs
// æˆ–è€… src/repositories/tests/memory_configuration_repository_tests.rs
use crate::services::persistence::repositories::configuration_repository::*;
use crate::models::config::{ChannelPointDefinition, TestParameterSet}; // å‡è®¾åœ¨models::configä¸­
use crate::models::enums::{ModuleType, PointDataType}; // å‡è®¾åœ¨models::enumsä¸­
use std::collections::HashMap;
use tokio;

// è¾…åŠ©å‡½æ•°åˆ›å»ºæµ‹è¯•ç”¨ ChannelPointDefinition
fn create_sample_def(id_suffix: &str, tag: &str, module_type: ModuleType) -> ChannelPointDefinition {
    ChannelPointDefinition {
        id: format!("id_{}", id_suffix),
        tag: tag.to_string(),
        variable_name: format!("Var {}", tag),
        variable_description: format!("Desc for {}", tag),
        module_type,
        data_type: PointDataType::Float, // ç¤ºä¾‹
        plc_communication_address: format!("DB1.DBD{}", id_suffix),
        // ... å…¶ä»–å­—æ®µåˆå§‹åŒ– ...
        station_name: "Station A".to_string(),
        module_name: "AI_Module_1".to_string(),
        channel_tag_in_module: "CH1".to_string(),
        power_supply_type: "24VDC".to_string(),
        wire_system: "2-wire".to_string(),
        plc_absolute_address: None,
        range_lower_limit: Some(0.0),
        range_upper_limit: Some(100.0),
        engineering_unit: Some("mA".to_string()),
        sll_set_value: None, sll_set_point_address: None, sll_feedback_address: None,
        sl_set_value: None, sl_set_point_address: None, sl_feedback_address: None,
        sh_set_value: None, sh_set_point_address: None, sh_feedback_address: None,
        shh_set_value: None, shh_set_point_address: None, shh_feedback_address: None,
        maintenance_value_set_point_address: None, maintenance_enable_switch_point_address: None,
        access_property: Some("RW".to_string()), save_history: Some(true), power_failure_protection: Some(false),
        test_rig_plc_address: None,
    }
}

#[tokio::test]
async fn test_config_repo_save_and_get_definition() {
    let repo = MemoryConfigurationRepository::new();
    let def1_no_id = ChannelPointDefinition { 
        id: "".to_string(), // æµ‹è¯•IDè‡ªåŠ¨ç”Ÿæˆ
        tag: "TAG_001".to_string(), 
        module_type: ModuleType::AI, 
        plc_communication_address: "Addr1".to_string(),
        // ... å…¶ä»–å¿…å¡«å­—æ®µ
        variable_name: "Var1".to_string(), variable_description: "Desc1".to_string(), data_type: PointDataType::Float,
        station_name: "S1".to_string(), module_name: "M1".to_string(), channel_tag_in_module: "C1".to_string(),
        power_supply_type: "P1".to_string(), wire_system: "W1".to_string(),
    };

    let saved_def1 = repo.save_channel_definition(&def1_no_id).await.unwrap();
    assert!(!saved_def1.id.is_empty());
    assert_eq!(saved_def1.tag, "TAG_001");

    let fetched_by_id = repo.get_channel_definition_by_id(&saved_def1.id).await.unwrap().unwrap();
    assert_eq!(fetched_by_id.tag, "TAG_001");

    let fetched_by_tag = repo.get_channel_definition_by_tag("TAG_001").await.unwrap().unwrap();
    assert_eq!(fetched_by_tag.id, saved_def1.id);

    // æµ‹è¯•ä¿å­˜å…·æœ‰ç›¸åŒä½å·çš„ç‚¹ä½ï¼ˆåº”å¤±è´¥ï¼‰
    let def_dup_tag = ChannelPointDefinition { 
        id: "".to_string(), 
        tag: "TAG_001".to_string(), // ç›¸åŒä½å·
        module_type: ModuleType::AO, 
        plc_communication_address: "Addr2".to_string(),
        // ...
        variable_name: "Var2".to_string(), variable_description: "Desc2".to_string(), data_type: PointDataType::Float,
        station_name: "S2".to_string(), module_name: "M2".to_string(), channel_tag_in_module: "C2".to_string(),
        power_supply_type: "P2".to_string(), wire_system: "W2".to_string(),
    };
    assert!(repo.save_channel_definition(&def_dup_tag).await.is_err(), "ä¿å­˜é‡å¤ä½å·åº”å¤±è´¥");
}

#[tokio::test]
async fn test_config_repo_update_definition() {
    let repo = MemoryConfigurationRepository::new();
    let initial_def = create_sample_def("1", "TAG_UPDATE_001", ModuleType::AI);
    let mut saved_def = repo.save_channel_definition(&initial_def).await.unwrap();

    saved_def.variable_name = "Updated Variable Name".to_string();
    saved_def.range_upper_limit = Some(250.0);
    let updated_def = repo.update_channel_definition(&saved_def).await.unwrap();
    assert_eq!(updated_def.variable_name, "Updated Variable Name");
    assert_eq!(updated_def.range_upper_limit, Some(250.0));

    let fetched_def = repo.get_channel_definition_by_id(&saved_def.id).await.unwrap().unwrap();
    assert_eq!(fetched_def.variable_name, "Updated Variable Name");
    
    // æµ‹è¯•æ›´æ–°ä½å·
    saved_def.tag = "TAG_UPDATED_NEW".to_string();
    let tag_updated_def = repo.update_channel_definition(&saved_def).await.unwrap();
    assert_eq!(tag_updated_def.tag, "TAG_UPDATED_NEW");
    assert!(repo.get_channel_definition_by_tag("TAG_UPDATE_001").await.unwrap().is_none()); // æ—§tagåº”ä¸å­˜åœ¨
    assert!(repo.get_channel_definition_by_tag("TAG_UPDATED_NEW").await.unwrap().is_some());
}

#[tokio::test]
async fn test_config_repo_delete_definition() {
    let repo = MemoryConfigurationRepository::new();
    let def_to_delete = create_sample_def("del1", "TAG_DELETE_001", ModuleType::DI);
    let saved_def = repo.save_channel_definition(&def_to_delete).await.unwrap();

    let deleted = repo.delete_channel_definition(&saved_def.id).await.unwrap();
    assert!(deleted);
    assert!(repo.get_channel_definition_by_id(&saved_def.id).await.unwrap().is_none());
    assert!(repo.get_channel_definition_by_tag("TAG_DELETE_001").await.unwrap().is_none());

    let not_deleted = repo.delete_channel_definition("non_existent_id").await.unwrap();
    assert!(!not_deleted);
}

#[tokio::test]
async fn test_config_repo_batch_operations() {
    let repo = MemoryConfigurationRepository::new();
    let defs_to_save = vec![
        create_sample_def("b1", "TAG_BATCH_001", ModuleType::AI),
        create_sample_def("b2", "TAG_BATCH_002", ModuleType::DO),
        create_sample_def("b3", "TAG_BATCH_003", ModuleType::AI),
    ];
    let saved_defs = repo.save_channel_definitions_batch(&defs_to_save).await.unwrap();
    assert_eq!(saved_defs.len(), 3);

    let all_defs = repo.list_all_channel_definitions().await.unwrap();
    assert_eq!(all_defs.len(), 3);

    let ids_to_delete: Vec<String> = saved_defs.iter().take(2).map(|d| d.id.clone()).collect();
    let deleted_count = repo.delete_channel_definitions_batch(&ids_to_delete).await.unwrap();
    assert_eq!(deleted_count, 2);

    let remaining_defs = repo.list_all_channel_definitions().await.unwrap();
    assert_eq!(remaining_defs.len(), 1);
    assert_eq!(remaining_defs[0].tag, "TAG_BATCH_003");
}

#[tokio::test]
async fn test_config_repo_configuration_sets() {
    let repo = MemoryConfigurationRepository::new();
    let def1 = repo.save_channel_definition(&create_sample_def("s1", "TAG_SET_001", ModuleType::AI)).await.unwrap();
    let def2 = repo.save_channel_definition(&create_sample_def("s2", "TAG_SET_002", ModuleType::DI)).await.unwrap();
    let def3 = repo.save_channel_definition(&create_sample_def("s3", "TAG_SET_003", ModuleType::AO)).await.unwrap();

    let set_name = "MyTestSet";
    repo.save_configuration_set(set_name, &vec![def1.id.clone(), def2.id.clone()]).await.unwrap();

    let loaded_set = repo.load_configuration_set(set_name).await.unwrap();
    assert_eq!(loaded_set.len(), 2);
    assert!(loaded_set.iter().any(|d| d.id == def1.id));
    assert!(loaded_set.iter().any(|d| d.id == def2.id));

    let set_list = repo.list_configuration_sets().await.unwrap();
    assert!(set_list.contains(&set_name.to_string()));
    
    // æ·»åŠ ç‚¹ä½åˆ°ç°æœ‰set
    repo.add_definition_to_set(set_name, &def3.id).await.unwrap();
    let loaded_set_after_add = repo.load_configuration_set(set_name).await.unwrap();
    assert_eq!(loaded_set_after_add.len(), 3);

    // ä»setç§»é™¤ç‚¹ä½
    repo.remove_definition_from_set(set_name, &def1.id).await.unwrap();
    let loaded_set_after_remove = repo.load_configuration_set(set_name).await.unwrap();
    assert_eq!(loaded_set_after_remove.len(), 2);


    let deleted = repo.delete_configuration_set(set_name).await.unwrap();
    assert!(deleted);
    assert!(repo.load_configuration_set(set_name).await.is_err());
}

#[tokio::test]
async fn test_config_repo_test_parameters() {
    let repo = MemoryConfigurationRepository::new();
    let params_ai = TestParameterSet {
        default_range: Some((0.0, 100.0)),
        test_points: vec![0.0, 50.0, 100.0],
        tolerance: 1.0,
        test_sequence: vec![/* SubTestItem::HardPoint */], // å‡è®¾SubTestItemå·²å®šä¹‰
    };
    repo.save_test_parameters(ModuleType::AI, &params_ai).await.unwrap();

    let fetched_params = repo.get_test_parameters(ModuleType::AI).await.unwrap().unwrap();
    assert_eq!(fetched_params.tolerance, 1.0);

    let all_params = repo.list_all_test_parameters().await.unwrap();
    assert_eq!(all_params.len(), 1);
    assert!(all_params.contains_key(&ModuleType::AI));
}

#[tokio::test]
async fn test_config_repo_validation() {
    let repo = MemoryConfigurationRepository::new();
    let invalid_defs = vec![
        ChannelPointDefinition { tag: "".to_string(), plc_communication_address: "Addr".to_string(), module_type: ModuleType::AI, ..Default::default() }, // ç©ºtag
        ChannelPointDefinition { tag: "ValidTag".to_string(), plc_communication_address: "".to_string(), module_type: ModuleType::DI, ..Default::default() }, // ç©ºåœ°å€
        ChannelPointDefinition { tag: "RangeTest".to_string(), plc_communication_address: "Addr3".to_string(), module_type: ModuleType::AI, range_lower_limit: Some(100.0), range_upper_limit: Some(0.0), ..Default::default() }, // é”™è¯¯é‡ç¨‹
    ];
    let issues = repo.validate_definitions_list(&invalid_defs).await.unwrap();
    assert_eq!(issues.len(), 3);
    assert!(issues.iter().all(|issue| issue.severity == ValidationSeverity::Error));
    
    // æµ‹è¯•åˆ—è¡¨å†…é‡å¤ä½å·
    let duplicate_tag_defs = vec![
        create_sample_def("dup1", "DUPLICATE_TAG", ModuleType::AI),
        create_sample_def("dup2", "DUPLICATE_TAG", ModuleType::AO),
    ];
    let duplicate_issues = repo.validate_definitions_list(&duplicate_tag_defs).await.unwrap();
    assert!(duplicate_issues.iter().any(|iss| iss.message.contains("DUPLICATE_TAG") && iss.field == Some("tag".to_string()) && iss.severity == ValidationSeverity::Error));
}

// TODO: æ·»åŠ  Excel å¯¼å…¥/å¯¼å‡ºåŠŸèƒ½çš„æµ‹è¯•ç”¨ä¾‹ (éœ€è¦mockæ–‡ä»¶ç³»ç»Ÿæˆ–ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶)
```

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 1.2)
1.  `IConfigurationRepository` æ¥å£å’Œ `MemoryConfigurationRepository` å®ç°å®Œæˆã€‚
2.  ç‚¹ä½å®šä¹‰ (`ChannelPointDefinition`) å’Œæµ‹è¯•å‚æ•° (`TestParameterSet`) çš„CRUDæ“ä½œåŠŸèƒ½æ­£å¸¸ã€‚
3.  Excelå¯¼å…¥/å¯¼å‡ºï¼ˆé«˜çº§æ­¥éª¤å·²è§„åˆ’ï¼Œå…·ä½“å®ç°å¯åç»­è¿­ä»£ï¼Œä½†æ¥å£å·²å®šä¹‰ï¼‰ã€‚
4.  é…ç½®é›†ç®¡ç†åŠŸèƒ½ (ä¿å­˜ã€åŠ è½½ã€åˆ—è¡¨ã€åˆ é™¤) æ­£å¸¸å·¥ä½œã€‚
5.  åŸºæœ¬çš„æ•°æ®éªŒè¯é€»è¾‘ (`validate_definitions_list`) å·²å®ç°ã€‚
6.  å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬è¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯å¤„ç†ã€‚
7.  ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒã€‚

---

### æ­¥éª¤ 1.3: åˆ›å»ºè¿è¡Œæ—¶æ•°æ®Repository (`IRuntimeRepository`)

#### ğŸ¯ ç›®æ ‡
å®ç°ä¸“é—¨ç®¡ç†è¿è¡Œæ—¶æ•°æ®çš„Repositoryï¼Œä¾‹å¦‚ `ChannelTestInstance`ï¼ˆé€šé“æµ‹è¯•å®ä¾‹çš„å®æ—¶çŠ¶æ€å’Œç»“æœï¼‰å’Œ `TestBatchInfo`ï¼ˆæµ‹è¯•æ‰¹æ¬¡çš„è¿è¡Œæ—¶ä¿¡æ¯ï¼‰ã€‚æ­¤Repositoryå°†ä¸»è¦ä½¿ç”¨å†…å­˜å®ç°ï¼Œä»¥ä¿è¯é«˜æ€§èƒ½çš„è¯»å†™è®¿é—®ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.3.1 å®šä¹‰è¿è¡Œæ—¶Repositoryæ¥å£ (`IRuntimeRepository`)
```rust
// src/services/persistence/repositories/runtime_repository.rs
// æˆ–è€… src/repositories/runtime_repository.rs
use async_trait::async_trait;
use crate::models::runtime::{ChannelTestInstance, TestBatchInfo, BatchStatistics, CacheStatistics}; // å‡è®¾åœ¨models::runtimeä¸­
use crate::models::enums::OverallTestStatus; // å‡è®¾åœ¨models::enumsä¸­
use crate::utils::error::AppError;
use super::base::QueryCriteria; // ä» Step 1.1 å¼•å…¥
use std::collections::HashMap;
use chrono::{DateTime, Utc};

/// è¿è¡Œæ—¶æ•°æ®Repositoryæ¥å£
#[async_trait]
pub trait IRuntimeRepository: Send + Sync {
    // å•ä¸ªé€šé“æµ‹è¯•å®ä¾‹ç®¡ç†
    async fn get_channel_instance(&self, instance_id: &str) -> Result<Option<ChannelTestInstance>, AppError>;
    async fn save_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError>; // è¿”å›ä¿å­˜çš„å®ä¾‹
    async fn update_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError>;
    async fn delete_channel_instance(&self, instance_id: &str) -> Result<bool, AppError>;
    async fn list_all_channel_instances(&self) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn query_channel_instances(&self, criteria: QueryCriteria) -> Result<Vec<ChannelTestInstance>, AppError>;

    // æ‰¹é‡æ“ä½œé€šé“æµ‹è¯•å®ä¾‹
    async fn save_channel_instances_batch(&self, instances: &[ChannelTestInstance]) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn update_instances_status_batch(&self, instance_ids: &[String], new_status: OverallTestStatus, operator_notes: Option<String>) -> Result<usize, AppError>; // è¿”å›æ›´æ–°çš„æ•°é‡
    async fn delete_channel_instances_batch(&self, instance_ids: &[String]) -> Result<usize, AppError>;

    // ä¸ç‰¹å®šæµ‹è¯•æ‰¹æ¬¡ç›¸å…³çš„å®ä¾‹æ“ä½œ
    async fn list_instances_by_batch_id(&self, batch_id: &str) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn count_instances_by_batch_id(&self, batch_id: &str) -> Result<i64, AppError>;
    async fn get_batch_statistics(&self, batch_id: &str) -> Result<BatchStatistics, AppError>;
    async fn delete_instances_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError>; // åˆ é™¤æ‰¹æ¬¡ä¸‹æ‰€æœ‰å®ä¾‹

    // æŒ‰çŠ¶æ€æŸ¥è¯¢å®ä¾‹
    async fn list_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<Vec<ChannelTestInstance>, AppError>;
    async fn count_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<i64, AppError>;

    // æµ‹è¯•æ‰¹æ¬¡ä¿¡æ¯ç®¡ç†
    async fn get_test_batch_info(&self, batch_id: &str) -> Result<Option<TestBatchInfo>, AppError>;
    async fn save_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError>;
    async fn update_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError>;
    async fn delete_test_batch_info(&self, batch_id: &str) -> Result<bool, AppError>; // åŒæ—¶åº”è€ƒè™‘å¤„ç†å…¶ä¸‹æ‰€æœ‰å®ä¾‹
    async fn list_all_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError>;
    async fn list_active_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError>; // ä¾‹å¦‚ï¼ŒçŠ¶æ€ä¸æ˜¯Completedæˆ–Cancelledçš„æ‰¹æ¬¡

    // ç¼“å­˜ç®¡ç† (å†…å­˜å®ç°é€šå¸¸ä¸éœ€è¦æ˜¾å¼ç¼“å­˜ç®¡ç†ï¼Œä½†æ¥å£å¯ä»¥ä¿ç•™ä»¥å¤‡å°†æ¥æ‰©å±•)
    async fn clear_all_runtime_data(&self) -> Result<(), AppError>; // æ¸…ç©ºæ‰€æœ‰è¿è¡Œæ—¶æ•°æ®
    async fn get_runtime_cache_stats(&self) -> Result<CacheStatistics, AppError>;
}
```
**æ³¨æ„**: `ChannelTestInstance` å’Œ `TestBatchInfo` ç»“æ„ä½“éœ€è¦åœ¨ `src/models/runtime.rs` ä¸­è¯¦ç»†å®šä¹‰ã€‚`ChannelTestInstance` åº”åŒ…å« `instance_id`, `definition_id`, `test_batch_id`, `overall_status`, `sub_test_results`, æ—¶é—´æˆ³ç­‰ã€‚`TestBatchInfo` åº”åŒ…å« `batch_id`, `product_model`, çŠ¶æ€æ‘˜è¦ï¼Œç‚¹ä½æ•°ç­‰ã€‚

##### 1.3.2 å®ç°å†…å­˜è¿è¡Œæ—¶Repository (`MemoryRuntimeRepository`)
```rust
// src/services/persistence/repositories/memory_runtime_repository.rs
// æˆ–è€… src/repositories/memory_runtime_repository.rs
use super::runtime_repository::*;
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;
use crate::models::enums::SubTestItem; // For BatchStatistics example
use crate::models::runtime::SubTestExecutionResult; // For BatchStatistics example


pub struct MemoryRuntimeRepository {
    instances: Arc<RwLock<HashMap<String, ChannelTestInstance>>>,
    batches: Arc<RwLock<HashMap<String, TestBatchInfo>>>,
    // è¾…åŠ©ç´¢å¼•ï¼šbatch_id -> Vec<instance_id>
    batch_to_instances_map: Arc<RwLock<HashMap<String, Vec<String>>>>,
    // ç®€æ˜“ç¼“å­˜ç»Ÿè®¡
    cache_stats: Arc<RwLock<CacheStatistics>>,
}

impl MemoryRuntimeRepository {
    pub fn new() -> Self {
        Self {
            instances: Arc::new(RwLock::new(HashMap::new())),
            batches: Arc::new(RwLock::new(HashMap::new())),
            batch_to_instances_map: Arc::new(RwLock::new(HashMap::new())),
            cache_stats: Arc::new(RwLock::new(CacheStatistics {
                instance_count: 0,
                batch_count: 0,
                // å…¶ä»–ç»Ÿè®¡æ•°æ®å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ 
            })),
        }
    }
    
    async fn update_stats_after_change(&self) {
        let mut stats = self.cache_stats.write().await;
        stats.instance_count = self.instances.read().await.len();
        stats.batch_count = self.batches.read().await.len();
    }
}

#[async_trait]
impl IRuntimeRepository for MemoryRuntimeRepository {
    async fn get_channel_instance(&self, instance_id: &str) -> Result<Option<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        Ok(inst_map.get(instance_id).cloned())
    }

    async fn save_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError> {
        let mut inst_to_save = instance.clone();
        if inst_to_save.instance_id.is_empty() || Uuid::try_parse(&inst_to_save.instance_id).is_err() {
            inst_to_save.instance_id = Uuid::new_v4().to_string();
        }
        
        let mut inst_map = self.instances.write().await;
        if inst_map.contains_key(&inst_to_save.instance_id) {
            return Err(AppError::AlreadyExists(format!("å®ä¾‹ ID: {} å·²å­˜åœ¨", inst_to_save.instance_id)));
        }
        inst_map.insert(inst_to_save.instance_id.clone(), inst_to_save.clone());

        // æ›´æ–° batch_to_instances_map
        let mut batch_map = self.batch_to_instances_map.write().await;
        batch_map.entry(inst_to_save.test_batch_id.clone())
            .or_default()
            .push(inst_to_save.instance_id.clone());
            
        self.update_stats_after_change().await;
        Ok(inst_to_save)
    }
    
    async fn update_channel_instance(&self, instance: &ChannelTestInstance) -> Result<ChannelTestInstance, AppError> {
        let mut inst_map = self.instances.write().await;
        if !inst_map.contains_key(&instance.instance_id) {
            return Err(AppError::RecordNotFound(format!("å®ä¾‹ ID: {} æœªæ‰¾åˆ°", instance.instance_id)));
        }
        // å‡è®¾å®ä¾‹çš„test_batch_idä¸ä¼šæ”¹å˜ï¼›å¦‚æœä¼šï¼Œéœ€è¦æ›´å¤æ‚çš„é€»è¾‘æ¥æ›´æ–°batch_to_instances_map
        inst_map.insert(instance.instance_id.clone(), instance.clone());
        self.update_stats_after_change().await;
        Ok(instance.clone())
    }

    async fn delete_channel_instance(&self, instance_id: &str) -> Result<bool, AppError> {
        let mut inst_map = self.instances.write().await;
        if let Some(removed_instance) = inst_map.remove(instance_id) {
            let mut batch_map = self.batch_to_instances_map.write().await;
            if let Some(ids_in_batch) = batch_map.get_mut(&removed_instance.test_batch_id) {
                ids_in_batch.retain(|id| id != instance_id);
                if ids_in_batch.is_empty() {
                    batch_map.remove(&removed_instance.test_batch_id);
                }
            }
            self.update_stats_after_change().await;
            Ok(true)
        } else {
            Ok(false)
        }
    }

    async fn list_all_channel_instances(&self) -> Result<Vec<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        Ok(inst_map.values().cloned().collect())
    }

    async fn query_channel_instances(&self, criteria: QueryCriteria) -> Result<Vec<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        let mut results: Vec<ChannelTestInstance> = inst_map.values().cloned().collect();
        // å®ç°è¿‡æ»¤ã€æ’åºã€åˆ†é¡µé€»è¾‘
        for filter in &criteria.filters {
            results.retain(|inst| {
                match filter.field.as_str() {
                    "test_batch_id" => if let FilterValue::String(v) = &filter.value { inst.test_batch_id == *v } else { false },
                    "overall_status" => if let FilterValue::String(v_str) = &filter.value {
                        if let Ok(status) = v_str.parse::<OverallTestStatus>() { inst.overall_status == status } else { false }
                    } else { false },
                    // ... å…¶ä»–å­—æ®µ
                    _ => true,
                }
            });
        }
        Ok(results)
    }
    
    async fn save_channel_instances_batch(&self, instances: &[ChannelTestInstance]) -> Result<Vec<ChannelTestInstance>, AppError> {
        let mut saved_instances = Vec::new();
        for inst in instances {
            // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå¦‚æœIDå·²å­˜åœ¨åˆ™è·³è¿‡æˆ–æŠ¥é”™ã€‚å®é™…ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘ã€‚
            if self.instances.read().await.contains_key(&inst.instance_id) {
                 log::warn!("æ‰¹é‡ä¿å­˜æ—¶è·³è¿‡å·²å­˜åœ¨çš„å®ä¾‹ID: {}", inst.instance_id);
                 continue; // æˆ–è€…è¿”å›é”™è¯¯
            }
            saved_instances.push(self.save_channel_instance(inst).await?);
        }
        Ok(saved_instances)
    }

    async fn update_instances_status_batch(&self, instance_ids: &[String], new_status: OverallTestStatus, operator_notes: Option<String>) -> Result<usize, AppError> {
        let mut inst_map = self.instances.write().await;
        let mut updated_count = 0;
        for id in instance_ids {
            if let Some(instance) = inst_map.get_mut(id) {
                instance.overall_status = new_status;
                instance.last_updated_time = Utc::now();
                // instance.error_message = operator_notes.clone(); // æ ¹æ®éœ€è¦è®¾ç½®
                updated_count += 1;
            }
        }
        Ok(updated_count)
    }
    
    async fn delete_channel_instances_batch(&self, instance_ids: &[String]) -> Result<usize, AppError> {
        let mut deleted_count = 0;
        for id in instance_ids {
            if self.delete_channel_instance(id).await? {
                deleted_count += 1;
            }
        }
        Ok(deleted_count)
    }

    async fn list_instances_by_batch_id(&self, batch_id: &str) -> Result<Vec<ChannelTestInstance>, AppError> {
        let batch_map = self.batch_to_instances_map.read().await;
        if let Some(instance_ids) = batch_map.get(batch_id) {
            let inst_map = self.instances.read().await;
            let result = instance_ids.iter()
                .filter_map(|id| inst_map.get(id).cloned())
                .collect();
            Ok(result)
        } else {
            Ok(Vec::new())
        }
    }
    
    async fn count_instances_by_batch_id(&self, batch_id: &str) -> Result<i64, AppError> {
        let batch_map = self.batch_to_instances_map.read().await;
        Ok(batch_map.get(batch_id).map_or(0, |ids| ids.len() as i64))
    }

    async fn get_batch_statistics(&self, batch_id: &str) -> Result<BatchStatistics, AppError> {
        let instances = self.list_instances_by_batch_id(batch_id).await?;
        let total_instances = instances.len();
        let mut stats = BatchStatistics {
            batch_id: batch_id.to_string(),
            total_instances,
            status_counts: HashMap::new(),
            progress_percentage: 0.0,
            // ... å…¶ä»–ç»Ÿè®¡å­—æ®µ
        };
        let mut tested_count = 0;
        for inst in instances {
            *stats.status_counts.entry(inst.overall_status).or_insert(0) += 1;
            if inst.overall_status != OverallTestStatus::NotTested && inst.overall_status != OverallTestStatus::Skipped { // å‡è®¾Skippedä¸ç®—æµ‹è¯•è¿‡
                 tested_count +=1;
            }
        }
        if total_instances > 0 {
            let completed_count = stats.status_counts.get(&OverallTestStatus::TestCompletedPassed).unwrap_or(&0) +
                                  stats.status_counts.get(&OverallTestStatus::TestCompletedFailed).unwrap_or(&0) +
                                  stats.status_counts.get(&OverallTestStatus::Skipped).unwrap_or(&0);
            stats.progress_percentage = (completed_count as f64 / total_instances as f64) * 100.0;
        }
        Ok(stats)
    }
    
    async fn delete_instances_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError> {
        let mut inst_map = self.instances.write().await;
        let mut batch_map = self.batch_to_instances_map.write().await;
        let mut deleted_count = 0;

        if let Some(instance_ids) = batch_map.remove(batch_id) {
            for id in instance_ids {
                if inst_map.remove(&id).is_some() {
                    deleted_count +=1;
                }
            }
        }
        self.update_stats_after_change().await;
        Ok(deleted_count)
    }

    async fn list_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<Vec<ChannelTestInstance>, AppError> {
        let inst_map = self.instances.read().await;
        let results = inst_map.values()
            .filter(|inst| inst.overall_status == status && (batch_id.is_none() || inst.test_batch_id == batch_id.unwrap()))
            .cloned()
            .collect();
        Ok(results)
    }

    async fn count_instances_by_status(&self, batch_id: Option<&str>, status: OverallTestStatus) -> Result<i64, AppError> {
        let inst_map = self.instances.read().await;
        let count = inst_map.values()
            .filter(|inst| inst.overall_status == status && (batch_id.is_none() || inst.test_batch_id == batch_id.unwrap()))
            .count();
        Ok(count as i64)
    }

    async fn get_test_batch_info(&self, batch_id: &str) -> Result<Option<TestBatchInfo>, AppError> {
        let batch_map = self.batches.read().await;
        Ok(batch_map.get(batch_id).cloned())
    }

    async fn save_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError> {
        let mut batch_to_save = batch_info.clone();
        if batch_to_save.batch_id.is_empty() || Uuid::try_parse(&batch_to_save.batch_id).is_err() {
             batch_to_save.batch_id = Uuid::new_v4().to_string();
        }

        let mut batch_map = self.batches.write().await;
        if batch_map.contains_key(&batch_to_save.batch_id) {
            return Err(AppError::AlreadyExists(format!("æ‰¹æ¬¡ID: {} å·²å­˜åœ¨", batch_to_save.batch_id)));
        }
        batch_map.insert(batch_to_save.batch_id.clone(), batch_to_save.clone());
        self.update_stats_after_change().await;
        Ok(batch_to_save)
    }
    
    async fn update_test_batch_info(&self, batch_info: &TestBatchInfo) -> Result<TestBatchInfo, AppError> {
        let mut batch_map = self.batches.write().await;
        if !batch_map.contains_key(&batch_info.batch_id) {
            return Err(AppError::RecordNotFound(format!("æ‰¹æ¬¡ID: {} æœªæ‰¾åˆ°", batch_info.batch_id)));
        }
        batch_map.insert(batch_info.batch_id.clone(), batch_info.clone());
        self.update_stats_after_change().await;
        Ok(batch_info.clone())
    }

    async fn delete_test_batch_info(&self, batch_id: &str) -> Result<bool, AppError> {
        let mut batch_map = self.batches.write().await;
        if batch_map.remove(batch_id).is_some() {
            // åŒæ—¶åˆ é™¤è¯¥æ‰¹æ¬¡ä¸‹çš„æ‰€æœ‰å®ä¾‹
            self.delete_instances_by_batch_id(batch_id).await?;
            self.update_stats_after_change().await;
            Ok(true)
        } else {
            Ok(false)
        }
    }
    
    async fn list_all_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError> {
        let batch_map = self.batches.read().await;
        Ok(batch_map.values().cloned().collect())
    }

    async fn list_active_test_batch_infos(&self) -> Result<Vec<TestBatchInfo>, AppError> {
        let batch_map = self.batches.read().await;
        // ç¤ºä¾‹ï¼šå‡è®¾TestBatchInfoæœ‰ä¸€ä¸ª status å­—æ®µ
        // Ok(batch_map.values().filter(|b| b.status != BatchStatus::Completed && b.status != BatchStatus::Cancelled).cloned().collect())
        // ä¸ºç®€åŒ–ï¼Œæ­¤å¤„è¿”å›æ‰€æœ‰
        Ok(batch_map.values().cloned().collect())
    }

    async fn clear_all_runtime_data(&self) -> Result<(), AppError> {
        self.instances.write().await.clear();
        self.batches.write().await.clear();
        self.batch_to_instances_map.write().await.clear();
        self.update_stats_after_change().await;
        log::info!("æ‰€æœ‰è¿è¡Œæ—¶æ•°æ®å·²æ¸…ç©º");
        Ok(())
    }
    
    async fn get_runtime_cache_stats(&self) -> Result<CacheStatistics, AppError> {
        Ok(self.cache_stats.read().await.clone())
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 1.3)
```rust
// src/services/persistence/repositories/tests/memory_runtime_repository_tests.rs
// æˆ–è€… src/repositories/tests/memory_runtime_repository_tests.rs
use crate::services::persistence::repositories::runtime_repository::*;
use crate::models::runtime::{ChannelTestInstance, TestBatchInfo, SubTestExecutionResult};
use crate::models::enums::{OverallTestStatus, SubTestItem, TestResult}; // å‡è®¾åœ¨models::enumsä¸­
use tokio;
use uuid::Uuid;
use chrono::Utc;

// è¾…åŠ©å‡½æ•°åˆ›å»ºæµ‹è¯•ç”¨ ChannelTestInstance
fn create_sample_instance(id_suffix: &str, batch_id: &str, status: OverallTestStatus) -> ChannelTestInstance {
    ChannelTestInstance {
        instance_id: format!("inst_{}", id_suffix),
        definition_id: format!("def_{}", id_suffix),
        test_batch_id: batch_id.to_string(),
        overall_status: status,
        current_step_details: None,
        error_message: None,
        start_time: Some(Utc::now()),
        last_updated_time: Utc::now(),
        final_test_time: None,
        total_test_duration_ms: None,
        sub_test_results: HashMap::new(),
        hardpoint_readings: None,
        manual_test_current_value_input: None,
        manual_test_current_value_output: None,
    }
}

// è¾…åŠ©å‡½æ•°åˆ›å»ºæµ‹è¯•ç”¨ TestBatchInfo
fn create_sample_batch(id_suffix: &str, product_model: &str) -> TestBatchInfo {
    TestBatchInfo {
        batch_id: format!("batch_{}", id_suffix),
        product_model: Some(product_model.to_string()),
        serial_number: Some(format!("SN{}", id_suffix)),
        customer_name: Some("Test Customer".to_string()),
        creation_time: Utc::now(),
        status_summary: Some("å·²åˆ›å»º".to_string()),
        total_points: 0,
        tested_points: 0,
        passed_points: 0,
        failed_points: 0,
    }
}


#[tokio::test]
async fn test_runtime_repo_save_and_get_instance() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("1", "ModelX")).await.unwrap();
    let inst1 = create_sample_instance("1", &batch1.batch_id, OverallTestStatus::NotTested);
    
    let saved_inst = repo.save_channel_instance(&inst1).await.unwrap();
    assert_eq!(saved_inst.instance_id, inst1.instance_id);

    let fetched_inst = repo.get_channel_instance(&inst1.instance_id).await.unwrap().unwrap();
    assert_eq!(fetched_inst.definition_id, inst1.definition_id);
    
    // æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ åˆ° batch_to_instances_map
    let batch_instances = repo.list_instances_by_batch_id(&batch1.batch_id).await.unwrap();
    assert_eq!(batch_instances.len(), 1);
    assert_eq!(batch_instances[0].instance_id, inst1.instance_id);
}

#[tokio::test]
async fn test_runtime_repo_update_instance() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("1", "ModelX")).await.unwrap();
    let mut inst1 = create_sample_instance("1", &batch1.batch_id, OverallTestStatus::NotTested);
    repo.save_channel_instance(&inst1).await.unwrap();

    inst1.overall_status = OverallTestStatus::TestCompletedPassed;
    inst1.error_message = Some("Test error".to_string());
    let updated_inst = repo.update_channel_instance(&inst1).await.unwrap();
    assert_eq!(updated_inst.overall_status, OverallTestStatus::TestCompletedPassed);

    let fetched_inst = repo.get_channel_instance(&inst1.instance_id).await.unwrap().unwrap();
    assert_eq!(fetched_inst.error_message, Some("Test error".to_string()));
}

#[tokio::test]
async fn test_runtime_repo_delete_instance() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("1", "ModelX")).await.unwrap();
    let inst1 = create_sample_instance("1", &batch1.batch_id, OverallTestStatus::NotTested);
    repo.save_channel_instance(&inst1).await.unwrap();

    let deleted = repo.delete_channel_instance(&inst1.instance_id).await.unwrap();
    assert!(deleted);
    assert!(repo.get_channel_instance(&inst1.instance_id).await.unwrap().is_none());
    
    // æ£€æŸ¥æ˜¯å¦å·²ä» batch_to_instances_map ç§»é™¤
    let batch_instances = repo.list_instances_by_batch_id(&batch1.batch_id).await.unwrap();
    assert!(batch_instances.is_empty());
}

#[tokio::test]
async fn test_runtime_repo_batch_instance_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("b1", "ModelX")).await.unwrap();
    let instances_to_save = vec![
        create_sample_instance("b_i1", &batch1.batch_id, OverallTestStatus::NotTested),
        create_sample_instance("b_i2", &batch1.batch_id, OverallTestStatus::NotTested),
    ];
    let saved_instances = repo.save_channel_instances_batch(&instances_to_save).await.unwrap();
    assert_eq!(saved_instances.len(), 2);

    let instance_ids: Vec<String> = saved_instances.iter().map(|i| i.instance_id.clone()).collect();
    let updated_count = repo.update_instances_status_batch(&instance_ids, OverallTestStatus::HardPointTesting, None).await.unwrap();
    assert_eq!(updated_count, 2);

    let fetched_inst1 = repo.get_channel_instance(&instance_ids[0]).await.unwrap().unwrap();
    assert_eq!(fetched_inst1.overall_status, OverallTestStatus::HardPointTesting);
    
    let deleted_count = repo.delete_channel_instances_batch(&instance_ids).await.unwrap();
    assert_eq!(deleted_count, 2);
    assert_eq!(repo.list_instances_by_batch_id(&batch1.batch_id).await.unwrap().len(), 0);
}

#[tokio::test]
async fn test_runtime_repo_batch_info_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch_info1 = create_sample_batch("info1", "ModelY");
    
    let saved_batch = repo.save_test_batch_info(&batch_info1).await.unwrap();
    assert_eq!(saved_batch.batch_id, batch_info1.batch_id);

    let mut fetched_batch = repo.get_test_batch_info(&batch_info1.batch_id).await.unwrap().unwrap();
    assert_eq!(fetched_batch.product_model, Some("ModelY".to_string()));

    fetched_batch.status_summary = Some("æµ‹è¯•ä¸­".to_string());
    repo.update_test_batch_info(&fetched_batch).await.unwrap();
    let updated_batch = repo.get_test_batch_info(&batch_info1.batch_id).await.unwrap().unwrap();
    assert_eq!(updated_batch.status_summary, Some("æµ‹è¯•ä¸­".to_string()));

    let all_batches = repo.list_all_test_batch_infos().await.unwrap();
    assert_eq!(all_batches.len(), 1);

    let deleted = repo.delete_test_batch_info(&batch_info1.batch_id).await.unwrap();
    assert!(deleted);
    assert!(repo.get_test_batch_info(&batch_info1.batch_id).await.unwrap().is_none());
}

#[tokio::test]
async fn test_runtime_repo_delete_batch_cascades_instances() {
    let repo = MemoryRuntimeRepository::new();
    let batch = repo.save_test_batch_info(&create_sample_batch("cascade", "ModelZ")).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("c_i1", &batch.batch_id, OverallTestStatus::NotTested)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("c_i2", &batch.batch_id, OverallTestStatus::NotTested)).await.unwrap();

    assert_eq!(repo.list_instances_by_batch_id(&batch.batch_id).await.unwrap().len(), 2);

    repo.delete_test_batch_info(&batch.batch_id).await.unwrap();
    assert!(repo.get_test_batch_info(&batch.batch_id).await.unwrap().is_none());
    assert_eq!(repo.list_instances_by_batch_id(&batch.batch_id).await.unwrap().len(), 0, "åˆ é™¤æ‰¹æ¬¡åå…¶å®ä¾‹ä¹Ÿåº”è¢«åˆ é™¤");
    assert!(repo.batch_to_instances_map.read().await.get(&batch.batch_id).is_none(), "æ‰¹æ¬¡æ˜ å°„ä¹Ÿåº”è¢«æ¸…é™¤");
}

#[tokio::test]
async fn test_runtime_repo_get_batch_statistics() {
    let repo = MemoryRuntimeRepository::new();
    let batch = repo.save_test_batch_info(&create_sample_batch("stats", "ModelStats")).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i1", &batch.batch_id, OverallTestStatus::NotTested)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i2", &batch.batch_id, OverallTestStatus::TestCompletedPassed)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i3", &batch.batch_id, OverallTestStatus::TestCompletedFailed)).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("s_i4", &batch.batch_id, OverallTestStatus::HardPointTesting)).await.unwrap();

    let stats = repo.get_batch_statistics(&batch.batch_id).await.unwrap();
    assert_eq!(stats.total_instances, 4);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::NotTested).unwrap_or(&0), 1);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::TestCompletedPassed).unwrap_or(&0), 1);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::TestCompletedFailed).unwrap_or(&0), 1);
    assert_eq!(*stats.status_counts.get(&OverallTestStatus::HardPointTesting).unwrap_or(&0), 1);
    assert_eq!(stats.progress_percentage, 50.0); // (Passed + Failed) / Total = 2/4
}


#[tokio::test]
async fn test_runtime_repo_clear_all() {
    let repo = MemoryRuntimeRepository::new();
    let batch1 = repo.save_test_batch_info(&create_sample_batch("clear1", "ModelX")).await.unwrap();
    repo.save_channel_instance(&create_sample_instance("c_i1", &batch1.batch_id, OverallTestStatus::NotTested)).await.unwrap();
    
    repo.clear_all_runtime_data().await.unwrap();
    
    assert_eq!(repo.list_all_channel_instances().await.unwrap().len(), 0);
    assert_eq!(repo.list_all_test_batch_infos().await.unwrap().len(), 0);
    let stats = repo.get_runtime_cache_stats().await.unwrap();
    assert_eq!(stats.instance_count, 0);
    assert_eq!(stats.batch_count, 0);
}
```

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 1.3)
1.  `IRuntimeRepository` æ¥å£å’Œ `MemoryRuntimeRepository` å®ç°å®Œæˆã€‚
2.  `ChannelTestInstance` å’Œ `TestBatchInfo` çš„CRUDåŠæ‰¹é‡æ“ä½œåŠŸèƒ½æ­£å¸¸ã€‚
3.  ä¸æ‰¹æ¬¡ç›¸å…³çš„å®ä¾‹æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚
4.  æŒ‰çŠ¶æ€æŸ¥è¯¢å®ä¾‹çš„åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚
5.  åŸºæœ¬çš„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯èƒ½å¤Ÿè·å–ã€‚
6.  å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒåŠŸèƒ½ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§å’Œå¹¶å‘åœºæ™¯ä¸‹çš„æ­£ç¡®æ€§ã€‚
7.  ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒã€‚

---
### æ­¥éª¤ 1.4: åˆ›å»ºæŒä¹…åŒ–æ•°æ®Repository (`IPersistentRepository`)

#### ğŸ¯ é‡æ„åŸå› 
è¿è¡Œæ—¶Repository (`MemoryRuntimeRepository`) ä¸­çš„æ•°æ®æ˜¯æ˜“å¤±çš„ï¼Œæ— æ³•æ»¡è¶³é•¿æœŸæ•°æ®å­˜å‚¨ã€å†å²è¿½æº¯å’ŒæŠ¥å‘Šçš„éœ€æ±‚ã€‚`IPersistentRepository` çš„ç›®æ ‡æ˜¯æä¾›ä¸€ä¸ªæ¥å£ï¼Œç”¨äºå°†å…³é”®çš„æµ‹è¯•æ•°æ®ï¼ˆå¦‚æœ€ç»ˆçš„æµ‹è¯•è®°å½•ã€æ‰¹æ¬¡æ‘˜è¦ï¼‰ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨ä¸­ï¼ˆæœ¬é¡¹ç›®é€‰ç”¨SQLiteï¼‰ã€‚è¿™ç¡®ä¿äº†æ•°æ®çš„æŒä¹…æ€§ã€å¯å®¡è®¡æ€§å’Œç”¨äºå†å²åˆ†æã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.4.1 å®šä¹‰æŒä¹…åŒ–Repositoryæ¥å£å’Œç›¸å…³æ•°æ®ç»“æ„
è¿™äº›ç»“æ„ä½“ä¸»è¦ç”¨äºæŒä¹…åŒ–å­˜å‚¨ï¼Œå¯èƒ½ä¸è¿è¡Œæ—¶ç»“æ„ä½“æœ‰å·®å¼‚æˆ–ä¸ºå…¶å¿«ç…§ã€‚

```rust
// src/services/persistence/repositories/persistent_repository.rs
// æˆ–è€… src/repositories/persistent_repository.rs
use async_trait::async_trait;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use crate::utils::error::AppError;
use super::base::QueryCriteria; // ä» Step 1.1 å¼•å…¥
use crate::models::enums::{OverallTestStatus, TestResult, SubTestItem}; // å¼•å…¥æ‰€éœ€æšä¸¾

/// ç”¨äºæŒä¹…åŒ–çš„æµ‹è¯•è®°å½• (TestRecord çš„æŒä¹…åŒ–ç‰ˆæœ¬)
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, sqlx::FromRow)]
pub struct PersistedTestRecord {
    #[sqlx(rename = "record_id")] // ç¡®ä¿ä¸æ•°æ®åº“åˆ—åä¸€è‡´
    pub record_id: String,        // ä¸»é”®, å¯ä»¥æ˜¯ instance_id
    pub instance_id: String,
    pub definition_id: String,
    pub test_batch_id: String,
    pub product_model: Option<String>,
    pub serial_number: Option<String>,
    pub overall_status_text: String, // å­˜å‚¨ OverallTestStatus çš„æ–‡æœ¬è¡¨ç¤º
    pub start_time: Option<DateTime<Utc>>,
    pub final_test_time: Option<DateTime<Utc>>,
    pub total_test_duration_ms: Option<i64>,
    pub error_message: Option<String>,
    pub sub_test_results_json: String, // å­˜å‚¨åºåˆ—åŒ–åçš„ HashMap<SubTestItem, SubTestExecutionResult>
    // ä» ChannelPointDefinition å¿«ç…§çš„å…³é”®ä¿¡æ¯
    pub tag: String,
    pub variable_name: String,
    pub plc_communication_address: String,
    pub module_type_text: String, // å­˜å‚¨ ModuleType çš„æ–‡æœ¬è¡¨ç¤º
    // è®°å½•åˆ›å»ºå’Œæ›´æ–°æ—¶é—´
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

/// ç”¨äºæŒä¹…åŒ–çš„æµ‹è¯•æ‰¹æ¬¡ä¿¡æ¯ (TestBatchInfo çš„æŒä¹…åŒ–ç‰ˆæœ¬)
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, sqlx::FromRow)]
pub struct PersistedTestBatch {
    #[sqlx(rename = "batch_id")]
    pub batch_id: String, // ä¸»é”®
    pub product_model: Option<String>,
    pub serial_number: Option<String>,
    pub customer_name: Option<String>,
    pub creation_time: DateTime<Utc>,
    pub completion_time: Option<DateTime<Utc>>,
    pub status_summary_text: String, // ä¾‹å¦‚ "å·²å®Œæˆ", "éƒ¨åˆ†å¤±è´¥"
    pub total_points: i32,
    pub tested_points: i32,
    pub passed_points: i32,
    pub failed_points: i32,
    pub skipped_points: i32,
    pub report_path: Option<String>, // ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    // è®°å½•åˆ›å»ºå’Œæ›´æ–°æ—¶é—´
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

// å­æµ‹è¯•æ‰§è¡Œç»“æœï¼Œç”¨äºåºåˆ—åŒ–åˆ° PersistedTestRecord çš„ JSON å­—æ®µ
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct PersistedSubTestExecutionResult {
    pub result: TestResult,
    pub measured_value: Option<f64>,
    pub expected_value: Option<f64>,
    pub tolerance: Option<f64>,
    pub timestamp: DateTime<Utc>,
    pub error_message: Option<String>,
    pub duration_ms: Option<i64>,
}


/// æŒä¹…åŒ–æ•°æ®Repositoryæ¥å£
#[async_trait]
pub trait IPersistentRepository: Send + Sync {
    // æµ‹è¯•è®°å½•ç®¡ç†
    async fn save_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError>;
    async fn get_test_record_by_id(&self, record_id: &str) -> Result<Option<PersistedTestRecord>, AppError>;
    async fn list_test_records_by_batch_id(&self, batch_id: &str) -> Result<Vec<PersistedTestRecord>, AppError>;
    async fn query_test_records(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestRecord>, AppError>;
    async fn count_test_records(&self, criteria: QueryCriteria) -> Result<i64, AppError>;
    async fn update_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError>; // å¦‚æœéœ€è¦æ›´æ–°å·²æŒä¹…åŒ–çš„è®°å½•

    // æ‰¹æ¬¡æŒä¹…åŒ–ç®¡ç†
    async fn save_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError>;
    async fn get_test_batch_by_id(&self, batch_id: &str) -> Result<Option<PersistedTestBatch>, AppError>;
    async fn list_historical_batches(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestBatch>, AppError>; // ä½¿ç”¨QueryCriteriaè¿›è¡Œçµæ´»æŸ¥è¯¢
    async fn count_historical_batches(&self, criteria: QueryCriteria) -> Result<i64, AppError>;
    async fn update_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError>;

    // æ•°æ®æ¸…ç† (å¯é€‰ï¼Œæ ¹æ®éœ€æ±‚)
    async fn delete_old_test_records(&self, older_than: DateTime<Utc>) -> Result<usize, AppError>; // è¿”å›åˆ é™¤çš„è®°å½•æ•°
    async fn delete_old_test_batches(&self, older_than: DateTime<Utc>) -> Result<usize, AppError>;
    
    // åˆå§‹åŒ– (ä¾‹å¦‚ï¼Œåˆ›å»ºè¡¨ç»“æ„)
    async fn initialize_schema(&self) -> Result<(), AppError>;
}
```

##### 1.4.2 SQLite è¡¨ç»“æ„è®¾è®¡
ä»¥ä¸‹æ˜¯å»ºè®®çš„SQLiteè¡¨ç»“æ„ï¼Œè¯·æ‚¨æ ¹æ® `ChannelMappings_202505292135.sql` å’Œå®é™…éœ€æ±‚è°ƒæ•´ã€‚

```sql
-- è¡¨ï¼špersisted_test_batches (å­˜å‚¨æµ‹è¯•æ‰¹æ¬¡æ‘˜è¦ä¿¡æ¯)
CREATE TABLE IF NOT EXISTS persisted_test_batches (
    batch_id TEXT PRIMARY KEY NOT NULL,
    product_model TEXT,
    serial_number TEXT,
    customer_name TEXT,
    creation_time TEXT NOT NULL,       -- ISO8601 DateTime String
    completion_time TEXT,            -- ISO8601 DateTime String
    status_summary_text TEXT NOT NULL, -- 'Completed', 'Failed', 'Cancelled'
    total_points INTEGER NOT NULL DEFAULT 0,
    tested_points INTEGER NOT NULL DEFAULT 0,
    passed_points INTEGER NOT NULL DEFAULT 0,
    failed_points INTEGER NOT NULL DEFAULT 0,
    skipped_points INTEGER NOT NULL DEFAULT 0,
    report_path TEXT,
    created_at TEXT NOT NULL,          -- ISO8601 DateTime String
    updated_at TEXT NOT NULL           -- ISO8601 DateTime String
);

CREATE INDEX IF NOT EXISTS idx_ptb_creation_time ON persisted_test_batches(creation_time);
CREATE INDEX IF NOT EXISTS idx_ptb_product_model ON persisted_test_batches(product_model);
CREATE INDEX IF NOT EXISTS idx_ptb_serial_number ON persisted_test_batches(serial_number);

-- è¡¨ï¼špersisted_test_records (å­˜å‚¨å•ä¸ªæµ‹è¯•å®ä¾‹çš„è¯¦ç»†ç»“æœ)
CREATE TABLE IF NOT EXISTS persisted_test_records (
    record_id TEXT PRIMARY KEY NOT NULL, -- é€šå¸¸æ˜¯ instance_id
    instance_id TEXT NOT NULL,
    definition_id TEXT NOT NULL,
    test_batch_id TEXT NOT NULL,
    product_model TEXT,
    serial_number TEXT,                  -- ä»æ‰¹æ¬¡ä¿¡æ¯å†—ä½™æˆ–å…³è”æŸ¥è¯¢
    overall_status_text TEXT NOT NULL,   -- OverallTestStatus æšä¸¾çš„æ–‡æœ¬
    start_time TEXT,                     -- ISO8601 DateTime String
    final_test_time TEXT,                -- ISO8601 DateTime String
    total_test_duration_ms INTEGER,
    error_message TEXT,
    sub_test_results_json TEXT NOT NULL, -- JSON å­—ç¬¦ä¸²å­˜å‚¨ HashMap<SubTestItem, PersistedSubTestExecutionResult>
    tag TEXT NOT NULL,                   -- ä» ChannelPointDefinition å¿«ç…§
    variable_name TEXT NOT NULL,         -- ä» ChannelPointDefinition å¿«ç…§
    plc_communication_address TEXT NOT NULL, -- ä» ChannelPointDefinition å¿«ç…§
    module_type_text TEXT NOT NULL,      -- ModuleType æšä¸¾çš„æ–‡æœ¬, ä» ChannelPointDefinition å¿«ç…§
    created_at TEXT NOT NULL,            -- ISO8601 DateTime String
    updated_at TEXT NOT NULL,             -- ISO8601 DateTime String
    FOREIGN KEY (test_batch_id) REFERENCES persisted_test_batches(batch_id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_ptr_test_batch_id ON persisted_test_records(test_batch_id);
CREATE INDEX IF NOT EXISTS idx_ptr_tag ON persisted_test_records(tag);
CREATE INDEX IF NOT EXISTS idx_ptr_final_test_time ON persisted_test_records(final_test_time);
CREATE INDEX IF NOT EXISTS idx_ptr_overall_status ON persisted_test_records(overall_status_text);
```

##### 1.4.3 å®ç°SQLiteæŒä¹…åŒ–Repository (`SqlitePersistentRepository`)
éœ€è¦ `sqlx` crateï¼Œå¹¶å¯ç”¨ `sqlite`, `runtime-tokio-rustls` (æˆ– `runtime-tokio-native-tls`), `macros`, `chrono`, `json` ç‰¹æ€§ã€‚

```rust
// src/services/persistence/repositories/sqlite_persistent_repository.rs
// æˆ–è€… src/repositories/sqlite_persistent_repository.rs
use super::persistent_repository::*;
use sqlx::{SqlitePool, Row}; // Row for manual mapping if needed
use sqlx::sqlite::SqliteConnectOptions;
use std::str::FromStr;

pub struct SqlitePersistentRepository {
    pool: SqlitePool,
}

impl SqlitePersistentRepository {
    pub async fn new(database_url: &str) -> Result<Self, AppError> {
        let options = SqliteConnectOptions::from_str(database_url)?
            .create_if_missing(true); // è‡ªåŠ¨åˆ›å»ºæ•°æ®åº“æ–‡ä»¶
            
        let pool = SqlitePool::connect_with(options).await
            .map_err(|e| AppError::DatabaseConnectionError(e.to_string()))?;
        let repo = Self { pool };
        repo.initialize_schema().await?; // ç¡®ä¿è¡¨å·²åˆ›å»º
        Ok(repo)
    }
}

#[async_trait]
impl IPersistentRepository for SqlitePersistentRepository {
    async fn initialize_schema(&self) -> Result<(), AppError> {
        sqlx::query(
            r#"
            CREATE TABLE IF NOT EXISTS persisted_test_batches (
                batch_id TEXT PRIMARY KEY NOT NULL, product_model TEXT, serial_number TEXT,
                customer_name TEXT, creation_time TEXT NOT NULL, completion_time TEXT,
                status_summary_text TEXT NOT NULL, total_points INTEGER NOT NULL DEFAULT 0,
                tested_points INTEGER NOT NULL DEFAULT 0, passed_points INTEGER NOT NULL DEFAULT 0,
                failed_points INTEGER NOT NULL DEFAULT 0, skipped_points INTEGER NOT NULL DEFAULT 0,
                report_path TEXT, created_at TEXT NOT NULL, updated_at TEXT NOT NULL
            );
            CREATE INDEX IF NOT EXISTS idx_ptb_creation_time ON persisted_test_batches(creation_time);

            CREATE TABLE IF NOT EXISTS persisted_test_records (
                record_id TEXT PRIMARY KEY NOT NULL, instance_id TEXT NOT NULL, definition_id TEXT NOT NULL,
                test_batch_id TEXT NOT NULL, product_model TEXT, serial_number TEXT,
                overall_status_text TEXT NOT NULL, start_time TEXT, final_test_time TEXT,
                total_test_duration_ms INTEGER, error_message TEXT, sub_test_results_json TEXT NOT NULL,
                tag TEXT NOT NULL, variable_name TEXT NOT NULL, plc_communication_address TEXT NOT NULL,
                module_type_text TEXT NOT NULL, created_at TEXT NOT NULL, updated_at TEXT NOT NULL,
                FOREIGN KEY (test_batch_id) REFERENCES persisted_test_batches(batch_id) ON DELETE CASCADE
            );
            CREATE INDEX IF NOT EXISTS idx_ptr_test_batch_id ON persisted_test_records(test_batch_id);
            CREATE INDEX IF NOT EXISTS idx_ptr_tag ON persisted_test_records(tag);
            "#
        )
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(format!("åˆå§‹åŒ–è¡¨ç»“æ„å¤±è´¥: {}", e)))?;
        Ok(())
    }

    async fn save_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        sqlx::query(
            r#"
            INSERT INTO persisted_test_records (
                record_id, instance_id, definition_id, test_batch_id, product_model, serial_number,
                overall_status_text, start_time, final_test_time, total_test_duration_ms, error_message,
                sub_test_results_json, tag, variable_name, plc_communication_address, module_type_text,
                created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            "#
        )
        .bind(&record.record_id).bind(&record.instance_id).bind(&record.definition_id)
        .bind(&record.test_batch_id).bind(&record.product_model).bind(&record.serial_number)
        .bind(&record.overall_status_text).bind(record.start_time.map(|dt| dt.to_rfc3339()))
        .bind(record.final_test_time.map(|dt| dt.to_rfc3339())).bind(record.total_test_duration_ms)
        .bind(&record.error_message).bind(&record.sub_test_results_json).bind(&record.tag)
        .bind(&record.variable_name).bind(&record.plc_communication_address).bind(&record.module_type_text)
        .bind(record.created_at.to_rfc3339()).bind(record.updated_at.to_rfc3339())
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }
    
    async fn update_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        sqlx::query(
            r#"
            UPDATE persisted_test_records SET
                instance_id = ?, definition_id = ?, test_batch_id = ?, product_model = ?, serial_number = ?,
                overall_status_text = ?, start_time = ?, final_test_time = ?, total_test_duration_ms = ?,
                error_message = ?, sub_test_results_json = ?, tag = ?, variable_name = ?,
                plc_communication_address = ?, module_type_text = ?, updated_at = ?
            WHERE record_id = ?
            "#
        )
        .bind(&record.instance_id).bind(&record.definition_id)
        .bind(&record.test_batch_id).bind(&record.product_model).bind(&record.serial_number)
        .bind(&record.overall_status_text).bind(record.start_time.map(|dt| dt.to_rfc3339()))
        .bind(record.final_test_time.map(|dt| dt.to_rfc3339())).bind(record.total_test_duration_ms)
        .bind(&record.error_message).bind(&record.sub_test_results_json).bind(&record.tag)
        .bind(&record.variable_name).bind(&record.plc_communication_address).bind(&record.module_type_text)
        .bind(Utc::now().to_rfc3339()) // æ›´æ–° updated_at
        .bind(&record.record_id)
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }

    async fn get_test_record_by_id(&self, record_id: &str) -> Result<Option<PersistedTestRecord>, AppError> {
        sqlx::query_as::<_, PersistedTestRecord>(
            "SELECT * FROM persisted_test_records WHERE record_id = ?"
        )
        .bind(record_id)
        .fetch_optional(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))
    }
    
    async fn list_test_records_by_batch_id(&self, batch_id: &str) -> Result<Vec<PersistedTestRecord>, AppError> {
        sqlx::query_as::<_, PersistedTestRecord>(
            "SELECT * FROM persisted_test_records WHERE test_batch_id = ? ORDER BY created_at ASC"
        )
        .bind(batch_id)
        .fetch_all(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))
    }

    async fn query_test_records(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestRecord>, AppError> {
        // æ„å»ºåŠ¨æ€SQLæŸ¥è¯¢ (æ³¨æ„SQLæ³¨å…¥é£é™©ï¼Œå¯¹äºå¤æ‚æŸ¥è¯¢ï¼Œè€ƒè™‘æŸ¥è¯¢æ„å»ºå™¨)
        // æ­¤å¤„ä¸ºç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…åº”æ›´å¥å£®
        let mut sql = "SELECT * FROM persisted_test_records WHERE 1=1".to_string();
        // TODO: æ ¹æ® criteria.filters æ„å»º WHERE å­å¥
        // TODO: æ ¹æ® criteria.sort_by æ„å»º ORDER BY å­å¥
        // TODO: æ ¹æ® criteria.limit, criteria.offset æ„å»º LIMIT å’Œ OFFSET
        sqlx::query_as::<_, PersistedTestRecord>(&sql)
            .fetch_all(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))
    }
    
    async fn count_test_records(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        // ç®€åŒ–å®ç°ï¼Œå®é™…åº”æ ¹æ®criteriaæ„å»ºæŸ¥è¯¢
        let row = sqlx::query("SELECT COUNT(*) as count FROM persisted_test_records")
            .fetch_one(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(row.try_get("count").unwrap_or(0))
    }


    async fn save_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
        sqlx::query(
            r#"
            INSERT INTO persisted_test_batches (
                batch_id, product_model, serial_number, customer_name, creation_time, completion_time,
                status_summary_text, total_points, tested_points, passed_points, failed_points, skipped_points,
                report_path, created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            "#
        )
        .bind(&batch.batch_id).bind(&batch.product_model).bind(&batch.serial_number)
        .bind(&batch.customer_name).bind(batch.creation_time.to_rfc3339())
        .bind(batch.completion_time.map(|dt| dt.to_rfc3339())).bind(&batch.status_summary_text)
        .bind(batch.total_points).bind(batch.tested_points).bind(batch.passed_points)
        .bind(batch.failed_points).bind(batch.skipped_points).bind(&batch.report_path)
        .bind(batch.created_at.to_rfc3339()).bind(batch.updated_at.to_rfc3339())
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }
    
    async fn update_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
        sqlx::query(
             r#"
            UPDATE persisted_test_batches SET
                product_model = ?, serial_number = ?, customer_name = ?, creation_time = ?, completion_time = ?,
                status_summary_text = ?, total_points = ?, tested_points = ?, passed_points = ?,
                failed_points = ?, skipped_points = ?, report_path = ?, updated_at = ?
            WHERE batch_id = ?
            "#
        )
        .bind(&batch.product_model).bind(&batch.serial_number).bind(&batch.customer_name)
        .bind(batch.creation_time.to_rfc3339()).bind(batch.completion_time.map(|dt| dt.to_rfc3339()))
        .bind(&batch.status_summary_text).bind(batch.total_points).bind(batch.tested_points)
        .bind(batch.passed_points).bind(batch.failed_points).bind(batch.skipped_points)
        .bind(&batch.report_path).bind(Utc::now().to_rfc3339()) // æ›´æ–° updated_at
        .bind(&batch.batch_id)
        .execute(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(())
    }

    async fn get_test_batch_by_id(&self, batch_id: &str) -> Result<Option<PersistedTestBatch>, AppError> {
        sqlx::query_as::<_, PersistedTestBatch>(
            "SELECT * FROM persisted_test_batches WHERE batch_id = ?"
        )
        .bind(batch_id)
        .fetch_optional(&self.pool).await
        .map_err(|e| AppError::PersistenceError(e.to_string()))
    }

    async fn list_historical_batches(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestBatch>, AppError> {
        // ç®€åŒ–å®ç°ï¼Œå®é™…åº”æ ¹æ®criteriaæ„å»ºæŸ¥è¯¢
        // ç¤ºä¾‹ï¼šæŸ¥è¯¢ç‰¹å®šæ—¶é—´èŒƒå›´çš„æ‰¹æ¬¡
        let mut sql = "SELECT * FROM persisted_test_batches WHERE 1=1".to_string();
        for filter in criteria.filters {
            if filter.field == "creation_time_gte" {
                if let FilterValue::String(dt_str) = filter.value {
                     sql.push_str(&format!(" AND creation_time >= '{}'", dt_str));
                }
            }
            if filter.field == "creation_time_lte" {
                 if let FilterValue::String(dt_str) = filter.value {
                     sql.push_str(&format!(" AND creation_time <= '{}'", dt_str));
                }
            }
            // æ·»åŠ æ›´å¤šè¿‡æ»¤æ¡ä»¶
        }
        sql.push_str(" ORDER BY creation_time DESC");
        if let Some(limit) = criteria.limit {
            sql.push_str(&format!(" LIMIT {}", limit));
             if let Some(offset) = criteria.offset {
                sql.push_str(&format!(" OFFSET {}", offset));
            }
        }
        
        sqlx::query_as::<_, PersistedTestBatch>(&sql)
            .fetch_all(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))
    }
    
    async fn count_historical_batches(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        // ç®€åŒ–å®ç°
        let row = sqlx::query("SELECT COUNT(*) as count FROM persisted_test_batches")
            .fetch_one(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(row.try_get("count").unwrap_or(0))
    }

    async fn delete_old_test_records(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        let result = sqlx::query("DELETE FROM persisted_test_records WHERE created_at < ?")
            .bind(older_than.to_rfc3339())
            .execute(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(result.rows_affected() as usize)
    }

    async fn delete_old_test_batches(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        // æ³¨æ„ï¼šå¦‚æœè®¾ç½®äº†çº§è”åˆ é™¤ï¼Œåˆ é™¤æ‰¹æ¬¡ä¹Ÿä¼šåˆ é™¤å…¶ä¸‹çš„è®°å½•ã€‚
        // å¦‚æœæ²¡æœ‰çº§è”ï¼Œéœ€è¦å…ˆåˆ é™¤è®°å½•æˆ–å¤„ç†å­¤ç«‹è®°å½•ã€‚
        let result = sqlx::query("DELETE FROM persisted_test_batches WHERE created_at < ?")
            .bind(older_than.to_rfc3339())
            .execute(&self.pool).await
            .map_err(|e| AppError::PersistenceError(e.to_string()))?;
        Ok(result.rows_affected() as usize)
    }
}
```

##### 1.4.4 å®ç°å†…å­˜æŒä¹…åŒ–Repository (`MemoryPersistentRepository`) - ç”¨äºæµ‹è¯•å’Œå¼€å‘
```rust
// src/services/persistence/repositories/memory_persistent_repository.rs
// æˆ–è€… src/repositories/memory_persistent_repository.rs
use super::persistent_repository::*;
use std::sync::Arc;
use tokio::sync::RwLock;

pub struct MemoryPersistentRepository {
    records: Arc<RwLock<HashMap<String, PersistedTestRecord>>>,
    batches: Arc<RwLock<HashMap<String, PersistedTestBatch>>>,
}

impl MemoryPersistentRepository {
    pub fn new() -> Self {
        Self {
            records: Arc::new(RwLock::new(HashMap::new())),
            batches: Arc::new(RwLock::new(HashMap::new())),
        }
    }
}

#[async_trait]
impl IPersistentRepository for MemoryPersistentRepository {
    async fn initialize_schema(&self) -> Result<(), AppError> {
        // å†…å­˜å®ç°ä¸éœ€è¦åˆå§‹åŒ–è¡¨ç»“æ„
        Ok(())
    }

    async fn save_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        let mut records = self.records.write().await;
        records.insert(record.record_id.clone(), record.clone());
        Ok(())
    }

    async fn get_test_record_by_id(&self, record_id: &str) -> Result<Option<PersistedTestRecord>, AppError> {
        let records = self.records.read().await;
        Ok(records.get(record_id).cloned())
    }
    
    async fn list_test_records_by_batch_id(&self, batch_id: &str) -> Result<Vec<PersistedTestRecord>, AppError> {
        let records = self.records.read().await;
        Ok(records.values().filter(|r| r.test_batch_id == batch_id).cloned().collect())
    }

    async fn query_test_records(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestRecord>, AppError> {
        let records = self.records.read().await;
        let mut results: Vec<PersistedTestRecord> = records.values().cloned().collect();
        // å®ç°è¿‡æ»¤ã€æ’åºã€åˆ†é¡µ
        Ok(results)
    }
    
    async fn count_test_records(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        let records = self.records.read().await;
        Ok(records.len() as i64) // ç®€åŒ–
    }
    
    async fn update_test_record(&self, record: &PersistedTestRecord) -> Result<(), AppError> {
        let mut records = self.records.write().await;
        if records.contains_key(&record.record_id) {
            records.insert(record.record_id.clone(), record.clone());
            Ok(())
        } else {
            Err(AppError::RecordNotFound(record.record_id.clone()))
        }
    }

    async fn save_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
        let mut batches = self.batches.write().await;
        batches.insert(batch.batch_id.clone(), batch.clone());
        Ok(())
    }

    async fn get_test_batch_by_id(&self, batch_id: &str) -> Result<Option<PersistedTestBatch>, AppError> {
        let batches = self.batches.read().await;
        Ok(batches.get(batch_id).cloned())
    }
    
    async fn list_historical_batches(&self, criteria: QueryCriteria) -> Result<Vec<PersistedTestBatch>, AppError> {
        let batches = self.batches.read().await;
        let mut results: Vec<PersistedTestBatch> = batches.values().cloned().collect();
        // å®ç°è¿‡æ»¤ã€æ’åºã€åˆ†é¡µ
        Ok(results)
    }

    async fn count_historical_batches(&self, criteria: QueryCriteria) -> Result<i64, AppError> {
        let batches = self.batches.read().await;
        Ok(batches.len() as i64) // ç®€åŒ–
    }
    
    async fn update_test_batch(&self, batch: &PersistedTestBatch) -> Result<(), AppError> {
         let mut batches = self.batches.write().await;
        if batches.contains_key(&batch.batch_id) {
            batches.insert(batch.batch_id.clone(), batch.clone());
            Ok(())
        } else {
            Err(AppError::RecordNotFound(batch.batch_id.clone()))
        }
    }
    
    async fn delete_old_test_records(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        let mut records = self.records.write().await;
        let initial_len = records.len();
        records.retain(|_, record| record.created_at >= older_than);
        Ok(initial_len - records.len())
    }

    async fn delete_old_test_batches(&self, older_than: DateTime<Utc>) -> Result<usize, AppError> {
        let mut batches = self.batches.write().await;
        let initial_len = batches.len();
        batches.retain(|_, batch| batch.created_at >= older_than);
        Ok(initial_len - batches.len())
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 1.4)
æµ‹è¯•å°†åˆ†åˆ«é’ˆå¯¹ `SqlitePersistentRepository` å’Œ `MemoryPersistentRepository`ã€‚
å¯¹äº `SqlitePersistentRepository`ï¼Œæµ‹è¯•æ—¶å¯ä»¥ä½¿ç”¨å†…å­˜ä¸­çš„SQLiteæ•°æ®åº“ (`sqlite::memory:`) æˆ–ä¸´æ—¶æ–‡ä»¶æ•°æ®åº“ï¼Œå¹¶åœ¨æ¯æ¬¡æµ‹è¯•å‰åæ¸…ç†ã€‚

```rust
// src/services/persistence/repositories/tests/persistent_repository_tests.rs
// æˆ–è€… src/repositories/tests/persistent_repository_tests.rs
use crate::services::persistence::repositories::persistent_repository::*;
use crate::services::persistence::repositories::sqlite_persistent_repository::SqlitePersistentRepository;
use crate::services::persistence::repositories::memory_persistent_repository::MemoryPersistentRepository;
use crate::models::enums::{OverallTestStatus, TestResult, SubTestItem, ModuleType}; // å‡è®¾åœ¨models::enumsä¸­
use tokio;
use uuid::Uuid;
use chrono::{Utc, Duration};
use serde_json;
use std::collections::HashMap;

async fn persistent_repository_test_suite(repo_builder: impl Fn() -> Box<dyn IPersistentRepository>) {
    let repo = repo_builder();
    repo.initialize_schema().await.expect("Schema initialization failed"); // SQLite repoéœ€è¦

    // 1. æµ‹è¯•æ‰¹æ¬¡ (PersistedTestBatch)
    let batch1_id = Uuid::new_v4().to_string();
    let batch1 = PersistedTestBatch {
        batch_id: batch1_id.clone(),
        product_model: Some("ModelX-Persist".to_string()),
        serial_number: Some("SN-PERSIST-001".to_string()),
        customer_name: Some("Customer Persist".to_string()),
        creation_time: Utc::now() - Duration::days(1),
        completion_time: Some(Utc::now()),
        status_summary_text: "Completed".to_string(),
        total_points: 10, tested_points: 10, passed_points: 8, failed_points: 1, skipped_points: 1,
        report_path: Some("/reports/batch1.pdf".to_string()),
        created_at: Utc::now() - Duration::days(1),
        updated_at: Utc::now(),
    };
    repo.save_test_batch(&batch1).await.expect("Failed to save batch1");

    let fetched_batch1 = repo.get_test_batch_by_id(&batch1_id).await.unwrap().expect("Batch1 not found");
    assert_eq!(fetched_batch1.product_model, batch1.product_model);

    // 2. æµ‹è¯•è®°å½• (PersistedTestRecord)
    let record1_id = Uuid::new_v4().to_string();
    let sub_results: HashMap<SubTestItem, PersistedSubTestExecutionResult> = HashMap::from([
        (SubTestItem::HardPoint, PersistedSubTestExecutionResult { 
            result: TestResult::Passed, measured_value: Some(5.0), expected_value: Some(5.0), tolerance: Some(0.1), 
            timestamp: Utc::now(), error_message: None, duration_ms: Some(100)
        })
    ]);
    let record1 = PersistedTestRecord {
        record_id: record1_id.clone(),
        instance_id: Uuid::new_v4().to_string(),
        definition_id: Uuid::new_v4().to_string(),
        test_batch_id: batch1_id.clone(),
        product_model: batch1.product_model.clone(),
        serial_number: batch1.serial_number.clone(),
        overall_status_text: OverallTestStatus::TestCompletedPassed.to_string(),
        start_time: Some(Utc::now() - Duration::minutes(5)),
        final_test_time: Some(Utc::now()),
        total_test_duration_ms: Some(300000),
        error_message: None,
        sub_test_results_json: serde_json::to_string(&sub_results).unwrap(),
        tag: "AI_TAG_001_P".to_string(),
        variable_name: "Temperature Persisted".to_string(),
        plc_communication_address: "DB1.DBD0.P".to_string(),
        module_type_text: ModuleType::AI.to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    repo.save_test_record(&record1).await.expect("Failed to save record1");

    let fetched_record1 = repo.get_test_record_by_id(&record1_id).await.unwrap().expect("Record1 not found");
    assert_eq!(fetched_record1.tag, record1.tag);
    let deserialized_subs: HashMap<SubTestItem, PersistedSubTestExecutionResult> = serde_json::from_str(&fetched_record1.sub_test_results_json).unwrap();
    assert_eq!(deserialized_subs.len(), 1);
    
    // 3. æµ‹è¯•åˆ—è¡¨å’ŒæŸ¥è¯¢
    let records_in_batch1 = repo.list_test_records_by_batch_id(&batch1_id).await.unwrap();
    assert_eq!(records_in_batch1.len(), 1);

    // 4. æµ‹è¯•æ›´æ–°
    let mut updated_batch1 = fetched_batch1.clone();
    updated_batch1.status_summary_text = "Completed with remarks".to_string();
    updated_batch1.updated_at = Utc::now(); // Manually update for memory repo, DB repo might auto-update
    repo.update_test_batch(&updated_batch1).await.expect("Failed to update batch1");
    let fetched_after_update_b1 = repo.get_test_batch_by_id(&batch1_id).await.unwrap().unwrap();
    assert_eq!(fetched_after_update_b1.status_summary_text, "Completed with remarks");

    // 5. æµ‹è¯•æ•°æ®æ¸…ç† (å¦‚æœå®ç°)
    let old_batch_id = Uuid::new_v4().to_string();
    let old_batch_time = Utc::now() - Duration::days(100);
    let old_batch = PersistedTestBatch { batch_id: old_batch_id.clone(), creation_time: old_batch_time, updated_at: old_batch_time, ..batch1.clone() };
    repo.save_test_batch(&old_batch).await.unwrap();
    
    let deleted_batches = repo.delete_old_test_batches(Utc::now() - Duration::days(90)).await.unwrap();
    assert_eq!(deleted_batches, 1);
    assert!(repo.get_test_batch_by_id(&old_batch_id).await.unwrap().is_none());

    // TODO: æ›´å¤šQueryCriteriaçš„æµ‹è¯•
}

#[tokio::test]
async fn test_memory_persistent_repository() {
    persistent_repository_test_suite(|| Box::new(MemoryPersistentRepository::new())).await;
}

#[tokio::test]
async fn test_sqlite_persistent_repository() {
    // ä½¿ç”¨å†…å­˜SQLiteè¿›è¡Œæµ‹è¯•ï¼Œé¿å…æ–‡ä»¶æ®‹ç•™
    let db_url = "sqlite::memory:"; 
    // æˆ–è€…ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶: let temp_dir = tempfile::tempdir().unwrap(); let db_path = temp_dir.path().join("test_persist.db"); let db_url = format!("sqlite:{}", db_path.to_str().unwrap());
    
    let repo = SqlitePersistentRepository::new(&db_url).await.expect("Failed to create SQLite repo");
    persistent_repository_test_suite(|| Box::new(repo)).await; // `repo` needs to be cloneable or re-created
    // For non-memory DBs, ensure cleanup: // drop(temp_dir);
}

// ä¸º SqlitePersistentRepository æ·»åŠ  Cloneable åŒ…è£…æˆ–ä¿®æ”¹æµ‹è¯•å¥—ä»¶ä»¥æ¥å— Future<Output = Repo>
struct TestSqliteRepoBuilder {
    db_url: String,
}
impl TestSqliteRepoBuilder {
    async fn build(&self) -> Box<dyn IPersistentRepository> {
        Box::new(SqlitePersistentRepository::new(&self.db_url).await.unwrap())
    }
}
#[tokio::test]
async fn test_sqlite_persistent_repository_v2() {
    let db_url = "sqlite::memory:".to_string();
    let builder = TestSqliteRepoBuilder { db_url };
    persistent_repository_test_suite(|| {
        // This is tricky because the builder is async and the closure is not.
        // A simpler way for tests is to just create it directly.
        // For now, the original test_sqlite_persistent_repository is okay if repo is created inside.
        // The test suite function itself needs to handle the creation.
        let repo = futures::executor::block_on(SqlitePersistentRepository::new("sqlite::memory:")).unwrap();
        Box::new(repo)
    }).await;
}


```

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 1.4)
1.  `IPersistentRepository` æ¥å£ã€`PersistedTestRecord` å’Œ `PersistedTestBatch` ç»“æ„ä½“å®šä¹‰å®Œæˆã€‚
2.  `SqlitePersistentRepository` å®ç°å®Œæˆï¼Œèƒ½å¤Ÿä½¿ç”¨ `sqlx` ä¸SQLiteæ•°æ®åº“è¿›è¡Œäº¤äº’ï¼Œå®ŒæˆCRUDæ“ä½œã€‚
3.  `MemoryPersistentRepository` å®ç°å®Œæˆï¼Œæä¾›å†…å­˜ä¸­çš„æŒä¹…åŒ–æ¨¡æ‹Ÿã€‚
4.  SQLiteæ•°æ®åº“è¡¨ç»“æ„è®¾è®¡å®Œæ¯•ï¼Œå¹¶é€šè¿‡ `initialize_schema` æ–¹æ³•åœ¨ `SqlitePersistentRepository` ä¸­å®ç°è‡ªåŠ¨åˆ›å»ºã€‚
5.  JSONåºåˆ—åŒ–/ååºåˆ—åŒ– `sub_test_results_json` å­—æ®µå·¥ä½œæ­£å¸¸ã€‚
6.  å•å…ƒæµ‹è¯•è¦†ç›– `SqlitePersistentRepository` å’Œ `MemoryPersistentRepository` çš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ•°æ®ä¿å­˜ã€è¯»å–ã€æŸ¥è¯¢å’Œæ›´æ–°ã€‚
7.  ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒã€‚

---
### æ­¥éª¤ 1.5: Repository é›†æˆä¸é…ç½®æœåŠ¡

#### ğŸ¯ ç›®æ ‡
1.  å°†æ–°åˆ›å»ºçš„ Repositoryï¼ˆ`IConfigurationRepository`, `IRuntimeRepository`, `IPersistentRepository`ï¼‰é›†æˆåˆ°åº”ç”¨çš„çŠ¶æ€ç®¡ç†æˆ–Tauriçš„ `AppState` ä¸­ï¼Œä»¥ä¾¿åœ¨æ•´ä¸ªåº”ç”¨ä¸­é€šè¿‡ä¾èµ–æ³¨å…¥è®¿é—®ã€‚
2.  åˆ›å»ºä¸€ä¸ªç®€å•çš„é…ç½®æœåŠ¡ï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰ï¼Œç”¨äºåŠ è½½å’Œç®¡ç†åº”ç”¨çº§é…ç½®ï¼ˆä¾‹å¦‚æ•°æ®åº“è·¯å¾„ã€æ—¥å¿—çº§åˆ«ç­‰ï¼‰ï¼Œè¿™äº›é…ç½®å¯èƒ½å­˜å‚¨åœ¨æ–‡ä»¶ä¸­ï¼ˆå¦‚ `config.toml`ï¼‰ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.5.1 æ›´æ–° `AppState` (Tauri) æˆ–æœåŠ¡æ„é€ å‡½æ•°
åœ¨ `src-tauri/src/main.rs` æˆ– `src-tauri/src/lib.rs` (å–å†³äºæ‚¨çš„é¡¹ç›®ç»“æ„)ï¼Œä¿®æ”¹ `AppState` æˆ–ç”¨äºæ„å»ºæœåŠ¡çš„ç»“æ„ä½“ï¼Œä»¥åŒ…å«å¯¹æ–°Repositoryå®ä¾‹çš„å¼•ç”¨ (`Arc<dyn Trait>`)ã€‚

```rust
// åœ¨ src-tauri/src/lib.rs æˆ– main.rs ä¸­çš„ AppState (ç¤ºä¾‹)
use std::sync::Arc;
use crate::services::persistence::repositories::{
    configuration_repository::{IConfigurationRepository, MemoryConfigurationRepository}, // ä½¿ç”¨å…·ä½“å®ç°
    runtime_repository::{IRuntimeRepository, MemoryRuntimeRepository},
    persistent_repository::{IPersistentRepository, SqlitePersistentRepository, MemoryPersistentRepository}, // æ ¹æ®ç¯å¢ƒé€‰æ‹©
};
// ... å…¶ä»– use è¯­å¥ ...

pub struct AppState {
    pub config_repo: Arc<dyn IConfigurationRepository>,
    pub runtime_repo: Arc<dyn IRuntimeRepository>,
    pub persistent_repo: Arc<dyn IPersistentRepository>,
    // ... å…¶ä»–æœåŠ¡ ...
}

impl AppState {
    pub async fn new() -> Result<Self, AppError> { // AppError åº”åŒ…å«åˆå§‹åŒ–é”™è¯¯
        // é…ç½®Repository (é€šå¸¸æ˜¯å†…å­˜å®ç°)
        let config_repo = Arc::new(MemoryConfigurationRepository::new());
        // config_repo._populate_test_data().await; // å¯é€‰ï¼šå¡«å……åˆå§‹æµ‹è¯•æ•°æ®

        // è¿è¡Œæ—¶Repository (æ€»æ˜¯å†…å­˜å®ç°)
        let runtime_repo = Arc::new(MemoryRuntimeRepository::new());

        // æŒä¹…åŒ–Repository (SQLiteå®ç°)
        // æ•°æ®åº“è·¯å¾„åº”æ¥è‡ªé…ç½®æœåŠ¡
        let db_path = std::env::var("APP_DB_PATH").unwrap_or_else(|_| "fat_test_storage.db".to_string());
        log::info!("æ•°æ®åº“è·¯å¾„: {}", db_path);
        let persistent_repo = Arc::new(
            SqlitePersistentRepository::new(&format!("sqlite:{}?mode=rwc", db_path)).await?
        );
        // æˆ–è€…åœ¨æµ‹è¯•/å¼€å‘ç¯å¢ƒä¸­ä½¿ç”¨å†…å­˜ç‰ˆ
        // let persistent_repo = Arc::new(MemoryPersistentRepository::new());
        // persistent_repo.initialize_schema().await?; // ç¡®ä¿Memoryç‰ˆä¹Ÿæœ‰æ­¤æ–¹æ³•(è™½ç„¶æ˜¯ç©ºæ“ä½œ)

        Ok(Self {
            config_repo,
            runtime_repo,
            persistent_repo,
            // ... åˆå§‹åŒ–å…¶ä»–æœåŠ¡ ...
        })
    }
}

// åœ¨ Tauri setup é’©å­ä¸­:
// .manage(AppState::new().await.expect("Failed to create AppState"))
```

##### 1.5.2 åˆ›å»ºåº”ç”¨é…ç½®æœåŠ¡ (å¦‚æœéœ€è¦)
å¦‚æœåº”ç”¨çš„é…ç½®ï¼ˆå¦‚æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼‰éœ€è¦ä»æ–‡ä»¶åŠ è½½ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„æœåŠ¡ã€‚

```rust
// src/services/app_config_service.rs
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use crate::utils::error::AppError;

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AppConfig {
    pub database_url: String, // ä¾‹å¦‚ "sqlite:fat_test_data.db"
    pub log_level: String,    // ä¾‹å¦‚ "info", "debug"
    pub max_concurrent_tests: usize,
    // ... å…¶ä»–é…ç½® ...
}

impl Default for AppConfig {
    fn default() -> Self {
        Self {
            database_url: "sqlite:./fat_test_app_data.sqlite".to_string(),
            log_level: "info".to_string(),
            max_concurrent_tests: 4,
        }
    }
}

pub fn load_config(config_path: Option<&str>) -> Result<AppConfig, AppError> {
    let path_str = config_path.unwrap_or("config.toml");
    let config_file_path = PathBuf::from(path_str);

    if !config_file_path.exists() {
        log::warn!("é…ç½®æ–‡ä»¶ {} ä¸å­˜åœ¨, å°†åˆ›å»ºå¹¶ä½¿ç”¨é»˜è®¤é…ç½®ã€‚", path_str);
        let default_config = AppConfig::default();
        let toml_string = toml::to_string_pretty(&default_config)
            .map_err(|e| AppError::ConfigError(format!("åºåˆ—åŒ–é»˜è®¤é…ç½®å¤±è´¥: {}", e)))?;
        std::fs::write(&config_file_path, toml_string)
            .map_err(|e| AppError::ConfigError(format!("å†™å…¥é»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: {}", e)))?;
        return Ok(default_config);
    }

    let config_content = std::fs::read_to_string(config_file_path)
        .map_err(|e| AppError::ConfigError(format!("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {}", e)))?;
    
    toml::from_str(&config_content)
        .map_err(|e| AppError::ConfigError(format!("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: {}", e)))
}
```
**æ³¨æ„**: `AppError` éœ€è¦æœ‰ `ConfigError(String)` å˜ä½“ã€‚æ—¥å¿—è®°å½• (`log::warn`, `log::info`) éœ€è¦ `log` crateã€‚

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 1.5)
1.  **AppState åˆå§‹åŒ–æµ‹è¯•**: ç¼–å†™æµ‹è¯•ä»¥ç¡®ä¿ `AppState` èƒ½å¤ŸæˆåŠŸåˆå§‹åŒ–æ‰€æœ‰Repositoryï¼ˆåŒ…æ‹¬å¤„ç†æ•°æ®åº“è¿æ¥é”™è¯¯ï¼‰ã€‚
2.  **é…ç½®åŠ è½½æµ‹è¯•**: æµ‹è¯• `load_config` å‡½æ•°èƒ½å¦æ­£ç¡®åŠ è½½é…ç½®æ–‡ä»¶ï¼Œä»¥åŠåœ¨æ–‡ä»¶ä¸å­˜åœ¨æ—¶èƒ½å¦åˆ›å»ºé»˜è®¤é…ç½®ã€‚
3.  **ä¾èµ–æ³¨å…¥æµ‹è¯•**: åœ¨Tauriå‘½ä»¤æˆ–æœåŠ¡çš„å•å…ƒæµ‹è¯•ä¸­ï¼ŒéªŒè¯æ˜¯å¦èƒ½ä» `tauri::State<AppState>` æ­£ç¡®è·å–å¹¶ä½¿ç”¨Repositoryå®ä¾‹ã€‚

```rust
#[cfg(test)]
mod app_state_tests {
    use super::*; // å‡è®¾ AppState å’Œ AppError åœ¨å½“å‰æ¨¡å—æˆ–çˆ¶æ¨¡å—
    use crate::services::persistence::repositories::app_config_service; // å¼•å…¥é…ç½®æœåŠ¡

    #[tokio::test]
    async fn test_app_state_creation() {
        // ä¸ºäº†æµ‹è¯•ï¼Œå¯èƒ½éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨ä¸´æ—¶é…ç½®æ–‡ä»¶è·¯å¾„
        // std::env::set_var("APP_DB_PATH", "test_app_state.db");
        // let _ = std::fs::remove_file("test_app_state.db"); // æ¸…ç†æ—§æ–‡ä»¶
        
        // ä½¿ç”¨é…ç½®æœåŠ¡åŠ è½½é…ç½®
        let app_config = app_config_service::load_config(Some("test_config.toml")).unwrap_or_default();
        // è¿™é‡Œéœ€è¦ä¸€ç§æ–¹æ³•å°† app_config.database_url ä¼ é€’ç»™ AppState::new()
        // æˆ–è€… AppState::new() å†…éƒ¨è°ƒç”¨ load_config()
        // ä¸ºäº†ç®€å•ï¼Œå‡è®¾ AppState::new() èƒ½å¤„ç†å¥½é…ç½®
        
        let app_state_result = AppState::new().await; // å‡è®¾ AppState::new ä½¿ç”¨é»˜è®¤æˆ–å¯é…ç½®çš„DBè·¯å¾„
        assert!(app_state_result.is_ok(), "AppStateåˆ›å»ºå¤±è´¥: {:?}", app_state_result.err());
        
        let app_state = app_state_result.unwrap();
        // ç®€å•éªŒè¯repositoryæ˜¯å¦è¢«åˆå§‹åŒ– (ä¸èƒ½æ˜¯None)
        // æ­¤å¤„ä¸èƒ½ç›´æ¥è®¿é—® Arc<dyn Trait> çš„å…·ä½“ç±»å‹ï¼Œä½†å¯ä»¥è°ƒç”¨å…¶æ–¹æ³•
        let cfgs = app_state.config_repo.list_all_channel_definitions().await;
        assert!(cfgs.is_ok());

        // æ¸…ç†æµ‹è¯•æ•°æ®åº“æ–‡ä»¶
        // let _ = std::fs::remove_file("test_app_state.db");
        let _ = std::fs::remove_file("test_config.toml"); // æ¸…ç†æµ‹è¯•é…ç½®æ–‡ä»¶
    }
}

#[cfg(test)]
mod app_config_service_tests {
    use super::app_config_service::*; // å‡è®¾åœ¨åŒä¸€æ¨¡å—æˆ–é€šè¿‡superè®¿é—®

    #[test]
    fn test_load_default_config_if_not_exists() {
        let test_cfg_path = "temp_test_config.toml";
        let _ = std::fs::remove_file(test_cfg_path); //ç¡®ä¿æ–‡ä»¶ä¸å­˜åœ¨

        let config_result = load_config(Some(test_cfg_path));
        assert!(config_result.is_ok());
        let config = config_result.unwrap();
        assert_eq!(config.log_level, "info"); // æ£€æŸ¥é»˜è®¤å€¼

        assert!(PathBuf::from(test_cfg_path).exists(), "é»˜è®¤é…ç½®æ–‡ä»¶åº”å·²åˆ›å»º");
        let _ = std::fs::remove_file(test_cfg_path); //æ¸…ç†
    }

    #[test]
    fn test_load_existing_config() {
        let test_cfg_path = "temp_existing_config.toml";
        let test_content = r#"
            database_url = "sqlite:./my_custom_data.db"
            log_level = "debug"
            max_concurrent_tests = 8
        "#;
        std::fs::write(test_cfg_path, test_content).unwrap();

        let config_result = load_config(Some(test_cfg_path));
        assert!(config_result.is_ok());
        let config = config_result.unwrap();
        assert_eq!(config.database_url, "sqlite:./my_custom_data.db");
        assert_eq!(config.log_level, "debug");
        assert_eq!(config.max_concurrent_tests, 8);
        
        let _ = std::fs::remove_file(test_cfg_path); //æ¸…ç†
    }
}
```

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 1.5)
1.  `AppState` (æˆ–åŒç­‰ç»“æ„) æˆåŠŸåˆå§‹åŒ–å¹¶ç®¡ç†æ‰€æœ‰Repositoryçš„å®ä¾‹ã€‚
2.  `AppConfig` åŠ `load_config` å‡½æ•° (æˆ–ç±»ä¼¼æœºåˆ¶) èƒ½å¤Ÿæ­£ç¡®åŠ è½½åº”ç”¨é…ç½®ï¼Œç‰¹åˆ«æ˜¯æ•°æ®åº“è·¯å¾„ã€‚
3.  Tauriå‘½ä»¤æˆ–åº”ç”¨æœåŠ¡èƒ½å¤Ÿé€šè¿‡ä¾èµ–æ³¨å…¥æ­£ç¡®è·å–å’Œä½¿ç”¨Repositoryå®ä¾‹ã€‚
4.  ç›¸å…³çš„å•å…ƒæµ‹è¯•é€šè¿‡ã€‚

**Phase 1 å®Œæˆæ ‡å‡†æ€»ç»“**
*   æ‰€æœ‰Repositoryæ¥å£ (`IConfigurationRepository`, `IRuntimeRepository`, `IPersistentRepository`) åŠå…¶å†…å­˜å®ç°å’ŒSQLiteå®ç°ï¼ˆé’ˆå¯¹`IPersistentRepository`ï¼‰å‡å·²å®Œæˆã€‚
*   Excelå¯¼å…¥å¯¼å‡ºåŠŸèƒ½å·²è§„åˆ’æˆ–åˆæ­¥å®ç°ã€‚
*   æ‰€æœ‰Repositoryéƒ½ç»è¿‡äº†å……åˆ†çš„å•å…ƒæµ‹è¯•ï¼ŒåŒ…æ‹¬CRUDæ“ä½œã€æŸ¥è¯¢ã€æ‰¹é‡æ“ä½œå’Œè¾¹ç•Œæ¡ä»¶ã€‚
*   Repositoryå®ä¾‹å·²æˆåŠŸé›†æˆåˆ°åº”ç”¨çš„ä¸»çŠ¶æ€ç®¡ç† (`AppState`) ä¸­ã€‚
*   åº”ç”¨çº§é…ç½®ï¼ˆå¦‚æ•°æ®åº“è·¯å¾„ï¼‰å¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶åŠ è½½ã€‚
*   æ•´ä¸ªæ•°æ®è®¿é—®å±‚ä¸ä¸šåŠ¡é€»è¾‘è§£è€¦ï¼Œæé«˜äº†æ¨¡å—åŒ–å’Œå¯æµ‹è¯•æ€§ã€‚

---

## ğŸš€ Phase 2: çŠ¶æ€ç®¡ç†å™¨é‡æ„ (State Management)

### ğŸ“Œ é‡æ„åŸå›  (Phase 2)
`ChannelTestInstance` çš„çŠ¶æ€è½¬æ¢æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ä¹‹ä¸€ã€‚å¦‚æœçŠ¶æ€ç®¡ç†ä¸ä¸¥æ ¼ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´ã€ä¸šåŠ¡æµç¨‹é”™è¯¯æˆ–éš¾ä»¥è¿½è¸ªé—®é¢˜ã€‚å½“å‰å¯èƒ½å­˜åœ¨ï¼š
*   çŠ¶æ€å˜æ›´é€»è¾‘åˆ†æ•£ã€‚
*   ç¼ºä¹ç»Ÿä¸€çš„çŠ¶æ€è½¬æ¢è§„åˆ™æ ¡éªŒã€‚
*   çŠ¶æ€å˜æ›´äº‹ä»¶é€šçŸ¥ä¸å®Œå–„ã€‚

é‡æ„çŠ¶æ€ç®¡ç†å™¨ (`ChannelStateManager`) çš„ç›®æ ‡æ˜¯ï¼š
*   **é›†ä¸­æ§åˆ¶**: å®ç° `FAT-CSM-001`ï¼Œ`ChannelStateManager` æ˜¯å”¯ä¸€å…è®¸ä¿®æ”¹ `ChannelTestInstance` çŠ¶æ€çš„ç»„ä»¶ã€‚
*   **è§„åˆ™å¼ºåˆ¶**: å®ç° `FAT-CSM-002`ï¼Œæ‰€æœ‰çŠ¶æ€è½¬æ¢å¿…é¡»ç¬¦åˆé¢„å®šä¹‰çš„ä¸šåŠ¡é€»è¾‘è§„åˆ™ï¼Œå¹¶è®°å½•æ—¶é—´æˆ³ã€‚
*   **äº‹ä»¶é©±åŠ¨**: å®ç° `FAT-EVT-001`ï¼Œé‡è¦çŠ¶æ€å˜æ›´å¿…é¡»å‘å¸ƒäº‹ä»¶ç»™ç³»ç»Ÿå…¶ä»–éƒ¨åˆ†ï¼ˆå¦‚å‰ç«¯UIæ›´æ–°ï¼‰ã€‚
*   **è§£è€¦å’Œå¯æµ‹è¯•æ€§**: ä½¿çŠ¶æ€ç®¡ç†é€»è¾‘ç‹¬ç«‹ã€æ¸…æ™°ä¸”æ˜“äºæµ‹è¯•ã€‚

### æ­¥éª¤ 2.1: åˆ›å»ºå¢å¼ºçš„çŠ¶æ€ç®¡ç†å™¨æ¥å£å’Œå®ç°

#### ğŸ¯ ç›®æ ‡
è®¾è®¡ `IChannelStateManager` æ¥å£ï¼Œå¹¶å®ç° `EnhancedChannelStateManager`ï¼Œè¯¥å®ç°å°†ä¾èµ– `IRuntimeRepository` æ¥è·å–å’Œæ›´æ–° `ChannelTestInstance` çš„å®æ—¶çŠ¶æ€ã€‚å®ƒå°†åŒ…å«ä¸¥æ ¼çš„çŠ¶æ€è½¬æ¢é€»è¾‘å’Œäº‹ä»¶å‘å¸ƒæœºåˆ¶ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 2.1.1 å®šä¹‰çŠ¶æ€ç®¡ç†å™¨æ ¸å¿ƒæ¥å£ (`IChannelStateManager`) å’Œè¾…åŠ©ç»“æ„
```rust
// src/services/state_management/channel_state_manager.rs
// æˆ–è€… src/state_manager/mod.rs (æ ¹æ®æ‚¨çš„é¡¹ç›®ç»“æ„è°ƒæ•´)
use async_trait::async_trait;
use crate::models::runtime::{ChannelTestInstance, TestOutcome, ChannelRuntimeState, TestPhase, ErrorInfo, TimestampCollection, ProgressInfo}; // ä»models::runtimeå¼•å…¥
use crate::models::enums::{OverallTestStatus, SubTestItem, TestResult}; // ä»models::enumså¼•å…¥
use crate::utils::error::AppError; // ä½¿ç”¨é¡¹ç›®ç»Ÿä¸€çš„ AppError
use crate::services::persistence::repositories::runtime_repository::IRuntimeRepository; // ä¾èµ–è¿è¡Œæ—¶ä»“åº“
use std::sync::Arc;
use tokio::sync::broadcast; // ç”¨äºäº‹ä»¶å‘å¸ƒ
use chrono::{DateTime, Utc};
use std::collections::HashMap;
use serde::{Serialize, Deserialize}; // ç”¨äºäº‹ä»¶ç­‰

/// çŠ¶æ€è½¬æ¢è®°å½• (ä¸»è¦ç”¨äºå†…å­˜ä¸­çš„è¿è¡Œæ—¶å†å²ï¼ŒæŒä¹…åŒ–çš„æœ€ç»ˆçŠ¶æ€åœ¨PersistedTestRecord)
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct StateTransition {
    pub transition_id: String, // å”¯ä¸€ID
    pub instance_id: String,
    pub old_status: OverallTestStatus,
    pub new_status: OverallTestStatus,
    pub reason: String, // è½¬æ¢åŸå› ï¼Œä¾‹å¦‚ "æµ‹è¯•ç»“æœåº”ç”¨: HardPoint" æˆ– "ç”¨æˆ·å¼ºåˆ¶æ“ä½œ"
    pub timestamp: DateTime<Utc>,
    // pub operator_info: Option<String>, // æ“ä½œè€…ä¿¡æ¯ï¼Œæ ¹æ®æ‚¨çš„å†³å®šï¼Œæ­¤å¤„ç®€åŒ–ï¼Œä¸æŒä¹…åŒ–æ“ä½œè€…
}

/// çŠ¶æ€å˜æ›´äº‹ä»¶ (ç”¨äºå¹¿æ’­é€šçŸ¥)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StateChangeEvent {
    pub instance_id: String,
    pub old_status: OverallTestStatus,
    pub new_status: OverallTestStatus,
    pub transition_reason: String,
    pub timestamp: DateTime<Utc>,
    // pub operator_info: Option<String>, // åŒä¸Šï¼Œç®€åŒ–
    // å¯ä»¥åŒ…å«éƒ¨åˆ†æ›´æ–°åçš„ ChannelTestInstance æ•°æ®ï¼Œå¦‚æœå‰ç«¯éœ€è¦
    pub updated_instance_summary: Option<PartialChannelTestInstanceUpdate>,
}

/// ç”¨äºäº‹ä»¶çš„éƒ¨åˆ†å®ä¾‹æ›´æ–°æ•°æ® (æŒ‰éœ€å®šä¹‰)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PartialChannelTestInstanceUpdate {
    pub overall_status: OverallTestStatus,
    pub error_message: Option<String>,
    pub last_updated_time: DateTime<Utc>,
    // ... å…¶ä»–å‰ç«¯å¯èƒ½ç›´æ¥éœ€è¦çš„å­—æ®µ ...
}


/// çŠ¶æ€ç®¡ç†å™¨æ¥å£
#[async_trait]
pub trait IChannelStateManager: Send + Sync {
    /// è·å–æŒ‡å®šå®ä¾‹çš„å½“å‰è¿è¡Œæ—¶çŠ¶æ€æ‘˜è¦
    async fn get_current_runtime_state(&self, instance_id: &str) -> Result<ChannelRuntimeState, AppError>;

    /// æ£€æŸ¥æ˜¯å¦å¯ä»¥ä»å½“å‰çŠ¶æ€è½¬æ¢åˆ°ç›®æ ‡çŠ¶æ€ (ä¸æ‰§è¡Œè½¬æ¢)
    async fn can_transition_to(&self, instance_id: &str, target_status: OverallTestStatus) -> Result<bool, AppError>;

    /// è·å–æŒ‡å®šå®ä¾‹çš„è¿è¡Œæ—¶çŠ¶æ€è½¬æ¢å†å² (å†…å­˜ä¸­çš„çŸ­æœŸå†å²)
    async fn get_runtime_transition_history(&self, instance_id: &str) -> Result<Vec<StateTransition>, AppError>;

    /// åº”ç”¨æµ‹è¯•ç»“æœå¹¶ç›¸åº”åœ°è½¬æ¢çŠ¶æ€ (ä¸»è¦çš„çŠ¶æ€å˜æ›´å…¥å£)
    /// è¿™æ˜¯ç¬¦åˆ FAT-CSM-001 çš„æ ¸å¿ƒæ–¹æ³•
    async fn apply_raw_outcome(&self, instance_id: &str, outcome: &TestOutcome) -> Result<StateTransition, AppError>;

    /// å¼ºåˆ¶å°†å®ä¾‹è½¬æ¢åˆ°ç›®æ ‡çŠ¶æ€ (åº”è°¨æ…ä½¿ç”¨ï¼Œä¾‹å¦‚ç®¡ç†å‘˜æ“ä½œ)
    async fn force_state_transition(&self, instance_id: &str, target_status: OverallTestStatus, reason: String /*, operator_info: Option<String> */) -> Result<StateTransition, AppError>;
    
    /// é‡ç½®å®ä¾‹çŠ¶æ€ä»¥ä¾¿é‡æ–°æµ‹è¯•
    async fn reset_instance_for_retest(&self, instance_id: &str /*, operator_info: Option<String> */) -> Result<StateTransition, AppError>;

    // æ‰¹é‡çŠ¶æ€æ“ä½œ (å¯é€‰ï¼Œæ ¹æ®éœ€æ±‚)
    // async fn batch_apply_outcomes(&self, outcomes: Vec<(String, TestOutcome)>) -> Result<Vec<StateTransition>, AppError>;
    // async fn batch_reset_for_retest(&self, instance_ids: &[String]) -> Result<Vec<StateTransition>, AppError>;

    /// è®¢é˜…æ‰€æœ‰å®ä¾‹çš„çŠ¶æ€å˜æ›´äº‹ä»¶
    fn subscribe_to_all_state_changes(&self) -> broadcast::Receiver<StateChangeEvent>;
    
    /// è®¢é˜…ç‰¹å®šå®ä¾‹çš„çŠ¶æ€å˜æ›´äº‹ä»¶
    /// (P2.1.2 ç»†åŒ–)
    async fn subscribe_to_instance_state_changes(&self, instance_id: &str) -> Result<broadcast::Receiver<StateChangeEvent>, AppError>;
}
```

##### 2.1.2 å®šä¹‰çŠ¶æ€è½¬æ¢è§„åˆ™ (`StateTransitionRules`)
```rust
// src/services/state_management/state_transition_rules.rs
// æˆ–è€…åœ¨ channel_state_manager.rs å†…éƒ¨å®šä¹‰
use crate::models::enums::OverallTestStatus;
use std::collections::HashMap;

#[derive(Debug)]
pub struct StateTransitionRules {
    // å®šä¹‰ä»ä¸€ä¸ªçŠ¶æ€å¯ä»¥åˆæ³•è½¬æ¢åˆ°çš„çŠ¶æ€åˆ—è¡¨
    allowed_transitions: HashMap<OverallTestStatus, Vec<OverallTestStatus>>,
}

impl StateTransitionRules {
    pub fn new() -> Self {
        let mut rules = HashMap::new();
        // æ ¹æ® FAT_TEST é¡¹ç›®çš„ä¸šåŠ¡é€»è¾‘å®šä¹‰è§„åˆ™
        // ç¤ºä¾‹è§„åˆ™ (è¯·æ ¹æ®æ‚¨çš„å®é™…éœ€æ±‚è°ƒæ•´ï¼Œmainrules ä¸­å®šä¹‰çš„ OverallTestStatus è¾ƒç®€å•)
        // å‡è®¾ OverallTestStatus æœ‰æ›´å¤šçŠ¶æ€å¦‚: NotTested, WiringConfirmed, HardPointTesting, SubTesting, ManualTesting, TestCompletedPassed, TestCompletedFailed, Skipped
        rules.insert(OverallTestStatus::NotTested, vec![
            OverallTestStatus::WiringConfirmed, // ä¾‹å¦‚ï¼Œå¦‚æœæœ‰ç‚¹è¡¨å¯¼å…¥åçš„æ¥çº¿ç¡®è®¤æ­¥éª¤
            OverallTestStatus::HardPointTesting, // ç›´æ¥å¼€å§‹ç¡¬ç‚¹æµ‹è¯•
            OverallTestStatus::Skipped,          // ç”¨æˆ·é€‰æ‹©è·³è¿‡
            OverallTestStatus::ManualTesting,    // ç›´æ¥è¿›å…¥æ‰‹åŠ¨æµ‹è¯•
        ]);
        rules.insert(OverallTestStatus::WiringConfirmed, vec![
            OverallTestStatus::HardPointTesting,
            OverallTestStatus::Skipped,
            OverallTestStatus::NotTested, // å…è®¸è¿”å›
        ]);
        rules.insert(OverallTestStatus::HardPointTesting, vec![ // ç¡¬ç‚¹æµ‹è¯•ä¸­æˆ–ç¡¬ç‚¹æµ‹è¯•å®Œæˆï¼Œå‡†å¤‡è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
            OverallTestStatus::SubTesting,       // è¿›å…¥å­é¡¹æµ‹è¯• (å¦‚æŠ¥è­¦æµ‹è¯•)
            OverallTestStatus::ManualTesting,    // è¿›å…¥æ‰‹åŠ¨æµ‹è¯•
            OverallTestStatus::TestCompletedPassed, // å¦‚æœç¡¬ç‚¹æ˜¯æœ€åä¸€ä¸ªæµ‹è¯•ä¸”é€šè¿‡
            OverallTestStatus::TestCompletedFailed, // ç¡¬ç‚¹æµ‹è¯•å¤±è´¥
            OverallTestStatus::NotTested,        // é‡ç½®/é‡æµ‹
            OverallTestStatus::Skipped,          // å½“å‰æµ‹è¯•è¢«è·³è¿‡
        ]);
        rules.insert(OverallTestStatus::SubTesting, vec![ // å­é¡¹ï¼ˆå¦‚æŠ¥è­¦ï¼‰æµ‹è¯•ä¸­
            OverallTestStatus::SubTesting,       // å¦ä¸€ä¸ªå­é¡¹æµ‹è¯•
            OverallTestStatus::ManualTesting,
            OverallTestStatus::TestCompletedPassed,
            OverallTestStatus::TestCompletedFailed,
            OverallTestStatus::NotTested,
            OverallTestStatus::Skipped,
        ]);
        rules.insert(OverallTestStatus::ManualTesting, vec![
            OverallTestStatus::TestCompletedPassed,
            OverallTestStatus::TestCompletedFailed,
            OverallTestStatus::NotTested,
        ]);
        rules.insert(OverallTestStatus::TestCompletedPassed, vec![
            OverallTestStatus::NotTested, // å…è®¸é‡æµ‹
        ]);
        rules.insert(OverallTestStatus::TestCompletedFailed, vec![
            OverallTestStatus::NotTested, // å…è®¸é‡æµ‹æˆ–ä¿®å¤åé‡æµ‹
            OverallTestStatus::ManualTesting, // å¯èƒ½éœ€è¦æ‰‹åŠ¨å¹²é¢„
        ]);
        rules.insert(OverallTestStatus::Skipped, vec![
            OverallTestStatus::NotTested, // å…è®¸é‡æµ‹
            OverallTestStatus::HardPointTesting, // ä»è·³è¿‡çŠ¶æ€é‡æ–°å¼€å§‹æµ‹è¯•
        ]);
        
        // ç¡®ä¿æ‰€æœ‰ OverallTestStatus éƒ½ä½œä¸ºkeyå­˜åœ¨ï¼Œå³ä½¿å®ƒä¸èƒ½è½¬æ¢åˆ°ä»»ä½•å…¶ä»–çŠ¶æ€ (valueæ˜¯ç©ºvec)
        // ä¾‹å¦‚ï¼šå¦‚æœæœ‰ä¸€ä¸ªç»ˆæ€ ErrorRecoveryPendingï¼Œå®ƒå¯èƒ½ä¸å…è®¸è‡ªåŠ¨è½¬æ¢å‡ºå»
        Self { allowed_transitions: rules }
    }

    pub fn is_valid(&self, from: OverallTestStatus, to: OverallTestStatus) -> bool {
        if from == to { // é€šå¸¸å…è®¸åœç•™åœ¨å½“å‰çŠ¶æ€ï¼Œæˆ–è€…æŸäº›æ“ä½œåçŠ¶æ€ä¸å˜
            return true; 
        }
        self.allowed_transitions.get(&from).map_or(false, |allowed_next_states| {
            allowed_next_states.contains(&to)
        })
    }
}
```

##### 2.1.3 å®ç°å¢å¼ºçš„çŠ¶æ€ç®¡ç†å™¨ (`EnhancedChannelStateManager`)
```rust
// åœ¨ channel_state_manager.rs (ç»­)
use uuid::Uuid;
use tokio::sync::Mutex; // ç”¨äºè¿‡æ»¤çš„è®¢é˜…è€…åˆ—è¡¨
use crate::services::state_management::state_transition_rules::StateTransitionRules; // å¼•å…¥è§„åˆ™

const DEFAULT_EVENT_CHANNEL_CAPACITY: usize = 100;

pub struct EnhancedChannelStateManager {
    runtime_repo: Arc<dyn IRuntimeRepository>,
    // persistent_repo: Arc<dyn IPersistentRepository>, // çŠ¶æ€ç®¡ç†å™¨ä¸ç›´æ¥å†™æŒä¹…å±‚ï¼Œé‚£æ˜¯åº”ç”¨æœåŠ¡æˆ–ä»»åŠ¡æ‰§è¡Œå™¨çš„èŒè´£
    
    // è¿è¡Œæ—¶çŠ¶æ€è½¬æ¢å†å² (å†…å­˜ä¸­ï¼Œæ¯ä¸ªå®ä¾‹ä¸€ä¸ªåˆ—è¡¨)
    // Phase2ä¸­çš„ç¬¬ä¸‰ä¸ªé—®é¢˜ï¼šå½“ç”¨æˆ·å¯¼å…¥ç‚¹è¡¨å¹¶å¼€å§‹æµ‹è¯•çš„æ—¶å€™åç»­æ‰€æœ‰çš„æ“ä½œéƒ½åº”è¯¥åªæ“ä½œåŒä¸€ä¸ªæµ‹è¯•å¯¹è±¡çš„å®ä¾‹é›†åˆä½“ï¼Œ
    // æ‰€ä»¥å†…å­˜å¢åŠ çš„é—®é¢˜åº”è¯¥ä¸ä¼šå‡ºç°ã€‚å¯¹åº”çš„åœ¨å„ä¸ªèŠ‚ç‚¹å°†é›†åˆä½“è¿›è¡Œå…¥åº“å’Œæ›´æ–°å³å¯
    // è¿™ä¸ªå†å²æ˜¯è¿è¡Œæ—¶çš„ï¼Œç”¨äºçŸ­æœŸè¿½æº¯æˆ–UIå±•ç¤ºï¼›é•¿æœŸçš„ã€æœ€ç»ˆçš„æµ‹è¯•è®°å½•ç”± PersistedTestRecord å­˜å‚¨ã€‚
    runtime_histories: Arc<RwLock<HashMap<String, Vec<StateTransition>>>>,
    
    event_broadcaster: broadcast::Sender<StateChangeEvent>,
    transition_rules: Arc<StateTransitionRules>,

    // ç”¨äºç‰¹å®šå®ä¾‹äº‹ä»¶è®¢é˜…çš„è¿‡æ»¤ (P2.1.2 ç»†åŒ–)
    // ä½¿ç”¨Mutexä¿æŠ¤å†…éƒ¨çš„ specific_instance_broadcastersï¼Œå› ä¸º broadcast::Sender æœ¬èº«ä¸æ˜¯ Sync
    // æˆ–è€…ï¼Œæ›´ç®€å•çš„æ–¹å¼æ˜¯è®©è®¢é˜…è€…è‡ªè¡Œè¿‡æ»¤ï¼Œä½†æ¥å£è¦æ±‚æˆ‘ä»¬æä¾›è¿‡æ»¤åçš„ã€‚
    // ä¸‹é¢çš„æ–¹æ³•æ˜¯ä¸ºæ¯ä¸ªè¢«è®¢é˜…çš„ instance_id åˆ›å»ºä¸€ä¸ªæ–°çš„ broadcast channelï¼Œç„¶åè½¬å‘ã€‚
    // è¿™æ˜¯ä¸€ä¸ªå¯é€‰çš„é«˜çº§å®ç°ï¼Œå¦‚æœç®€å•å®ç°ï¼ˆè®¢é˜…è€…è‡ªè¡Œè¿‡æ»¤ï¼‰å¯æ¥å—ï¼Œå¯ä»¥ç®€åŒ–ã€‚
    // ä¸ºäº†æ€§èƒ½å’Œç®€åŒ–ï¼Œé€šå¸¸è®©è®¢é˜…è€…è‡ªè¡Œè¿‡æ»¤æ›´ä½³ã€‚ä½†æˆ‘ä»¬æŒ‰æ¥å£è¦æ±‚å°è¯•å®ç°è¿‡æ»¤å¹¿æ’­ã€‚
    // æ³¨æ„ï¼šä¸ºæ¯ä¸ª instance_id åˆ›å»ºç‹¬ç«‹çš„ broadcaster å¯èƒ½å¯¼è‡´ broadcaster æ•°é‡è¿‡å¤šã€‚
    // ä¸€ä¸ªæŠ˜ä¸­æ–¹æ¡ˆæ˜¯ï¼Œ`subscribe_to_instance_state_changes` è¿”å›ä¸€ä¸ªåŒ…è£…äº†ä¸» `Receiver` çš„æµï¼Œè¯¥æµè¿›è¡Œè¿‡æ»¤ã€‚
    // è¿™é‡Œï¼Œæˆ‘ä»¬å…ˆå®ç°ä¸€ä¸ªç®€å•çš„åŸºäºä¸» broadcaster çš„è¿‡æ»¤æµã€‚
}

impl EnhancedChannelStateManager {
    pub fn new(runtime_repo: Arc<dyn IRuntimeRepository>) -> Self {
        let (event_broadcaster, _) = broadcast::channel(DEFAULT_EVENT_CHANNEL_CAPACITY);
        Self {
            runtime_repo,
            runtime_histories: Arc::new(RwLock::new(HashMap::new())),
            event_broadcaster,
            transition_rules: Arc::new(StateTransitionRules::new()),
        }
    }

    async fn record_and_publish_transition(
        &self, 
        instance: &ChannelTestInstance, // ä¼ å…¥æ›´æ–°åçš„å®ä¾‹ç”¨äºè·å–éƒ¨åˆ†ä¿¡æ¯
        old_status: OverallTestStatus, 
        new_status: OverallTestStatus, 
        reason: String
    ) -> Result<StateTransition, AppError> {
        let transition = StateTransition {
            transition_id: Uuid::new_v4().to_string(),
            instance_id: instance.instance_id.clone(),
            old_status,
            new_status,
            reason: reason.clone(),
            timestamp: Utc::now(),
        };

        // è®°å½•è¿è¡Œæ—¶å†å²
        let mut histories = self.runtime_histories.write().await;
        histories.entry(instance.instance_id.clone()).or_default().push(transition.clone());

        // å‘å¸ƒäº‹ä»¶
        // Phase2ä¸­çš„ç¬¬äºŒä¸ªé—®é¢˜ï¼šçŠ¶æ€å®¡è®¡åº”è¯¥æ˜¯ä¸å¤ªéœ€è¦ã€‚ operator_info ç§»é™¤
        let event = StateChangeEvent {
            instance_id: instance.instance_id.clone(),
            old_status,
            new_status,
            transition_reason: reason,
            timestamp: transition.timestamp,
            updated_instance_summary: Some(PartialChannelTestInstanceUpdate { // å¡«å……éƒ¨åˆ†æ›´æ–°
                overall_status: new_status,
                error_message: instance.error_message.clone(),
                last_updated_time: instance.last_updated_time,
            })
        };
        
        if self.event_broadcaster.send(event).is_err() {
            log::warn!("çŠ¶æ€å˜æ›´äº‹ä»¶å‘å¸ƒå¤±è´¥ (instance_id: {}): æ— è®¢é˜…è€…æˆ–é€šé“å·²æ»¡ã€‚", instance.instance_id);
            // ä¸åº”å› äº‹ä»¶å‘å¸ƒå¤±è´¥è€Œä¸­æ–­æ ¸å¿ƒé€»è¾‘
        }
        Ok(transition)
    }
}

#[async_trait]
impl IChannelStateManager for EnhancedChannelStateManager {
    async fn get_current_runtime_state(&self, instance_id: &str) -> Result<ChannelRuntimeState, AppError> {
        let instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        
        // æ­¤å¤„åº”ä» ChannelTestInstance è½¬æ¢ä¸º ChannelRuntimeState
        // å‡è®¾ ChannelRuntimeState çš„å­—æ®µå¯ä»¥ä» ChannelTestInstance è®¡ç®—æˆ–æ˜ å°„å¾—åˆ°
        Ok(ChannelRuntimeState {
            instance_id: instance.instance_id.clone(),
            definition_id: instance.definition_id.clone(),
            test_batch_id: instance.test_batch_id.clone(),
            overall_status: instance.overall_status,
            current_phase: TestPhase::from_status(instance.overall_status), // å‡è®¾æœ‰æ­¤è½¬æ¢é€»è¾‘
            error_info: instance.error_message.map(ErrorInfo::new),
            timestamps: TimestampCollection::from_instance(&instance), // å‡è®¾æœ‰æ­¤è½¬æ¢é€»è¾‘
            progress_info: ProgressInfo::calculate(&instance), // å‡è®¾æœ‰æ­¤è½¬æ¢é€»è¾‘
            sub_test_results: instance.sub_test_results.clone(),
            // ... å…¶ä»–æ‰€éœ€å­—æ®µ
        })
    }

    async fn can_transition_to(&self, instance_id: &str, target_status: OverallTestStatus) -> Result<bool, AppError> {
        let instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        Ok(self.transition_rules.is_valid(instance.overall_status, target_status))
    }

    async fn get_runtime_transition_history(&self, instance_id: &str) -> Result<Vec<StateTransition>, AppError> {
        let histories = self.runtime_histories.read().await;
        Ok(histories.get(instance_id).cloned().unwrap_or_default())
    }

    async fn apply_raw_outcome(&self, instance_id: &str, outcome: &TestOutcome) -> Result<StateTransition, AppError> {
        let mut instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        let new_status: OverallTestStatus;

        // æ ¸å¿ƒçŠ¶æ€å†³å®šé€»è¾‘ (åŸºäº FAT_TESTé‡æ„ä¼˜åŒ–æ–¹æ¡ˆ.md ä¸­çš„çŠ¶æ€å›¾æˆ–æ‚¨çš„å…·ä½“ä¸šåŠ¡)
        match outcome.result {
            TestResult::Passed => {
                // æ ¹æ®å½“å‰æµ‹è¯•é¡¹å’Œæ•´ä½“æµç¨‹å†³å®šä¸‹ä¸€ä¸ªçŠ¶æ€
                // ä¾‹å¦‚ï¼Œå¦‚æœå½“å‰æ˜¯HardPointä¸”é€šè¿‡ï¼Œå¯èƒ½è¿›å…¥SubTestingæˆ–ManualTestingæˆ–ç›´æ¥CompletedPassed
                // éœ€è¦æ›´è¯¦ç»†çš„ä¸šåŠ¡è§„åˆ™æ¥ç²¾ç¡®å®šä¹‰
                match outcome.test_item {
                    SubTestItem::HardPoint => new_status = OverallTestStatus::HardPointTesting, // æˆ–è€… WiringConfirmed -> HardPointTesting
                    // SubTestItem::LowAlarm | SubTestItem::HighAlarm => {
                    //     // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­æµ‹è¯•éƒ½å·²å®Œæˆ
                    //     // if all_subtests_done_for_current_phase(&instance, outcome.test_item) {
                    //     //    new_status = OverallTestStatus::TestCompletedPassed; // æˆ–è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
                    //     // } else {
                    //     //    new_status = OverallTestStatus::SubTesting; // ç»§ç»­æµ‹å…¶ä»–å­é¡¹
                    //     // }
                    // }
                    _ => new_status = OverallTestStatus::TestCompletedPassed, // ç®€åŒ–ï¼šå‡è®¾å…¶ä»–é€šè¿‡åˆ™ç›´æ¥å®Œæˆ
                }
                // å¦‚æœä¸Šé¢è®¾ç½®ä¸º HardPointTestingï¼Œè¿™é‡Œå¯èƒ½éœ€è¦æ ¹æ®å…·ä½“æµç¨‹å›¾å†æ¬¡åˆ¤æ–­
                // ä¾‹å¦‚ï¼Œè‹¥ç¡¬ç‚¹æµ‹è¯•åæ²¡æœ‰å…¶ä»–è‡ªåŠ¨æµ‹è¯•ï¼Œåˆ™å¯èƒ½æ˜¯ TestCompletedPassed
                // æ­¤å¤„é€»è¾‘éœ€è¦éå¸¸ç²¾ç¡®åœ°æ˜ å°„æ‚¨çš„çŠ¶æ€å›¾
                if new_status == OverallTestStatus::HardPointTesting && !self.transition_rules.is_valid(old_status, new_status) {
                    // å°è¯•ä¸€ä¸ªæ›´åˆç†çš„é»˜è®¤ "é€šè¿‡" çŠ¶æ€
                    new_status = OverallTestStatus::TestCompletedPassed;
                }
            }
            TestResult::Failed => {
                new_status = OverallTestStatus::TestCompletedFailed;
            }
            TestResult::Skipped => {
                new_status = OverallTestStatus::Skipped;
            }
            TestResult::InProgress => {
                // æ ¹æ®å½“å‰æµ‹è¯•é¡¹å†³å®šè¿›è¡Œä¸­çš„çŠ¶æ€
                match outcome.test_item {
                    SubTestItem::HardPoint => new_status = OverallTestStatus::HardPointTesting,
                    // SubTestItem::LowAlarm | SubTestItem::HighAlarm => new_status = OverallTestStatus::SubTesting,
                    _ => new_status = OverallTestStatus::ManualTesting, // é»˜è®¤å…¶ä»–è¿›è¡Œä¸­è½¬ä¸ºæ‰‹åŠ¨
                }
            }
        }

        if !self.transition_rules.is_valid(old_status, new_status) {
            return Err(AppError::StateTransitionError(format!(
                "ä» {:?} åˆ° {:?} çš„çŠ¶æ€è½¬æ¢ä¸å…è®¸ (æµ‹è¯•é¡¹: {:?}, ç»“æœ: {:?})", 
                old_status, new_status, outcome.test_item, outcome.result
            )));
        }

        // æ›´æ–°å®ä¾‹
        instance.overall_status = new_status;
        instance.last_updated_time = Utc::now();
        instance.error_message = outcome.error_message.clone(); // ä¿å­˜é”™è¯¯ä¿¡æ¯
        
        // æ›´æ–°æˆ–æ·»åŠ å­æµ‹è¯•ç»“æœ (ç¡®ä¿ SubTestExecutionResult ä¸ TestOutcome å­—æ®µåŒ¹é…)
        instance.sub_test_results.insert(outcome.test_item, SubTestExecutionResult {
            result: outcome.result,
            measured_value: outcome.measured_value,
            expected_value: outcome.expected_value,
            tolerance: outcome.tolerance,
            timestamp: Utc::now(),
            error_message: outcome.error_message.clone(),
            duration_ms: outcome.duration_ms,
        });
        if outcome.result == TestResult::Passed && instance.start_time.is_none() && new_status != OverallTestStatus::NotTested {
             instance.start_time = Some(Utc::now()); // é¦–æ¬¡æœ‰æ•ˆæ“ä½œæ—¶è®°å½•å¼€å§‹æ—¶é—´
        }
        if new_status == OverallTestStatus::TestCompletedPassed || new_status == OverallTestStatus::TestCompletedFailed {
            instance.final_test_time = Some(Utc::now());
            if let Some(start) = instance.start_time {
                instance.total_test_duration_ms = Some((Utc::now() - start).num_milliseconds());
            }
        }


        self.runtime_repo.update_channel_instance(&instance).await?;
        
        self.record_and_publish_transition(&instance, old_status, new_status, 
            format!("æµ‹è¯•ç»“æœåº”ç”¨: {:?} ({:?})", outcome.test_item, outcome.result)
        ).await
    }

    async fn force_state_transition(&self, instance_id: &str, target_status: OverallTestStatus, reason: String) -> Result<StateTransition, AppError> {
        let mut instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        // å¯¹äºå¼ºåˆ¶è½¬æ¢ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥æ£€æŸ¥è§„åˆ™ï¼Œä½†é€šå¸¸æ˜¯ç»•è¿‡å®ƒæˆ–æœ‰ä¸€å¥—ç‰¹æ®Šçš„â€œå¼ºåˆ¶â€è§„åˆ™
        // log::warn!("å¼ºåˆ¶çŠ¶æ€è½¬æ¢: {} ä» {:?} åˆ° {:?}ï¼ŒåŸå› : {}", instance_id, old_status, target_status, reason);

        instance.overall_status = target_status;
        instance.last_updated_time = Utc::now();
        instance.error_message = Some(format!("å¼ºåˆ¶çŠ¶æ€è½¬æ¢: {}", reason)); // è®°å½•åŸå› 

        self.runtime_repo.update_channel_instance(&instance).await?;
        self.record_and_publish_transition(&instance, old_status, target_status, reason).await
    }
    
    async fn reset_instance_for_retest(&self, instance_id: &str) -> Result<StateTransition, AppError> {
        let mut instance = self.runtime_repo.get_channel_instance(instance_id).await?
            .ok_or_else(|| AppError::InstanceNotFound(instance_id.to_string()))?;

        let old_status = instance.overall_status;
        let target_status = OverallTestStatus::NotTested; // é‡ç½®ç›®æ ‡çŠ¶æ€

        if !self.transition_rules.is_valid(old_status, target_status) && old_status != target_status { // å¦‚æœå·²ç»æ˜¯NotTestedåˆ™æ— éœ€æŠ¥é”™
             log::warn!("å°è¯•ä» {:?} é‡ç½®åˆ° {:?}ï¼Œè§„åˆ™ä¸Šå¯èƒ½ä¸å…è®¸ï¼Œä½†å°†ç»§ç»­æ‰§è¡Œé‡ç½®é€»è¾‘ã€‚", old_status, target_status);
        }

        instance.overall_status = target_status;
        instance.current_step_details = None;
        instance.error_message = None;
        instance.start_time = None;
        instance.final_test_time = None;
        instance.total_test_duration_ms = None;
        instance.sub_test_results.clear();
        instance.hardpoint_readings = None;
        instance.manual_test_current_value_input = None;
        instance.manual_test_current_value_output = None;
        instance.last_updated_time = Utc::now();

        self.runtime_repo.update_channel_instance(&instance).await?;
        self.record_and_publish_transition(&instance, old_status, target_status, "é‡ç½®ä»¥è¿›è¡Œé‡æµ‹".to_string()).await
    }

    fn subscribe_to_all_state_changes(&self) -> broadcast::Receiver<StateChangeEvent> {
        self.event_broadcaster.subscribe()
    }
    
    // P2.1.2 ç»†åŒ–: è®¢é˜…ç‰¹å®šå®ä¾‹äº‹ä»¶
    // å®ç°æ–¹å¼1ï¼šè¿”å›ä¸€ä¸ªè¿‡æ»¤æµ (æ¨èï¼Œæ›´é«˜æ•ˆï¼Œé¿å…ç®¡ç†å¤šä¸ªbroadcaster)
    async fn subscribe_to_instance_state_changes(&self, instance_id: &str) -> Result<broadcast::Receiver<StateChangeEvent>, AppError> {
        // æ³¨æ„ï¼šbroadcast::Receiver æœ¬èº«ä¸èƒ½ç›´æ¥è¢«è¿‡æ»¤ç„¶åè¿”å›ä¸€ä¸ªæ–°çš„ Receiverã€‚
        // è°ƒç”¨è€…è·å–ä¸» Receiver åï¼Œéœ€è¦è‡ªè¡Œä½¿ç”¨å¦‚ `tokio_stream::StreamExt::filter` æ¥å¤„ç†ã€‚
        // ä¸ºäº†ç¬¦åˆæ¥å£ç­¾åå¹¶â€œæä¾›â€è¿‡æ»¤ï¼Œä¸€ä¸ªæ–¹æ³•æ˜¯åˆ›å»ºä¸€ä¸ªæ–°çš„ channelï¼Œå¹¶åœ¨ä¸€ä¸ªä»»åŠ¡ä¸­ä»ä¸» channel æ¥æ”¶ã€è¿‡æ»¤ã€è½¬å‘ã€‚
        // ä½†è¿™ä¼šä¸ºæ¯ä¸ªè®¢é˜…è€…åˆ›å»ºä¸€ä¸ªä»»åŠ¡å’Œ channelï¼Œå¼€é”€è¾ƒå¤§ã€‚
        
        // ç®€åŒ–å’Œæ¨èçš„åšæ³•æ˜¯ï¼šè°ƒç”¨è€…è·å–ä¸» Receiverï¼Œç„¶åè‡ªå·±è¿‡æ»¤ã€‚
        // å¦‚æœæ¥å£è®¾è®¡å¼ºåˆ¶è¦æ±‚æœåŠ¡è¿›è¡Œè¿‡æ»¤å¹¶è¿”å›ä¸€ä¸ªâ€œå·²è¿‡æ»¤â€çš„ Receiverï¼Œé‚£ä¹ˆå®ç°ä¼šå¤æ‚å¾ˆå¤šã€‚
        // è¿™é‡Œæˆ‘ä»¬è¿”å›ä¸» Receiverï¼Œå¹¶åœ¨æ–‡æ¡£/æ³¨é‡Šä¸­è¯´æ˜è°ƒç”¨è€…éœ€è¦è¿‡æ»¤ã€‚
        // æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥è¿”å›ä¸€ä¸ªåŒ…è£…ç±»å‹ï¼Œå®ƒå†…éƒ¨æŒæœ‰ Receiver å¹¶å®ç° Stream trait è¿›è¡Œè¿‡æ»¤ã€‚
        
        // **æœ€ç®€å•çš„ç¬¦åˆæ¥å£ç­¾åçš„æ–¹å¼ï¼ˆä½†ä¸æ˜¯æœ€é«˜æ•ˆçš„ï¼Œä¹Ÿä¸æ˜¯çœŸæ­£çš„ç‹¬ç«‹è¿‡æ»¤channelï¼‰ï¼š**
        // è¿”å›ä¸»å¹¿æ’­å™¨çš„è®¢é˜…è€…ï¼Œå¹¶æ˜ç¡®å‘ŠçŸ¥è°ƒç”¨æ–¹éœ€è¦è‡ªè¡Œè¿‡æ»¤ã€‚
        // å¦‚æœç¡®å®éœ€è¦æœåŠ¡ç«¯è¿‡æ»¤ï¼Œåº”è¯¥ä¿®æ”¹æ¥å£è¿”å›ç±»å‹ä¸ºç±»ä¼¼ `impl Stream<Item = StateChangeEvent>`
        log::debug!("ä¸ºå®ä¾‹ {} åˆ›å»ºçŠ¶æ€å˜æ›´è®¢é˜… (è®¢é˜…è€…éœ€è‡ªè¡Œè¿‡æ»¤)", instance_id);
        Ok(self.event_broadcaster.subscribe())
        // è¦å®ç°çœŸæ­£çš„è¿‡æ»¤å Receiverï¼Œéœ€è¦æ›´å¤æ‚çš„æœºåˆ¶ï¼Œå¦‚ä¸ºæ¯ä¸ª instance_id ç»´æŠ¤ä¸€ä¸ª mpsc::channelï¼Œ
        // ç„¶åæœ‰ä¸€ä¸ªåå°ä»»åŠ¡ç›‘å¬ä¸» broadcastï¼Œå¹¶å‘åŒ¹é…çš„ mpsc::channel å‘é€ã€‚
        // è¿™è¶…å‡ºäº†å½“å‰æ­¥éª¤çš„å…¸å‹å®ç°å¤æ‚åº¦ã€‚
        // æœ€ç¬¦åˆå½“å‰ Rustç”Ÿæ€çš„åšæ³•æ˜¯è®©è°ƒç”¨è€…ä½¿ç”¨ Stream API è¿›è¡Œè¿‡æ»¤ã€‚
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 2.1)
```rust
// src/services/state_management/tests/enhanced_channel_state_manager_tests.rs
// æˆ–è€… src/state_manager/tests.rs
use crate::services::state_management::channel_state_manager::*;
use crate::services::persistence::repositories::runtime_repository::{MemoryRuntimeRepository, IRuntimeRepository};
use crate::models::runtime::{ChannelTestInstance, TestOutcome};
use crate::models::enums::{OverallTestStatus, SubTestItem, TestResult};
use std::sync::Arc;
use tokio;
use uuid::Uuid;
use chrono::Utc;

async fn setup_manager_and_instance(initial_status: OverallTestStatus) -> (Arc<EnhancedChannelStateManager>, String) {
    let runtime_repo = Arc::new(MemoryRuntimeRepository::new());
    let manager = Arc::new(EnhancedChannelStateManager::new(runtime_repo.clone()));
    
    let instance_id = Uuid::new_v4().to_string();
    let instance = ChannelTestInstance {
        instance_id: instance_id.clone(),
        definition_id: Uuid::new_v4().to_string(),
        test_batch_id: "batch_sm_test".to_string(),
        overall_status: initial_status,
        last_updated_time: Utc::now(),
        // ... å…¶ä»–å­—æ®µåˆå§‹åŒ– ...
        current_step_details: None, error_message: None, start_time: None, final_test_time: None,
        total_test_duration_ms: None, sub_test_results: HashMap::new(), hardpoint_readings: None,
        manual_test_current_value_input: None, manual_test_current_value_output: None,
    };
    runtime_repo.save_channel_instance(&instance).await.unwrap();
    (manager, instance_id)
}

#[tokio::test]
async fn test_sm_initial_state_and_valid_transition() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;

    let state = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state.overall_status, OverallTestStatus::NotTested);

    let can_transition = manager.can_transition_to(&instance_id, OverallTestStatus::HardPointTesting).await.unwrap();
    assert!(can_transition, "Should be able to transition from NotTested to HardPointTesting");
    
    let cannot_transition = manager.can_transition_to(&instance_id, OverallTestStatus::TestCompletedPassed).await.unwrap();
    assert!(!cannot_transition, "Should not be able to directly transition from NotTested to TestCompletedPassed without intermediate steps");
}

#[tokio::test]
async fn test_sm_apply_outcome_passed() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    let outcome = TestOutcome {
        test_item: SubTestItem::HardPoint,
        result: TestResult::Passed,
        // ... å…¶ä»– outcome å­—æ®µ ...
        measured_value: None, expected_value: None, tolerance: None, duration_ms: None, error_message: None,
    };

    let transition = manager.apply_raw_outcome(&instance_id, &outcome).await.unwrap();
    // åŸºäºStateTransitionRulesï¼Œä»NotTestedé€šè¿‡HardPointæµ‹è¯•ï¼Œå¯èƒ½è¿›å…¥HardPointTestingæˆ–TestCompletedPassed
    // æ­¤å¤„å‡è®¾è¿›å…¥ HardPointTesting (è¡¨ç¤ºç¡¬ç‚¹æµ‹è¯•è¿™ä¸ªé˜¶æ®µå·²é€šè¿‡ï¼Œä½†å¯èƒ½è¿˜æœ‰åç»­)
    // å¦‚æœè§„åˆ™æ˜¯ä»NotTestedé€šè¿‡HardPointç›´æ¥åˆ°TestCompletedPassedï¼Œåˆ™ä¿®æ”¹æœŸæœ›å€¼
    assert_eq!(transition.new_status, OverallTestStatus::HardPointTesting); 

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::HardPointTesting);
    assert!(state_after.sub_test_results.contains_key(&SubTestItem::HardPoint));
}

#[tokio::test]
async fn test_sm_apply_outcome_failed() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::HardPointTesting).await;
    let outcome = TestOutcome {
        test_item: SubTestItem::HardPoint, // å‡è®¾æ˜¯ç¡¬ç‚¹æµ‹è¯•å¤±è´¥
        result: TestResult::Failed,
        error_message: Some("Sensor reading out of range".to_string()),
        // ...
        measured_value: None, expected_value: None, tolerance: None, duration_ms: None,
    };

    let transition = manager.apply_raw_outcome(&instance_id, &outcome).await.unwrap();
    assert_eq!(transition.new_status, OverallTestStatus::TestCompletedFailed);

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::TestCompletedFailed);
    assert_eq!(state_after.error_info.unwrap().message, "Sensor reading out of range");
}


#[tokio::test]
async fn test_sm_invalid_transition_via_apply_outcome() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::TestCompletedPassed).await;
     let outcome = TestOutcome { // å°è¯•ä»æœªå…è®¸çš„çŠ¶æ€è½¬æ¢
        test_item: SubTestItem::HardPoint,
        result: TestResult::InProgress, // TestCompletedPassed -> HardPointTesting (InProgress) é€šå¸¸ä¸å…è®¸
        measured_value: None, expected_value: None, tolerance: None, duration_ms: None, error_message: None,
    };
    let result = manager.apply_raw_outcome(&instance_id, &outcome).await;
    assert!(result.is_err());
    if let Err(AppError::StateTransitionError(msg)) = result {
        println!("æ•è·åˆ°é¢„æœŸçš„çŠ¶æ€è½¬æ¢é”™è¯¯: {}", msg);
    } else {
        panic!("æœªæ•è·åˆ°é¢„æœŸçš„StateTransitionErrorï¼Œå®é™…é”™è¯¯: {:?}", result.err());
    }
}


#[tokio::test]
async fn test_sm_force_transition() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    let reason = "ç®¡ç†å‘˜æ“ä½œ".to_string();
    
    let transition = manager.force_state_transition(&instance_id, OverallTestStatus::Skipped, reason.clone()).await.unwrap();
    assert_eq!(transition.new_status, OverallTestStatus::Skipped);
    assert_eq!(transition.reason, reason);

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::Skipped);
}

#[tokio::test]
async fn test_sm_reset_for_retest() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::TestCompletedFailed).await;
    
    // ç»™å®ä¾‹æ·»åŠ ä¸€äº›å†å²æ•°æ®
    let mut inst = manager.runtime_repo.get_channel_instance(&instance_id).await.unwrap().unwrap();
    inst.error_message = Some("Previous error".to_string());
    inst.sub_test_results.insert(SubTestItem::HardPoint, SubTestExecutionResult::default());
    manager.runtime_repo.update_channel_instance(&inst).await.unwrap();
    
    let transition = manager.reset_instance_for_retest(&instance_id).await.unwrap();
    assert_eq!(transition.new_status, OverallTestStatus::NotTested);

    let state_after = manager.get_current_runtime_state(&instance_id).await.unwrap();
    assert_eq!(state_after.overall_status, OverallTestStatus::NotTested);
    assert!(state_after.error_info.is_none());
    assert!(state_after.sub_test_results.is_empty());
}

#[tokio::test]
async fn test_sm_event_subscription_and_filtering() {
    let (manager, instance1_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    let (_, instance2_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await; // ç¬¬äºŒä¸ªå®ä¾‹

    let mut rx_all = manager.subscribe_to_all_state_changes();
    // P2.1.2: æ¥å£è¦æ±‚è¿”å› Receiverï¼Œå®é™…è¿‡æ»¤ç”±è°ƒç”¨è€…å®Œæˆ
    let mut rx_inst1 = manager.subscribe_to_instance_state_changes(&instance1_id).await.unwrap();

    let outcome = TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() };
    
    // è§¦å‘instance1çš„äº‹ä»¶
    manager.apply_raw_outcome(&instance1_id, &outcome).await.unwrap();
    // è§¦å‘instance2çš„äº‹ä»¶
    manager.apply_raw_outcome(&instance2_id, &outcome).await.unwrap();

    let mut events_for_all_count = 0;
    let mut events_for_inst1_count = 0;

    // ä» rx_all æ¥æ”¶æ‰€æœ‰äº‹ä»¶
    for _ in 0..2 { // æœŸæœ›æ”¶åˆ°ä¸¤ä¸ªäº‹ä»¶
        if let Ok(event) = tokio::time::timeout(std::time::Duration::from_secs(1), rx_all.recv()).await {
            events_for_all_count +=1;
            println!("rx_all received: {:?}", event.unwrap().instance_id);
        } else {
            break;
        }
    }
    assert_eq!(events_for_all_count, 2, "rx_all should receive events from both instances");
    
    // ä» rx_inst1 æ¥æ”¶äº‹ä»¶å¹¶è¿‡æ»¤
    // ç”±äº rx_inst1 å®é™…æ˜¯ä¸»å¹¿æ’­çš„æ‹·è´ï¼Œå®ƒä¹Ÿä¼šæ”¶åˆ°ä¸¤ä¸ªäº‹ä»¶ï¼Œéœ€è¦æ‰‹åŠ¨è¿‡æ»¤
    let mut actual_inst1_events = 0;
     for _ in 0..2 { // å°è¯•æ¥æ”¶ä¸¤ä¸ªäº‹ä»¶
        if let Ok(Ok(event)) = tokio::time::timeout(std::time::Duration::from_secs(1), rx_inst1.recv()).await {
             if event.instance_id == instance1_id {
                events_for_inst1_count += 1;
                println!("rx_inst1 (filtered) received: {:?}", event.instance_id);
             }
        } else {
            break; // è¶…æ—¶æˆ–é€šé“å…³é—­
        }
    }
    assert_eq!(events_for_inst1_count, 1, "rx_inst1 (after filtering) should only count event for instance1_id");
}


#[tokio::test]
async fn test_sm_runtime_history() {
    let (manager, instance_id) = setup_manager_and_instance(OverallTestStatus::NotTested).await;
    
    let outcome1 = TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::InProgress, ..Default::default() };
    manager.apply_raw_outcome(&instance_id, &outcome1).await.unwrap();
    
    let outcome2 = TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() };
    manager.apply_raw_outcome(&instance_id, &outcome2).await.unwrap();

    let history = manager.get_runtime_transition_history(&instance_id).await.unwrap();
    assert_eq!(history.len(), 2);
    assert_eq!(history[0].old_status, OverallTestStatus::NotTested);
    // å‡è®¾ InProgress ä¼šè½¬ä¸º HardPointTesting
    assert_eq!(history[0].new_status, OverallTestStatus::HardPointTesting); 
    assert_eq!(history[1].old_status, OverallTestStatus::HardPointTesting);
    // å‡è®¾ Passed ä¼šè½¬ä¸º TestCompletedPassed (æˆ–å–å†³äºè§„åˆ™ï¼Œå¯èƒ½æ˜¯HardPointTestingçš„å®Œæˆ)
    assert_eq!(history[1].new_status, OverallTestStatus::TestCompletedPassed); 
}
```

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 2.1)
1.  `IChannelStateManager` æ¥å£ã€`EnhancedChannelStateManager` å®ç°ã€`StateTransitionRules` å’Œç›¸å…³äº‹ä»¶/è¾…åŠ©ç»“æ„å®šä¹‰å®Œæˆã€‚
2.  çŠ¶æ€è½¬æ¢ä¸¥æ ¼éµå¾ª `StateTransitionRules`ï¼Œéæ³•è½¬æ¢è¢«é˜»æ­¢ã€‚
3.  `apply_raw_outcome` ä½œä¸ºä¸»è¦çŠ¶æ€å˜æ›´å…¥å£ï¼Œæ­£ç¡®å¤„ç†æµ‹è¯•ç»“æœå¹¶æ›´æ–°å®ä¾‹çŠ¶æ€ã€‚
4.  å¼ºåˆ¶è½¬æ¢å’Œé‡ç½®åŠŸèƒ½æŒ‰é¢„æœŸå·¥ä½œã€‚
5.  çŠ¶æ€å˜æ›´äº‹ä»¶é€šè¿‡ `tokio::sync::broadcast` æ­£ç¡®å‘å¸ƒï¼Œè®¢é˜…è€…å¯ä»¥æ¥æ”¶ã€‚
6.  `subscribe_to_instance_state_changes` èƒ½æä¾›é’ˆå¯¹ç‰¹å®šå®ä¾‹çš„äº‹ä»¶æµï¼ˆé€šè¿‡è°ƒç”¨è€…è¿‡æ»¤ä¸» `Receiver`ï¼‰ã€‚
7.  è¿è¡Œæ—¶çŠ¶æ€è½¬æ¢å†å²è¢«æ­£ç¡®è®°å½•åœ¨å†…å­˜ä¸­ã€‚
8.  å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬å„ç§çŠ¶æ€è½¬æ¢åœºæ™¯ã€äº‹ä»¶å‘å¸ƒå’Œå†å²è®°å½•ã€‚
9.  ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒã€‚

---

## ğŸš€ Phase 3: ä»»åŠ¡è°ƒåº¦å™¨ä¸æ‰§è¡Œå™¨é‡æ„ (Task Scheduling & Execution)

### ğŸ“Œ é‡æ„åŸå›  (Phase 3)
è‡ªåŠ¨åŒ–æµ‹è¯•ç³»ç»Ÿéœ€è¦ä¸€ä¸ªå¼ºå¤§çš„ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œæ ¸å¿ƒæ¥ç®¡ç†å’Œè¿è¡Œæµ‹è¯•åºåˆ—ã€‚å½“å‰å¯èƒ½ç¼ºä¹ï¼š
*   çµæ´»çš„ä»»åŠ¡ä¼˜å…ˆçº§å’Œä¾èµ–ç®¡ç†ã€‚
*   ç²¾ç»†çš„å¹¶å‘æ§åˆ¶ï¼ˆ`FAT-TTM-001`ï¼‰ã€‚
*   æ ‡å‡†åŒ–çš„æµ‹è¯•æ­¥éª¤æ‰§è¡Œæ¥å£ï¼ˆ`FAT-CTK-001`ï¼‰ã€‚
*   æ¸…æ™°çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆæš‚åœã€æ¢å¤ã€å–æ¶ˆã€é‡è¯•ï¼‰ã€‚
*   ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„äº‹ä»¶é€šçŸ¥å’ŒçŠ¶æ€åé¦ˆã€‚

æ­¤é˜¶æ®µçš„ç›®æ ‡æ˜¯è®¾è®¡å¹¶å®ç° `ITaskScheduler`ï¼ˆä»»åŠ¡è°ƒåº¦å™¨ï¼‰å’Œ `ISpecificTestStepExecutor`ï¼ˆå…·ä½“æµ‹è¯•æ­¥éª¤æ‰§è¡Œå™¨ï¼‰ä½“ç³»ï¼Œå‚è€ƒ `TestTaskManager.cs` çš„ä¼˜ç§€è®¾è®¡ï¼Œå¹¶ç»“åˆRustå¼‚æ­¥ç”Ÿæ€è¿›è¡Œä¼˜åŒ–ã€‚

### æ­¥éª¤ 3.1: å®šä¹‰ä»»åŠ¡è°ƒåº¦å™¨å’Œæ‰§è¡Œå™¨æ¥å£

#### ğŸ¯ ç›®æ ‡
å®šä¹‰ `ITaskScheduler` æ¥å£ç”¨äºç®¡ç†å’Œè°ƒåº¦æµ‹è¯•ä»»åŠ¡ï¼Œ`ISpecificTestStepExecutor` æ¥å£ç”¨äºå°è£…å•ä¸ªå…·ä½“æµ‹è¯•æ­¥éª¤çš„æ‰§è¡Œé€»è¾‘ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 3.1.1 å®šä¹‰ä»»åŠ¡ç›¸å…³çš„æ•°æ®ç»“æ„
```rust
// src/services/task_scheduling/task_models.rs (æˆ–ç±»ä¼¼æ¨¡å—)
use crate::models::enums::{SubTestItem, TaskPriority, TaskStatus};
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition, TestOutcome}; // å‡è®¾è¿™äº›å·²å®šä¹‰
use crate::utils::error::AppError;
use chrono::{DateTime, Utc};
use std::collections::HashMap;
use serde::{Serialize, Deserialize};
use uuid::Uuid;
use std::sync::Arc;
use crate::services::plc_communication::IPlcCommunicationService; // PLCæœåŠ¡æ¥å£

/// æµ‹è¯•ä»»åŠ¡å®šä¹‰ (ç”±åº”ç”¨æœåŠ¡å±‚åˆ›å»ºï¼Œäº¤ç»™è°ƒåº¦å™¨)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestTask {
    pub task_id: String,              // å”¯ä¸€ä»»åŠ¡ID
    pub instance_id: String,          //å…³è”çš„ ChannelTestInstance ID
    pub definition_id: String,        // å…³è”çš„ ChannelPointDefinition ID
    pub batch_id: String,             // æ‰€å±æ‰¹æ¬¡ID
    pub sub_test_item: SubTestItem,   // å½“å‰ä»»åŠ¡è¦æ‰§è¡Œçš„å…·ä½“æµ‹è¯•é¡¹
    pub priority: TaskPriority,
    pub created_at: DateTime<Utc>,
    pub max_retries: u32,             // æœ€å¤§é‡è¯•æ¬¡æ•°
    pub timeout_ms: Option<u64>,      // ä»»åŠ¡æ‰§è¡Œè¶…æ—¶
    // pub dependencies: Vec<String>, // ä¾èµ–çš„å…¶ä»–task_idï¼Œç®€åŒ–ï¼šå½“å‰ç‰ˆæœ¬ä¸å®ç°å¤æ‚ä¾èµ–
    pub metadata: Option<HashMap<String, String>>, // å…¶ä»–å…ƒæ•°æ®
}

impl TestTask {
    pub fn new(instance_id: &str, definition_id: &str, batch_id: &str, sub_test_item: SubTestItem) -> Self {
        Self {
            task_id: Uuid::new_v4().to_string(),
            instance_id: instance_id.to_string(),
            definition_id: definition_id.to_string(),
            batch_id: batch_id.to_string(),
            sub_test_item,
            priority: TaskPriority::Normal,
            created_at: Utc::now(),
            max_retries: 1, // é»˜è®¤é‡è¯•1æ¬¡
            timeout_ms: Some(30000), // é»˜è®¤30ç§’è¶…æ—¶
            metadata: None,
        }
    }
}


/// ä»»åŠ¡å¥æŸ„ (è°ƒåº¦å™¨è¿”å›ç»™è°ƒç”¨è€…ï¼Œç”¨äºåç»­æ“ä½œ)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct TaskHandle(pub String); // ä½¿ç”¨Stringç±»å‹çš„task_id

/// ä»»åŠ¡è¿è¡Œæ—¶ä¿¡æ¯ (è°ƒåº¦å™¨å†…éƒ¨æˆ–æŸ¥è¯¢æ—¶ä½¿ç”¨)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskRuntimeInfo {
    pub handle: TaskHandle,
    pub task_definition: TestTask, // åŸå§‹ä»»åŠ¡å®šä¹‰
    pub status: TaskStatus,
    pub current_retry_count: u32,
    pub scheduled_at: DateTime<Utc>,
    pub started_at: Option<DateTime<Utc>>,
    pub completed_at: Option<DateTime<Utc>>,
    pub error_message: Option<String>,
    // pub progress_percentage: f64, // å¯¹äºå•ä¸ªæµ‹è¯•é¡¹ä»»åŠ¡ï¼Œè¿›åº¦å¯èƒ½åªæ˜¯0æˆ–100
}

/// ä»»åŠ¡äº‹ä»¶ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum TaskEventType {
    Scheduled,
    Started,
    AttemptFailed, // ä¸€æ¬¡å°è¯•å¤±è´¥ (å¯èƒ½é‡è¯•)
    CompletedSuccessfully,
    CompletedWithFailure, // æ‰€æœ‰é‡è¯•åæœ€ç»ˆå¤±è´¥
    Cancelled,
    // Paused, Resumed, // Phase3ä¸­çš„ç¬¬ä¸‰ä¸ªé—®é¢˜ï¼šç®€åŒ–ï¼Œæš‚ä¸å®ç°æš‚åœ/æ¢å¤å•ä¸ªä»»åŠ¡
}

/// ä»»åŠ¡äº‹ä»¶ (ç”±è°ƒåº¦å™¨å‘å¸ƒ)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskExecutionEvent {
    pub task_handle: TaskHandle,
    pub instance_id: String,
    pub batch_id: String,
    pub sub_test_item: SubTestItem,
    pub event_type: TaskEventType,
    pub timestamp: DateTime<Utc>,
    pub details: Option<String>, // ä¾‹å¦‚é”™è¯¯ä¿¡æ¯
    pub outcome: Option<TestOutcome>, // ä»»åŠ¡å®Œæˆæ—¶ï¼ŒåŒ…å«æ‰§è¡Œç»“æœ
}
```

##### 3.1.2 å®šä¹‰ `ISpecificTestStepExecutor` æ¥å£
```rust
// src/services/task_scheduling/test_executors.rs (æˆ–ç±»ä¼¼æ¨¡å—)
use async_trait::async_trait;
// (å¼•å…¥ä¸Šé¢å®šä¹‰çš„ TestTask, TaskRuntimeInfo, TestOutcome ç­‰)
// (å¼•å…¥ ChannelTestInstance, ChannelPointDefinition, IPlcCommunicationService, AppError)
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition, TestOutcome};
use crate::models::enums::SubTestItem;
use crate::utils::error::AppError;
use crate::services::plc_communication::IPlcCommunicationService;
use std::sync::Arc;


/// å…·ä½“æµ‹è¯•æ­¥éª¤æ‰§è¡Œå™¨æ¥å£ (FAT-CTK-001)
/// æ¯ä¸ªå®ç°ç±»è´Ÿè´£æ‰§è¡Œä¸€ä¸ªç‰¹å®šç±»å‹çš„ SubTestItemã€‚
#[async_trait]
pub trait ISpecificTestStepExecutor: Send + Sync {
    /// è¿”å›æ­¤æ‰§è¡Œå™¨å¤„ç†çš„ SubTestItem ç±»å‹
    fn item_type(&self) -> SubTestItem;

    /// æ‰§è¡Œæµ‹è¯•æ­¥éª¤
    /// - `task`: å½“å‰æ‰§è¡Œçš„ä»»åŠ¡å®šä¹‰ã€‚
    /// - `instance`: ç›®æ ‡ ChannelTestInstance çš„å½“å‰çŠ¶æ€ (å¯å˜å¼•ç”¨ï¼Œå…è®¸æ‰§è¡Œå™¨åœ¨æŸäº›æƒ…å†µä¸‹æ›´æ–°ä¸´æ—¶çŠ¶æ€ï¼Œä½†æœ€ç»ˆçŠ¶æ€åº”ç”±StateManagerå¤„ç†)ã€‚
    /// - `definition`: ç›®æ ‡ ChannelPointDefinitionã€‚
    /// - `plc_service`: ç”¨äºä¸PLCé€šä¿¡çš„å…±äº«æœåŠ¡å®ä¾‹ã€‚
    /// è¿”å› TestOutcomeï¼ŒåŒ…å«æµ‹è¯•ç»“æœå’Œç›¸å…³æ•°æ®ã€‚
    async fn execute(
        &self,
        task: &TestTask, // åŒ…å« instance_id, definition_id, sub_test_item ç­‰
        instance_snapshot: &ChannelTestInstance, // æ‰§è¡Œå‰çš„å®ä¾‹å¿«ç…§ï¼Œåªè¯»
        definition: &ChannelPointDefinition,
        plc_service: Arc<dyn IPlcCommunicationService>, // å…·ä½“çš„PLCé€šä¿¡æœåŠ¡
    ) -> Result<TestOutcome, AppError>; // TestOutcome åº”åŒ…å«è¶³å¤Ÿä¿¡æ¯ä¾› StateManager æ›´æ–°çŠ¶æ€
}
```

##### 3.1.3 å®šä¹‰ `ITaskScheduler` æ¥å£
```rust
// src/services/task_scheduling/scheduler.rs (æˆ–ç±»ä¼¼æ¨¡å—)
use async_trait::async_trait;
// (å¼•å…¥ä¸Šé¢å®šä¹‰çš„ TestTask, TaskHandle, TaskRuntimeInfo, TaskExecutionEvent ç­‰)
// (å¼•å…¥ AppError, TaskPriority)
use crate::services::task_scheduling::task_models::{TestTask, TaskHandle, TaskRuntimeInfo, TaskExecutionEvent};
use crate::utils::error::AppError;
use crate::models::enums::TaskPriority;
use tokio::sync::broadcast;


/// ä»»åŠ¡è°ƒåº¦å™¨æ¥å£ (FAT-TTM-001)
#[async_trait]
pub trait ITaskScheduler: Send + Sync {
    /// æäº¤å•ä¸ªæµ‹è¯•ä»»åŠ¡åˆ°è°ƒåº¦é˜Ÿåˆ—
    async fn schedule_task(&self, task: TestTask) -> Result<TaskHandle, AppError>;

    /// æ‰¹é‡æäº¤æµ‹è¯•ä»»åŠ¡
    async fn schedule_tasks_batch(&self, tasks: Vec<TestTask>) -> Result<Vec<TaskHandle>, AppError>;
    
    /// å–æ¶ˆä¸€ä¸ªå¾…å¤„ç†æˆ–æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
    /// Phase3ä¸­çš„ç¬¬å››ä¸ªé—®é¢˜ï¼šç®€åŒ–å–æ¶ˆé€»è¾‘
    async fn cancel_task(&self, task_handle: &TaskHandle) -> Result<(), AppError>;

    /// å–æ¶ˆæŒ‡å®šæ‰¹æ¬¡ä¸‹çš„æ‰€æœ‰å¾…å¤„ç†æˆ–æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
    async fn cancel_tasks_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError>; // è¿”å›å–æ¶ˆçš„ä»»åŠ¡æ•°é‡

    /// è·å–ä»»åŠ¡çš„å½“å‰è¿è¡Œæ—¶ä¿¡æ¯ (çŠ¶æ€ã€è¿›åº¦ç­‰)
    async fn get_task_runtime_info(&self, task_handle: &TaskHandle) -> Result<Option<TaskRuntimeInfo>, AppError>;

    /// è·å–æŒ‡å®šæ‰¹æ¬¡ä¸‹æ‰€æœ‰ä»»åŠ¡çš„è¿è¡Œæ—¶ä¿¡æ¯
    async fn list_tasks_by_batch_id(&self, batch_id: &str) -> Result<Vec<TaskRuntimeInfo>, AppError>;
    
    /// è·å–å½“å‰æ´»åŠ¨çš„ä»»åŠ¡æ•°é‡ (Pending + Running)
    async fn get_active_task_count(&self) -> Result<usize, AppError>;

    /// è®¢é˜…ä»»åŠ¡æ‰§è¡Œäº‹ä»¶
    fn subscribe_to_task_events(&self) -> broadcast::Receiver<TaskExecutionEvent>;

    /// è®¾ç½®æœ€å¤§å¹¶å‘æµ‹è¯•æ•° (FAT-TTM-001)
    async fn set_max_concurrent_tasks(&self, limit: usize) -> Result<(), AppError>;
    
    /// è·å–å½“å‰æœ€å¤§å¹¶å‘æ•°
    async fn get_max_concurrent_tasks(&self) -> Result<usize, AppError>;

    /// ä¼˜é›…åœ°å…³é—­è°ƒåº¦å™¨ï¼Œç­‰å¾…æ´»åŠ¨ä»»åŠ¡å®Œæˆï¼ˆåœ¨è¶…æ—¶èŒƒå›´å†…ï¼‰
    async fn shutdown(&self, timeout_ms: Option<u64>) -> Result<(), AppError>;
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 3.1)
æ­¤æ­¥éª¤ä¸»è¦å®šä¹‰æ¥å£å’Œæ•°æ®ç»“æ„ï¼Œç›´æ¥çš„å•å…ƒæµ‹è¯•è¾ƒå°‘ã€‚æµ‹è¯•é‡ç‚¹åœ¨äºï¼š
1.  **ç¼–è¯‘æ£€æŸ¥**: ç¡®ä¿æ‰€æœ‰æ¥å£ã€ç»“æ„ä½“å®šä¹‰æ­£ç¡®ï¼Œç±»å‹åŒ¹é…ã€‚
2.  **æ•°æ®ç»“æ„åºåˆ—åŒ–/ååºåˆ—åŒ–**: å¦‚æœè¿™äº›ç»“æ„ä½“éœ€è¦åœ¨ç½‘ç»œä¸Šä¼ è¾“æˆ–å­˜å‚¨ï¼ˆä¾‹å¦‚ `TestTask` å¯èƒ½ä»å¤–éƒ¨ä¼ å…¥ï¼‰ï¼Œæµ‹è¯•å…¶ `serde` åŠŸèƒ½ã€‚
3.  **æ–‡æ¡£å’Œæ¸…æ™°åº¦**: å®¡æŸ¥æ¥å£å’Œç»“æ„ä½“å®šä¹‰çš„æ³¨é‡Šæ˜¯å¦æ¸…æ™°ï¼Œç”¨é€”æ˜¯å¦æ˜ç¡®ã€‚

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 3.1)
1.  `TestTask`, `TaskHandle`, `TaskRuntimeInfo`, `TaskExecutionEvent` ç­‰æ ¸å¿ƒæ•°æ®ç»“æ„å®šä¹‰å®Œæˆã€‚
2.  `ISpecificTestStepExecutor` æ¥å£å®šä¹‰å®Œæˆï¼Œæ˜ç¡®äº†æ‰§è¡Œå•ä¸ªæµ‹è¯•æ­¥éª¤çš„å¥‘çº¦ã€‚
3.  `ITaskScheduler` æ¥å£å®šä¹‰å®Œæˆï¼Œæ˜ç¡®äº†ä»»åŠ¡è°ƒåº¦ã€æ§åˆ¶å’ŒæŸ¥è¯¢çš„å„é¡¹åŠŸèƒ½ã€‚
4.  æ‰€æœ‰å®šä¹‰ç¬¦åˆé¡¹ç›®ä»£ç è§„èŒƒã€‚

---
### æ­¥éª¤ 3.2: å®ç°å…·ä½“æµ‹è¯•æ­¥éª¤æ‰§è¡Œå™¨ (`ISpecificTestStepExecutor` çš„å®ç°ç±»)

#### ğŸ¯ ç›®æ ‡
æ ¹æ® `FAT-CTK-001`ï¼ˆæ¯ä¸ªæ‰§è¡Œå™¨å¤„ç†å•ä¸€æµ‹è¯•æ­¥éª¤ï¼‰ï¼Œä¸ºæ ¸å¿ƒçš„ `SubTestItem`ï¼ˆä¾‹å¦‚ `HardPoint`ï¼Œä»¥åŠåç»­çš„æŠ¥è­¦æµ‹è¯•å¦‚ `LowAlarm`, `HighAlarm` ç­‰ï¼‰åˆ›å»ºå…·ä½“çš„å®ç°ç±»ã€‚è¿™äº›æ‰§è¡Œå™¨å°†å°è£…ä¸PLCäº¤äº’çš„é€»è¾‘ï¼Œæ‰§è¡Œæµ‹è¯•å¹¶è¿”å› `TestOutcome`ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 3.2.1 å®ç°ç¡¬ç‚¹æµ‹è¯•æ‰§è¡Œå™¨ (`HardPointTestExecutor`)
ç¡¬ç‚¹æµ‹è¯•é€šå¸¸æ¶‰åŠè¯»å–PLCä¸­æŸä¸ªåœ°å€çš„æ¨¡æ‹Ÿé‡æˆ–æ•°å­—é‡ï¼Œå¹¶ä¸é¢„æœŸèŒƒå›´ï¼ˆå¯èƒ½æ¥è‡ª `ChannelPointDefinition` æˆ– `TestParameterSet`ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚

```rust
// src/services/task_scheduling/executors/hardpoint_test_executor.rs
use crate::services::task_scheduling::task_models::{TestTask, TestOutcome}; // ä» 3.1.1 å¼•å…¥
use crate::services::task_scheduling::test_executors::ISpecificTestStepExecutor; // ä» 3.1.2 å¼•å…¥
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition};
use crate::models::enums::{SubTestItem, TestResult, PointDataType}; // å‡è®¾PointDataTypeå·²å®šä¹‰
use crate::utils::error::AppError;
use crate::services::plc_communication::IPlcCommunicationService; // PLCæœåŠ¡æ¥å£
use std::sync::Arc;
use chrono::Utc;
use async_trait::async_trait;

pub struct HardPointTestExecutor;

impl HardPointTestExecutor {
    pub fn new() -> Self { Self }
}

#[async_trait]
impl ISpecificTestStepExecutor for HardPointTestExecutor {
    fn item_type(&self) -> SubTestItem {
        SubTestItem::HardPoint
    }

    async fn execute(
        &self,
        task: &TestTask,
        instance_snapshot: &ChannelTestInstance, // åªè¯»å¿«ç…§
        definition: &ChannelPointDefinition,
        plc_service: Arc<dyn IPlcCommunicationService>,
    ) -> Result<TestOutcome, AppError> {
        log::info!("å¼€å§‹æ‰§è¡Œç¡¬ç‚¹æµ‹è¯•: instance_id={}, task_id={}, plc_addr={}",
            task.instance_id, task.task_id, definition.plc_communication_address);

        let start_time = Utc::now();
        let mut outcome = TestOutcome {
            test_item: self.item_type(),
            result: TestResult::InProgress, // åˆå§‹çŠ¶æ€
            measured_value: None,
            expected_value: definition.range_lower_limit, // ç®€åŒ–ï¼šæœŸæœ›å€¼å¯èƒ½æ›´å¤æ‚æˆ–æ¥è‡ªå‚æ•°é›†
            tolerance: None, // åº”ä» TestParameterSet è·å–
            duration_ms: None,
            error_message: None,
            timestamp: start_time,
        };

        // 1. ä» TestParameterSet (é€šè¿‡ definition.module_type æŸ¥è¯¢ ConfigurationRepository) è·å–å®¹å·®ç­‰å‚æ•°
        //    (æ­¤å¤„ç®€åŒ–ï¼Œå‡è®¾å®¹å·®å·²çŸ¥æˆ–ä¸åœ¨æ­¤å¤„å¤„ç†)
        let tolerance = definition.engineering_unit.as_ref().map_or(0.1, |_| 0.1); // ç¤ºä¾‹å®¹å·®

        // 2. æ ¹æ® definition.data_type å’Œ definition.plc_communication_address è¯»å–PLCå€¼
        let read_value: f64; // æ ‡å‡†åŒ–ä¸º f64 ä¾¿äºæ¯”è¾ƒ

        match definition.data_type {
            PointDataType::Bool | PointDataType::Digital => {
                let plc_bool_val = plc_service.read_bool(&definition.plc_communication_address).await
                    .map_err(|e| {
                        outcome.result = TestResult::Failed;
                        outcome.error_message = Some(format!("PLCè¯»å–å¸ƒå°”å€¼å¤±è´¥: {}", e));
                        AppError::PlcCommunicationError(format!("HardPoint ReadBool Error: {}", e))
                    })?;
                read_value = if plc_bool_val { 1.0 } else { 0.0 };
                // å¯¹äºæ•°å­—é‡ï¼Œé¢„æœŸå€¼å’ŒèŒƒå›´å¯èƒ½ä¸åŒï¼Œæ­¤å¤„ç®€åŒ–
                outcome.expected_value = Some(1.0); // å‡è®¾æœŸæœ›ç¡¬ç‚¹ä¸ºON
            }
            PointDataType::Float | PointDataType::Analog => {
                read_value = plc_service.read_f32(&definition.plc_communication_address).await
                    .map_err(|e| {
                        outcome.result = TestResult::Failed;
                        outcome.error_message = Some(format!("PLCè¯»å–æµ®ç‚¹æ•°å¤±è´¥: {}", e));
                        AppError::PlcCommunicationError(format!("HardPoint ReadF32 Error: {}", e))
                    })? as f64;
            }
            PointDataType::Int16 | PointDataType::Int32 | PointDataType::Integer => {
                 read_value = plc_service.read_i32(&definition.plc_communication_address).await // å‡è®¾æœ‰ read_i32
                    .map_err(|e| {
                        outcome.result = TestResult::Failed;
                        outcome.error_message = Some(format!("PLCè¯»å–æ•´æ•°å¤±è´¥: {}", e));
                        AppError::PlcCommunicationError(format!("HardPoint ReadInt Error: {}", e))
                    })? as f64;
            }
            _ => {
                outcome.result = TestResult::Skipped; // æˆ– Failed
                outcome.error_message = Some(format!("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹è¿›è¡Œç¡¬ç‚¹æµ‹è¯•: {:?}", definition.data_type));
                 return Err(AppError::InvalidInput(format!("HardPoint: Unsupported data type {:?}", definition.data_type)));
            }
        }
        
        outcome.measured_value = Some(read_value);

        // 3. æ¯”è¾ƒè¯»å–å€¼ä¸é¢„æœŸå€¼/èŒƒå›´
        // å¯¹äºæ¨¡æ‹Ÿé‡ç¡¬ç‚¹ï¼Œé€šå¸¸æ˜¯æ£€æŸ¥å€¼æ˜¯å¦åœ¨ä¸€ä¸ªé¢„æœŸçš„å°èŒƒå›´å†…ï¼Œæˆ–è€…æ˜¯å¦ç¨³å®šã€‚
        // æ­¤å¤„ç®€åŒ–ä¸ºæ£€æŸ¥æ˜¯å¦åœ¨é‡ç¨‹å†…ï¼Œæˆ–è€…ä¸ä¸€ä¸ªå›ºå®šçš„æœŸæœ›ç‚¹æ¯”è¾ƒã€‚
        // å®é™…ç¡¬ç‚¹æµ‹è¯•å¯èƒ½æ›´å¤æ‚ï¼Œä¾‹å¦‚ï¼šç¡®ä¿AIé€šé“çš„å€¼åœ¨ä¸€ä¸ªæ ‡å®šç‚¹é™„è¿‘ã€‚
        // å‡è®¾ç¡¬ç‚¹æµ‹è¯•æ˜¯æ£€æŸ¥å€¼æ˜¯å¦è½åœ¨é‡ç¨‹å®šä¹‰çš„ min/max ä¹‹é—´ (è¿™æ›´åƒæ˜¯èŒƒå›´æ£€æŸ¥è€Œéç²¾ç¡®ç¡¬ç‚¹)
        // æˆ–è€…ï¼Œå¦‚æœTestParameterSetä¸­å®šä¹‰äº†å…·ä½“çš„ç¡¬ç‚¹æµ‹è¯•æœŸæœ›å€¼ï¼Œåˆ™ç”¨é‚£ä¸ªå€¼ã€‚
        
        let mut test_passed = false;
        if let (Some(min), Some(max)) = (definition.range_lower_limit, definition.range_upper_limit) {
            if definition.data_type != PointDataType::Bool && definition.data_type != PointDataType::Digital { // æ¨¡æ‹Ÿé‡æ£€æŸ¥èŒƒå›´
                if read_value >= (min - tolerance) && read_value <= (max + tolerance) {
                    test_passed = true;
                    outcome.expected_value = Some(min); // ç®€åŒ–ï¼Œå®é™…æœŸæœ›å¯èƒ½æ˜¯æŸä¸ªç‰¹å®šç‚¹
                } else {
                    outcome.error_message = Some(format!("æµ‹é‡å€¼ {:.2} è¶…å‡ºé¢„æœŸèŒƒå›´ [{:.2}, {:.2}] (å«å®¹å·® {:.2})", read_value, min - tolerance, max + tolerance, tolerance));
                }
            }
        }
        // å¯¹äºæ•°å­—é‡ç¡¬ç‚¹
        if definition.data_type == PointDataType::Bool || definition.data_type == PointDataType::Digital {
            // å‡è®¾æœŸæœ›å€¼ä¸º1.0 (ON)
            if (read_value - 1.0).abs() < tolerance { // æ¯”è¾ƒæ˜¯å¦ä¸º1.0
                test_passed = true;
            } else {
                 outcome.error_message = Some(format!("æ•°å­—é‡ç¡¬ç‚¹æœŸæœ›ä¸ºON (1.0)ï¼Œå®é™…ä¸º {:.0}", read_value));
            }
        }


        if test_passed {
            outcome.result = TestResult::Passed;
            log::info!("ç¡¬ç‚¹æµ‹è¯•é€šè¿‡: instance_id={}, task_id={}, measured_value={:?}",
                task.instance_id, task.task_id, outcome.measured_value);
        } else {
            outcome.result = TestResult::Failed;
            log::warn!("ç¡¬ç‚¹æµ‹è¯•å¤±è´¥: instance_id={}, task_id={}, measured_value={:?}, error={:?}",
                task.instance_id, task.task_id, outcome.measured_value, outcome.error_message);
        }
        
        let end_time = Utc::now();
        outcome.duration_ms = Some((end_time - start_time).num_milliseconds());
        outcome.timestamp = end_time;

        Ok(outcome)
    }
}
```
**æ³¨æ„**:
*   `IPlcCommunicationService` éœ€è¦æœ‰å¦‚ `read_bool`, `read_f32`, `read_i32` ç­‰æ–¹æ³•ã€‚
*   é”™è¯¯å¤„ç†ï¼šå½“PLCé€šä¿¡å¤±è´¥æ—¶ï¼Œåº”å°† `TestOutcome.result` è®¾ç½®ä¸º `Failed` å¹¶å¡«å…… `error_message`ï¼ŒåŒæ—¶è¿”å› `AppError::PlcCommunicationError`ã€‚
*   `TestParameterSet` çš„è·å–é€»è¾‘ï¼šåœ¨å®é™…åœºæ™¯ä¸­ï¼Œ`TestOrchestrationService` æˆ– `TaskScheduler` åœ¨åˆ›å»º `TestTask` æ—¶ï¼Œåº”å·²ä» `IConfigurationRepository` åŠ è½½ç›¸å…³çš„ `TestParameterSet` å¹¶å°†å…¶éƒ¨åˆ†ä¿¡æ¯ï¼ˆå¦‚å®¹å·®ã€å…·ä½“æµ‹è¯•ç‚¹ï¼‰ä¼ é€’ç»™ `TestTask` æˆ–ä½¿å…¶å¯è¢« `ISpecificTestStepExecutor` è®¿é—®ã€‚æ­¤å¤„ä¸ºç®€åŒ–ï¼Œç›´æ¥åœ¨æ‰§è¡Œå™¨å†…å‡è®¾æˆ–ç¡¬ç¼–ç äº†éƒ¨åˆ†å‚æ•°ã€‚

##### 3.2.2 å®ç°å…¶ä»–æµ‹è¯•æ‰§è¡Œå™¨ (ä¾‹å¦‚æŠ¥è­¦æµ‹è¯•ï¼Œå¯é€‰)
ç±»ä¼¼çš„ï¼Œå¯ä»¥ä¸º `LowAlarm`, `HighAlarm`, `DigitalOutputTest` ç­‰åˆ›å»ºæ‰§è¡Œå™¨ã€‚
ä¾‹å¦‚ï¼Œ`LowAlarmTestExecutor`:
1.  è¯»å–å½“å‰æ¨¡æ‹Ÿé‡å€¼ã€‚
2.  é€šè¿‡PLCæœåŠ¡å†™å…¥ä¸€ä¸ªä½äºä½æŠ¥è­¦è®¾å®šå€¼çš„å€¼åˆ°è¿‡ç¨‹å˜é‡ï¼ˆæˆ–æ¨¡æ‹Ÿè¾“å…¥ï¼‰ã€‚
3.  ç­‰å¾…ä¸€å°æ®µæ—¶é—´ã€‚
4.  è¯»å–PLCä¸­å¯¹åº”çš„ä½æŠ¥è­¦çŠ¶æ€ä½ã€‚
5.  éªŒè¯æŠ¥è­¦çŠ¶æ€æ˜¯å¦ä¸ºONã€‚
6.  æ¢å¤è¿‡ç¨‹å˜é‡çš„å€¼ã€‚
7.  è¿”å› `TestOutcome`ã€‚

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 3.2)
å¯¹æ¯ä¸ªå…·ä½“çš„æµ‹è¯•æ­¥éª¤æ‰§è¡Œå™¨è¿›è¡Œå•å…ƒæµ‹è¯•ï¼Œéœ€è¦Mock `IPlcCommunicationService`ã€‚

```rust
// src/services/task_scheduling/tests/hardpoint_test_executor_tests.rs
use crate::services::task_scheduling::executors::hardpoint_test_executor::HardPointTestExecutor;
use crate::services::task_scheduling::test_executors::ISpecificTestStepExecutor;
use crate::services::task_scheduling::task_models::TestTask;
use crate::models::runtime::{ChannelTestInstance, ChannelPointDefinition, TestOutcome};
use crate::models::enums::{SubTestItem, TestResult, PointDataType, ModuleType, OverallTestStatus};
use crate::services::plc_communication::{MockIPlcCommunicationService, IPlcCommunicationService}; // éœ€è¦åˆ›å»ºMock
use crate::utils::error::AppError;
use std::sync::Arc;
use mockall::predicate::*;
use chrono::Utc;

fn create_test_task_for_executor(item: SubTestItem) -> TestTask {
    TestTask {
        task_id: "task_exec_test".to_string(),
        instance_id: "inst_exec_test".to_string(),
        definition_id: "def_exec_test".to_string(),
        batch_id: "batch_exec_test".to_string(),
        sub_test_item: item,
        priority: Default::default(),
        created_at: Utc::now(),
        max_retries: 0,
        timeout_ms: None,
        metadata: None,
    }
}

fn create_test_definition(data_type: PointDataType, low: Option<f64>, high: Option<f64>) -> ChannelPointDefinition {
    ChannelPointDefinition {
        id: "def_exec_test".to_string(),
        tag: "HP_TEST_TAG".to_string(),
        plc_communication_address: "PLC_ADDR_HP".to_string(),
        data_type,
        range_lower_limit: low,
        range_upper_limit: high,
        module_type: ModuleType::AI, // ç¤ºä¾‹
        // ... å…¶ä»–å­—æ®µ
        variable_name: String::new(), variable_description: String::new(), station_name: String::new(),
        module_name: String::new(), channel_tag_in_module: String::new(), power_supply_type: String::new(),
        wire_system: String::new(), plc_absolute_address: None, engineering_unit: None,
        sll_set_value: None, sll_set_point_address: None, sll_feedback_address: None,
        sl_set_value: None, sl_set_point_address: None, sl_feedback_address: None,
        sh_set_value: None, sh_set_point_address: None, sh_feedback_address: None,
        shh_set_value: None, shh_set_point_address: None, shh_feedback_address: None,
        maintenance_value_set_point_address: None, maintenance_enable_switch_point_address: None,
        access_property: None, save_history: None, power_failure_protection: None, test_rig_plc_address: None,
    }
}

fn create_test_instance_snapshot() -> ChannelTestInstance {
    // å¯¹äºæ‰§è¡Œå™¨ï¼Œå®ä¾‹å¿«ç…§ä¸»è¦æ˜¯å‚è€ƒï¼Œä¸åº”è¢«ä¿®æ”¹
    ChannelTestInstance {
        instance_id: "inst_exec_test".to_string(),
        definition_id: "def_exec_test".to_string(),
        test_batch_id: "batch_exec_test".to_string(),
        overall_status: OverallTestStatus::HardPointTesting, // å‡è®¾æµ‹è¯•å‰çŠ¶æ€
        // ...
        current_step_details: None, error_message: None, start_time: None, last_updated_time: Utc::now(),
        final_test_time: None, total_test_duration_ms: None, sub_test_results: Default::default(),
        hardpoint_readings: None, manual_test_current_value_input: None, manual_test_current_value_output: None,
    }
}


#[tokio::test]
async fn test_hardpoint_executor_ai_passed() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    let definition = create_test_definition(PointDataType::Float, Some(0.0), Some(100.0));
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_f32()
        .with(eq("PLC_ADDR_HP"))
        .times(1)
        .returning(|_| Ok(50.0_f32)); // PLCè¿”å›50.0

    let outcome = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await.unwrap();
    
    assert_eq!(outcome.test_item, SubTestItem::HardPoint);
    assert_eq!(outcome.result, TestResult::Passed);
    assert_eq!(outcome.measured_value, Some(50.0));
    assert!(outcome.error_message.is_none());
}

#[tokio::test]
async fn test_hardpoint_executor_ai_failed_out_of_range() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    let definition = create_test_definition(PointDataType::Float, Some(0.0), Some(100.0));
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_f32()
        .with(eq("PLC_ADDR_HP"))
        .times(1)
        .returning(|_| Ok(150.0_f32)); // PLCè¿”å›150.0 (è¶…å‡ºèŒƒå›´)

    let outcome = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await.unwrap();
    
    assert_eq!(outcome.result, TestResult::Failed);
    assert_eq!(outcome.measured_value, Some(150.0));
    assert!(outcome.error_message.is_some());
    assert!(outcome.error_message.unwrap().contains("è¶…å‡ºé¢„æœŸèŒƒå›´"));
}

#[tokio::test]
async fn test_hardpoint_executor_di_passed() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    // å¯¹äºDIï¼Œrange_lower/upper_limit å¯èƒ½ä¸é€‚ç”¨æˆ–æœ‰ä¸åŒå«ä¹‰ï¼Œè¿™é‡Œå‡è®¾æœŸæœ›å€¼ä¸º1 (ON)
    let definition = create_test_definition(PointDataType::Bool, Some(0.0), Some(1.0)); 
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_bool()
        .with(eq("PLC_ADDR_HP"))
        .times(1)
        .returning(|_| Ok(true)); // PLCè¿”å›true (ON)

    let outcome = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await.unwrap();
    
    assert_eq!(outcome.result, TestResult::Passed);
    assert_eq!(outcome.measured_value, Some(1.0)); // true æ˜ å°„ä¸º 1.0
}

#[tokio::test]
async fn test_hardpoint_executor_plc_communication_error() {
    let executor = HardPointTestExecutor::new();
    let task = create_test_task_for_executor(SubTestItem::HardPoint);
    let definition = create_test_definition(PointDataType::Float, Some(0.0), Some(100.0));
    let instance_snapshot = create_test_instance_snapshot();

    let mut mock_plc = MockIPlcCommunicationService::new();
    mock_plc.expect_read_f32()
        .times(1)
        .returning(|_| Err(AppError::PlcCommunicationError("Simulated PLC conn error".to_string())));

    // executeæœ¬èº«åº”è¿”å›AppErrorï¼ŒTestOutcomeå†…éƒ¨ä¹Ÿåº”æ ‡è®°å¤±è´¥
    let result = executor.execute(&task, &instance_snapshot, &definition, Arc::new(mock_plc)).await;
    assert!(result.is_err());
    if let Err(AppError::PlcCommunicationError(msg)) = result {
         assert!(msg.contains("Simulated PLC conn error"));
    } else {
        panic!("Expected PlcCommunicationError, got {:?}", result);
    }
    // å¦‚æœè¦æ£€æŸ¥TestOutcomeå†…éƒ¨ï¼Œéœ€è¦è®©executeåœ¨PLCé”™è¯¯æ—¶ä¸panicè€Œæ˜¯è¿”å›Ok(TestOutcome{result:Failed})
    // å½“å‰ ISpecificTestStepExecutor å®šä¹‰æ˜¯è¿”å› Result<TestOutcome, AppError>
    // æ‰€ä»¥ï¼Œå¦‚æœPLCé€šä¿¡å‡ºé”™ï¼Œexecuteæ–¹æ³•æœ¬èº«ä¼šè¿”å›Errã€‚
    // å¦‚æœå¸Œæœ›executeæ€»æ˜¯è¿”å›Ok(TestOutcome)ï¼Œåˆ™éœ€è¦åœ¨å…¶å†…éƒ¨æ•è·PLCé”™è¯¯å¹¶è®¾ç½®outcome.result=Failedã€‚
    // æŒ‰ç…§å½“å‰å®šä¹‰ï¼Œå¤–éƒ¨(è°ƒåº¦å™¨)åº”å¤„ç†executeè¿”å›çš„Errã€‚
}
```
**åˆ›å»º `MockIPlcCommunicationService`**:
æ‚¨éœ€è¦ä½¿ç”¨ `mockall` crate æ¥ä¸º `IPlcCommunicationService` åˆ›å»ºä¸€ä¸ª mock å®ç°ã€‚
```rust
// src/services/plc_communication.rs (æˆ–è€…ä¸€ä¸ªä¸“é—¨çš„ mock æ–‡ä»¶)
// ... (IPlcCommunicationService trait å®šä¹‰) ...

#[cfg(test)]
use mockall::mock;

#[cfg(test)]
mock! {
    pub PlcCommunicationService {} // åç§°å¯ä»¥ä»»æ„ï¼Œé€šå¸¸ä¸traitåç›¸ä¼¼
    #[async_trait::async_trait]
    impl IPlcCommunicationService for PlcCommunicationService {
        async fn connect(&self, plc_id: &str, config_json: &str) -> Result<(), AppError>;
        async fn disconnect(&self, plc_id: &str) -> Result<(), AppError>;
        async fn read_bool(&self, plc_id: &str, address: &str) -> Result<bool, AppError>;
        async fn write_bool(&self, plc_id: &str, address: &str, value: bool) -> Result<(), AppError>;
        async fn read_f32(&self, plc_id: &str, address: &str) -> Result<f32, AppError>;
        async fn write_f32(&self, plc_id: &str, address: &str, value: f32) -> Result<(), AppError>;
        async fn read_i32(&self, plc_id: &str, address: &str) -> Result<i32, AppError>;
        async fn write_i32(&self, plc_id: &str, address: &str, value: i32) -> Result<(), AppError>;
        // æ·»åŠ å…¶ä»–ä½ éœ€è¦ mock çš„æ–¹æ³•
    }
}
// æ³¨æ„: mockallç”Ÿæˆçš„Mocké»˜è®¤ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„(Send+Sync)ï¼Œå¦‚æœå¼‚æ­¥traitæ–¹æ³•éœ€è¦åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­ä½¿ç”¨ï¼Œ
// å¯èƒ½éœ€è¦ä¸ºexpect_...æ–¹æ³•æ·»åŠ  .once().returning(...) ç­‰ï¼Œæˆ–è€…ç¡®ä¿æµ‹è¯•åœ¨å•çº¿ç¨‹è¿è¡Œæ—¶(å¦‚ current_thread runtime)ã€‚
// å¯¹äº async_traitï¼Œmockall é€šå¸¸èƒ½å¾ˆå¥½åœ°å¤„ç†ã€‚
```
æ‚¨éœ€è¦æ ¹æ® `IPlcCommunicationService` çš„å®é™…å®šä¹‰æ¥è°ƒæ•´ `mock!` å®ã€‚
åœ¨æµ‹è¯•ä¸­ï¼Œ`plc_service: Arc<dyn IPlcCommunicationService>` å‚æ•°ä¸­çš„ `plc_id` æš‚æ—¶è¢«å¿½ç•¥äº†ï¼Œå› ä¸ºæ‰§è¡Œå™¨ç›´æ¥ä½¿ç”¨äº† `address`ã€‚å¦‚æœ `IPlcCommunicationService` çš„æ–¹æ³•ç­¾åç¡®å®éœ€è¦ `plc_id`ï¼ˆä¾‹å¦‚ï¼Œç®¡ç†å¤šä¸ªPLCè¿æ¥ï¼‰ï¼Œé‚£ä¹ˆ `TestTask` æˆ– `ChannelPointDefinition` éœ€è¦åŒ…å«æ­¤ä¿¡æ¯ï¼Œå¹¶ä¼ é€’ç»™PLCæœåŠ¡æ–¹æ³•ã€‚ä¸ºç®€åŒ–ï¼Œå½“å‰ `IPlcCommunicationService` çš„ mock å’Œæµ‹è¯•æ‰§è¡Œå™¨è°ƒç”¨éƒ½å‡è®¾åœ°å€æœ¬èº«å·²è¶³å¤Ÿå”¯ä¸€ï¼Œæˆ–è€… `plc_id` ç”±å¤–éƒ¨ç®¡ç†ã€‚

#### âœ… é¢„æœŸç»“æœ/å®Œæˆæ ‡å‡† (æ­¥éª¤ 3.2)
1.  è‡³å°‘ä¸º `SubTestItem::HardPoint` å®ç°äº† `ISpecificTestStepExecutor` (å³ `HardPointTestExecutor`)ã€‚
2.  æ‰§è¡Œå™¨èƒ½å¤Ÿæ­£ç¡®åœ°ä¸ (mocked) `IPlcCommunicationService` äº¤äº’ï¼Œè¯»å–/å†™å…¥PLCæ•°æ®ã€‚
3.  æ‰§è¡Œå™¨æ ¹æ®è¯»å–åˆ°çš„å€¼å’Œå®šä¹‰/å‚æ•°ï¼Œæ­£ç¡®åˆ¤æ–­æµ‹è¯•ç»“æœ (Passed/Failed/Skipped) å¹¶æ„å»º `TestOutcome`ã€‚
4.  é”™è¯¯å¤„ç†å®Œå–„ï¼ŒPLCé€šä¿¡æ•…éšœæˆ–æ— æ•ˆå‚æ•°èƒ½è¢«æ­£ç¡®å¤„ç†å¹¶åæ˜ åœ¨ `TestOutcome` å’Œ/æˆ–è¿”å›çš„ `AppError` ä¸­ã€‚
5.  å•å…ƒæµ‹è¯•è¦†ç›–å„ç§åœºæ™¯ï¼ˆé€šè¿‡ã€å¤±è´¥ã€PLCé”™è¯¯ã€æ— æ•ˆæ•°æ®ç±»å‹ç­‰ï¼‰ã€‚
6.  ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒã€‚

---
### æ­¥éª¤ 3.3: å®ç°é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨ (`AdvancedTaskScheduler`)

#### ğŸ¯ ç›®æ ‡
åŸºäº `ITaskScheduler` æ¥å£ï¼Œå®ç° `AdvancedTaskScheduler`ã€‚å®ƒå°†è´Ÿè´£ï¼š
*   ç®¡ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæ”¯æŒä¼˜å…ˆçº§ï¼‰ã€‚
*   ä½¿ç”¨ `tokio::sync::Semaphore` æ§åˆ¶å¹¶å‘æ‰§è¡Œçš„ä»»åŠ¡æ•°é‡ (`FAT-TTM-001`)ã€‚
*   åœ¨ç‹¬ç«‹çš„tokioä»»åŠ¡ä¸­æ‰§è¡Œ `TestTask`ï¼Œé€šè¿‡æŸ¥æ‰¾å¹¶è°ƒç”¨ç›¸åº”çš„ `ISpecificTestStepExecutor`ã€‚
*   å¤„ç†ä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸï¼šè°ƒåº¦ã€æ‰§è¡Œã€é‡è¯•ï¼ˆåŸºäº `TestTask.max_retries` å’Œ `TestOutcome`ï¼‰ã€å®Œæˆã€å–æ¶ˆã€‚
*   æ”¶é›† `TestOutcome` å¹¶é€šè¿‡ `IChannelStateManager` æ›´æ–° `ChannelTestInstance` çŠ¶æ€ã€‚
*   å‘å¸ƒ `TaskExecutionEvent`ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 3.3.1 `AdvancedTaskScheduler` ç»“æ„ä½“å’Œåˆå§‹åŒ–
```rust
// src/services/task_scheduling/scheduler.rs (ç»­)
use super::task_models::*;
use super::test_executors::ISpecificTestStepExecutor;
use crate::services::state_management::IChannelStateManager;
use crate::services::persistence::repositories::configuration_repository::IConfigurationRepository;
use crate::services::persistence::repositories::runtime_repository::IRuntimeRepository;
use crate::services::plc_communication::IPlcCommunicationService; // å¼•å…¥PLCæœåŠ¡trait
use std::sync::Arc;
use tokio::sync::{Semaphore, Mutex, RwLock, broadcast, watch};
use tokio::task::JoinHandle;
use std::collections::{BinaryHeap, HashMap, VecDeque}; // BinaryHeap for priority queue
use std::cmp::Ordering;
use chrono::Utc;
use uuid::Uuid;

const DEFAULT_SCHEDULER_EVENT_CAPACITY: usize = 256;
const DEFAULT_MAX_CONCURRENT_TASKS: usize = 4; // é»˜è®¤å¹¶å‘æ•°

// ç”¨äºä¼˜å…ˆçº§é˜Ÿåˆ—çš„åŒ…è£…é¡¹
#[derive(Debug, Clone)]
struct ScheduledTaskItem {
    task: TestTask,
    handle: TaskHandle,
    scheduled_at: DateTime<Utc>, // ç”¨äºå¤„ç†ç›¸åŒä¼˜å…ˆçº§æ—¶çš„FIFO
    current_retry_count: u32,
}

// ä¸ºBinaryHeapå®ç°Ord (Min-Heapï¼Œæ‰€ä»¥æ¯”è¾ƒæ—¶åè½¬ä¼˜å…ˆçº§)
impl Ord for ScheduledTaskItem {
    fn cmp(&self, other: &Self) -> Ordering {
        other.task.priority.cmp(&self.task.priority) // Higher numeric priority means higher actual priority
            .then_with(|| self.scheduled_at.cmp(&other.scheduled_at)) // FIFO for same priority
    }
}
impl PartialOrd for ScheduledTaskItem {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}
impl PartialEq for ScheduledTaskItem {
    fn eq(&self, other: &Self) -> bool {
        self.handle == other.handle && self.scheduled_at == other.scheduled_at
    }
}
impl Eq for ScheduledTaskItem {}


pub struct AdvancedTaskScheduler {
    // ä¾èµ–
    state_manager: Arc<dyn IChannelStateManager>,
    config_repo: Arc<dyn IConfigurationRepository>, // ç”¨äºè·å–ChannelPointDefinition
    runtime_repo: Arc<dyn IRuntimeRepository>,   // ç”¨äºè·å–ChannelTestInstanceå¿«ç…§
    plc_service_factory: Arc<dyn Fn() -> Arc<dyn IPlcCommunicationService> + Send + Sync>, // PLCæœåŠ¡å·¥å‚æˆ–å…±äº«å®ä¾‹
    executors: Arc<HashMap<SubTestItem, Arc<dyn ISpecificTestStepExecutor>>>,

    // å†…éƒ¨çŠ¶æ€
    task_queue: Arc<Mutex<BinaryHeap<ScheduledTaskItem>>>, // ä¼˜å…ˆçº§é˜Ÿåˆ—
    active_tasks: Arc<RwLock<HashMap<TaskHandle, TaskRuntimeInfo>>>, // æ­£åœ¨è¿è¡Œæˆ–æœ€è¿‘å®Œæˆçš„ä»»åŠ¡ä¿¡æ¯
    running_task_handles: Arc<RwLock<HashMap<TaskHandle, JoinHandle<()>>>>, // Tokioä»»åŠ¡å¥æŸ„ï¼Œç”¨äºå–æ¶ˆ

    concurrency_semaphore: Arc<Semaphore>,
    max_concurrent_tasks: Arc<RwLock<usize>>, // å…è®¸åŠ¨æ€è°ƒæ•´

    event_broadcaster: broadcast::Sender<TaskExecutionEvent>,
    
    // ä¼˜é›…å…³é—­æ§åˆ¶
    shutdown_signal_tx: watch::Sender<bool>,
    shutdown_signal_rx: watch::Receiver<bool>,
}

impl AdvancedTaskScheduler {
    pub fn new(
        state_manager: Arc<dyn IChannelStateManager>,
        config_repo: Arc<dyn IConfigurationRepository>,
        runtime_repo: Arc<dyn IRuntimeRepository>,
        plc_service_factory: Arc<dyn Fn() -> Arc<dyn IPlcCommunicationService> + Send + Sync>,
        executors: HashMap<SubTestItem, Arc<dyn ISpecificTestStepExecutor>>,
        initial_max_concurrent_tasks: Option<usize>,
    ) -> Arc<Self> {
        let (event_tx, _) = broadcast::channel(DEFAULT_SCHEDULER_EVENT_CAPACITY);
        let (shutdown_tx, shutdown_rx) = watch::channel(false); // false = not shutting down
        
        let max_tasks = initial_max_concurrent_tasks.unwrap_or(DEFAULT_MAX_CONCURRENT_TASKS);

        Arc::new(Self {
            state_manager,
            config_repo,
            runtime_repo,
            plc_service_factory,
            executors: Arc::new(executors),
            task_queue: Arc::new(Mutex::new(BinaryHeap::new())),
            active_tasks: Arc::new(RwLock::new(HashMap::new())),
            running_task_handles: Arc::new(RwLock::new(HashMap::new())),
            concurrency_semaphore: Arc::new(Semaphore::new(max_tasks)),
            max_concurrent_tasks: Arc::new(RwLock::new(max_tasks)),
            event_broadcaster: event_tx,
            shutdown_signal_tx: shutdown_tx,
            shutdown_signal_rx: shutdown_rx,
        })
    }

    /// å¯åŠ¨è°ƒåº¦å™¨çš„ä¸»å¤„ç†å¾ªç¯ (åº”åœ¨ä¸€ä¸ªç‹¬ç«‹çš„tokioä»»åŠ¡ä¸­è¿è¡Œ)
    pub fn start_processing_loop(self: Arc<Self>) {
        tokio::spawn(async move {
            log::info!("AdvancedTaskSchedulerå¤„ç†å¾ªç¯å·²å¯åŠ¨ã€‚æœ€å¤§å¹¶å‘æ•°: {}", self.concurrency_semaphore.available_permits());
            loop {
                // æ£€æŸ¥å…³é—­ä¿¡å·
                if *self.shutdown_signal_rx.borrow() {
                    log::info!("AdvancedTaskScheduleræ£€æµ‹åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡ºå¤„ç†å¾ªç¯...");
                    // å¯ä»¥é€‰æ‹©ç­‰å¾…ç°æœ‰ä»»åŠ¡å®Œæˆï¼Œæˆ–ç›´æ¥é€€å‡º
                    // æ­¤å¤„ç®€å•é€€å‡ºï¼Œshutdownæ–¹æ³•è´Ÿè´£æ›´å¤æ‚çš„é€»è¾‘
                    break;
                }

                // 1. è·å–å¹¶å‘è®¸å¯
                //    tokio::select! å…è®¸åŒæ—¶ç­‰å¾…ä¿¡å·å’Œè®¸å¯
                let permit = tokio::select! {
                    biased; // ä¼˜å…ˆæ£€æŸ¥å…³é—­ä¿¡å·
                    _ = self.shutdown_signal_rx.changed() => { // changed() ä¼šåœ¨ä¿¡å·æ”¹å˜æ—¶å”¤é†’
                        if *self.shutdown_signal_rx.borrow() { continue; } // å†æ¬¡æ£€æŸ¥ï¼Œå¦‚æœæ˜¯å…³é—­åˆ™å¾ªç¯
                        // å¦‚æœä¸æ˜¯å…³é—­ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œåªæ˜¯åˆå§‹å€¼è¢«è¯»å–ï¼‰ï¼Œåˆ™å°è¯•è·å–è®¸å¯
                        // ä½†ç›´æ¥ continue å¯èƒ½å¯¼è‡´æ­»å¾ªç¯ï¼Œæ‰€ä»¥æœ€å¥½æ˜¯æ˜ç¡®å¤„ç†å…³é—­
                        // è¿™é‡Œç®€åŒ–ï¼šå¦‚æœ changed ä¸”ä¸æ˜¯å…³é—­ï¼Œå°±å°è¯•è·å–è®¸å¯ã€‚
                        // æˆ–è€…ï¼Œè®© acquire åœ¨è¶…æ—¶åè¿”å›ï¼Œç„¶åæ£€æŸ¥ shutdown_signal_rx
                        match self.concurrency_semaphore.try_acquire_owned() {
                            Ok(p) => p,
                            Err(_) => { tokio::time::sleep(std::time::Duration::from_millis(50)).await; continue; } // æ²¡æœ‰å¯ç”¨è®¸å¯ï¼Œç¨åé‡è¯•
                        }
                    },
                    permit_result = self.concurrency_semaphore.acquire_owned() => {
                        match permit_result {
                            Ok(p) => p,
                            Err(_) => { // Semaphoreè¢«å…³é—­ (é€šå¸¸åœ¨shutdownæ—¶å‘ç”Ÿ)
                                log_warn!("å¹¶å‘ä¿¡å·é‡å·²å…³é—­ï¼Œå¤„ç†å¾ªç¯å¯èƒ½å³å°†åœæ­¢ã€‚");
                                continue; // æˆ– break;
                            }
                        }
                    }
                };
                
                // 2. ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡
                let scheduled_item_opt: Option<ScheduledTaskItem>;
                { // é™åˆ¶ MutexGuard çš„ä½œç”¨åŸŸ
                    let mut queue = self.task_queue.lock().await;
                    scheduled_item_opt = queue.pop();
                }

                if let Some(scheduled_item) = scheduled_item_opt {
                    let task = scheduled_item.task.clone();
                    let handle = scheduled_item.handle;
                    log::info!("ä»é˜Ÿåˆ—å–å‡ºä»»åŠ¡: {:?}, ID: {}", task.sub_test_item, task.task_id);

                    // æ›´æ–°ä»»åŠ¡ä¿¡æ¯ä¸º Running
                    let runtime_info = TaskRuntimeInfo {
                        handle,
                        task_definition: task.clone(),
                        status: TaskStatus::Running,
                        current_retry_count: scheduled_item.current_retry_count,
                        scheduled_at: scheduled_item.scheduled_at,
                        started_at: Some(Utc::now()),
                        completed_at: None,
                        error_message: None,
                    };
                    self.active_tasks.write().await.insert(handle, runtime_info.clone());
                    
                    // å‘å¸ƒ Started äº‹ä»¶
                    self.publish_event(TaskExecutionEvent {
                        task_handle: handle, instance_id: task.instance_id.clone(), batch_id: task.batch_id.clone(),
                        sub_test_item: task.sub_test_item, event_type: TaskEventType::Started,
                        timestamp: Utc::now(), details: None, outcome: None,
                    }).await;

                    // 3. å¼‚æ­¥æ‰§è¡Œä»»åŠ¡
                    let self_clone = self.clone(); // Clone Arc for the new task
                    let task_join_handle = tokio::spawn(async move {
                        // permit åœ¨æ­¤ä½œç”¨åŸŸç»“æŸæ—¶ä¼šè‡ªåŠ¨é‡Šæ”¾
                        let _permit_guard = permit; 
                        self_clone.execute_and_process_task(scheduled_item).await;
                    });
                    self.running_task_handles.write().await.insert(handle, task_join_handle);

                } else {
                    // é˜Ÿåˆ—ä¸ºç©ºï¼Œé‡Šæ”¾è®¸å¯ï¼Œç¨åé‡è¯•
                    drop(permit); // æ˜ç¡®é‡Šæ”¾
                    tokio::time::sleep(std::time::Duration::from_millis(100)).await; // é¿å…å¿™ç­‰å¾…
                }
            }
            log::info!("AdvancedTaskSchedulerå¤„ç†å¾ªç¯å·²åœæ­¢ã€‚");
        });
    }

    /// å†…éƒ¨å‡½æ•°ï¼šæ‰§è¡Œå•ä¸ªä»»åŠ¡å¹¶å¤„ç†å…¶ç»“æœ
    async fn execute_and_process_task(&self, scheduled_item: ScheduledTaskItem) {
        let task = scheduled_item.task;
        let handle = scheduled_item.handle;
        let mut current_retry_count = scheduled_item.current_retry_count;
        
        let final_outcome: TestOutcome;
        let mut execution_error: Option<AppError> = None;

        loop { // é‡è¯•å¾ªç¯
            // a. è·å–æ‰§è¡Œå™¨
            let executor = match self.executors.get(&task.sub_test_item) {
                Some(exec) => exec.clone(),
                None => {
                    let err_msg = format!("æœªæ‰¾åˆ°ä»»åŠ¡é¡¹ {:?} çš„æ‰§è¡Œå™¨", task.sub_test_item);
                    log::error!("{}", err_msg);
                    final_outcome = TestOutcome::new_failed(task.sub_test_item, Some(err_msg.clone()));
                    execution_error = Some(AppError::ExecutorNotFound(err_msg));
                    break;
                }
            };

            // b. è·å–ä¾èµ–æ•°æ® (Definition, Instance Snapshot)
            let definition_res = self.config_repo.get_channel_definition_by_id(&task.definition_id).await;
            let instance_snapshot_res = self.runtime_repo.get_channel_instance(&task.instance_id).await;

            match (definition_res, instance_snapshot_res) {
                (Ok(Some(def)), Ok(Some(inst_snapshot))) => {
                    // c. æ‰§è¡Œæµ‹è¯•æ­¥éª¤
                    let plc_service = (self.plc_service_factory)(); // è·å–PLCæœåŠ¡å®ä¾‹
                    let outcome_res = executor.execute(&task, &inst_snapshot, &def, plc_service).await;

                    match outcome_res {
                        Ok(outcome) => {
                            if outcome.result == TestResult::Passed || outcome.result == TestResult::Skipped {
                                final_outcome = outcome; // æˆåŠŸæˆ–è·³è¿‡ï¼Œç»“æŸé‡è¯•
                                break;
                            } else { // Failed or InProgress (InProgressä¸åº”åˆ°æ­¤ï¼Œexecutoråº”è¿”å›æœ€ç»ˆç»“æœ)
                                if current_retry_count < task.max_retries {
                                    current_retry_count += 1;
                                    log::warn!("ä»»åŠ¡ {:?} (ID: {}) ç¬¬ {} æ¬¡å°è¯•å¤±è´¥ï¼Œå°†é‡è¯•ã€‚é”™è¯¯: {:?}", 
                                        task.sub_test_item, task.task_id, current_retry_count, outcome.error_message);
                                    
                                    self.publish_event(TaskExecutionEvent {
                                        task_handle: handle, instance_id: task.instance_id.clone(), batch_id: task.batch_id.clone(),
                                        sub_test_item: task.sub_test_item, event_type: TaskEventType::AttemptFailed,
                                        timestamp: Utc::now(), details: outcome.error_message.clone(), outcome: Some(outcome.clone()),
                                    }).await;
                                    // TODO: å®ç°é‡è¯•å»¶è¿Ÿç­–ç•¥
                                    tokio::time::sleep(std::time::Duration::from_secs(1)).await; // ç®€å•å»¶è¿Ÿ
                                    continue; // è¿›å…¥ä¸‹ä¸€æ¬¡é‡è¯•
                                } else {
                                    log::error!("ä»»åŠ¡ {:?} (ID: {}) å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({})ï¼Œæœ€ç»ˆå¤±è´¥ã€‚", 
                                        task.sub_test_item, task.task_id, task.max_retries);
                                    final_outcome = outcome; // è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»¥æ­¤ç»“æœä¸ºå‡†
                                    break;
                                }
                            }
                        }
                        Err(app_err) => { // æ‰§è¡Œå™¨å†…éƒ¨é”™è¯¯ (ä¾‹å¦‚PLCé€šä¿¡ä¸¥é‡æ•…éšœ)
                            log::error!("ä»»åŠ¡ {:?} (ID: {}) æ‰§è¡Œå™¨è¿”å›é”™è¯¯: {:?}", task.sub_test_item, task.task_id, app_err);
                            final_outcome = TestOutcome::new_failed(task.sub_test_item, Some(app_err.to_string()));
                            execution_error = Some(app_err);
                            break; 
                        }
                    }
                }
                (Err(e), _) | (_, Err(e)) => {
                    let err_msg = format!("è·å–ä»»åŠ¡ä¾èµ–æ•°æ®å¤±è´¥ (def_id: {}, inst_id: {}): {:?}", task.definition_id, task.instance_id, e);
                    log::error!("{}", err_msg);
                    final_outcome = TestOutcome::new_failed(task.sub_test_item, Some(err_msg.clone()));
                    execution_error = Some(AppError::RepositoryError(err_msg));
                    break;
                }
                (Ok(None), _) => { /* def not found */ execution_error = Some(AppError::RecordNotFound(task.definition_id.clone())); final_outcome = TestOutcome::new_skipped(task.sub_test_item, Some("Definition not found".to_string())); break; }
                (_, Ok(None)) => { /* instance not found */ execution_error = Some(AppError::InstanceNotFound(task.instance_id.clone())); final_outcome = TestOutcome::new_skipped(task.sub_test_item, Some("Instance not found".to_string())); break; }
            }
        } // end retry loop

        // d. æ›´æ–° ChannelTestInstance çŠ¶æ€ (é€šè¿‡ StateManager)
        match self.state_manager.apply_raw_outcome(&task.instance_id, &final_outcome).await {
            Ok(_) => log::info!("ä»»åŠ¡ {:?} (ID: {}) ç»“æœå·²æˆåŠŸåº”ç”¨åˆ°çŠ¶æ€ç®¡ç†å™¨ã€‚", task.sub_test_item, task.task_id),
            Err(e) => log::error!("ä»»åŠ¡ {:?} (ID: {}) ç»“æœåº”ç”¨åˆ°çŠ¶æ€ç®¡ç†å™¨å¤±è´¥: {:?}", task.sub_test_item, task.task_id, e),
        }
        
        // e. æ›´æ–°ä»»åŠ¡è¿è¡Œæ—¶ä¿¡æ¯ä¸º Completed/Failed
        let final_status = if final_outcome.result == TestResult::Passed || final_outcome.result == TestResult::Skipped {
            TaskStatus::Completed
        } else {
            TaskStatus::Failed
        };
        
        let event_type = if final_status == TaskStatus::Completed {
            TaskEventType::CompletedSuccessfully
        } else {
            TaskEventType::CompletedWithFailure
        };

        if let Some(mut info) = self.active_tasks.write().await.get_mut(&handle) {
            info.status = final_status;
            info.completed_at = Some(Utc::now());
            info.error_message = execution_error.map(|e| e.to_string()).or(final_outcome.error_message.clone());
            // info.progress_percentage = 100.0;
        }
        
        // f. å‘å¸ƒ Completed/Failed äº‹ä»¶
        self.publish_event(TaskExecutionEvent {
            task_handle: handle, instance_id: task.instance_id.clone(), batch_id: task.batch_id.clone(),
            sub_test_item: task.sub_test_item, event_type,
            timestamp: Utc::now(), details: final_outcome.error_message.clone(), outcome: Some(final_outcome),
        }).await;

        // g. ä» active_tasks å’Œ running_task_handles ä¸­ç§»é™¤
        self.active_tasks.write().await.remove(&handle);
        self.running_task_handles.write().await.remove(&handle);
        log::info!("ä»»åŠ¡ {:?} (ID: {}) æ‰§è¡Œå®Œæ¯•ï¼ŒçŠ¶æ€: {:?}.", task.sub_test_item, task.task_id, final_status);
    }

    async fn publish_event(&self, event: TaskExecutionEvent) {
        if self.event_broadcaster.send(event.clone()).is_err() {
            log::warn!("ä»»åŠ¡äº‹ä»¶ {:?} (Task ID: {}) å‘å¸ƒå¤±è´¥: æ— è®¢é˜…è€…æˆ–é€šé“å·²æ»¡ã€‚", event.event_type, event.task_handle.0);
        }
    }
}
```

##### 3.3.2 `ITaskScheduler` æ¥å£å®ç°
```rust
// src/services/task_scheduling/scheduler.rs (ç»­)
#[async_trait]
impl ITaskScheduler for AdvancedTaskScheduler {
    async fn schedule_task(&self, task: TestTask) -> Result<TaskHandle, AppError> {
        let handle = TaskHandle(task.task_id.clone()); // ä½¿ç”¨ task_id ä½œä¸ºå¥æŸ„
        let scheduled_item = ScheduledTaskItem {
            task,
            handle,
            scheduled_at: Utc::now(),
            current_retry_count: 0,
        };

        self.task_queue.lock().await.push(scheduled_item);
        log::info!("ä»»åŠ¡å·²è°ƒåº¦: ID={}, Item={:?}", handle.0, self.task_queue.lock().await.peek().unwrap().task.sub_test_item);
        
        // åˆå§‹ä»»åŠ¡ä¿¡æ¯
        let runtime_info = TaskRuntimeInfo {
            handle,
            task_definition: self.task_queue.lock().await.peek().unwrap().task.clone(), // ä»é˜Ÿåˆ—ä¸­è·å–æœ€æ–°çš„taskå®šä¹‰
            status: TaskStatus::Pending,
            current_retry_count: 0,
            scheduled_at: Utc::now(),
            started_at: None, completed_at: None, error_message: None,
        };
        self.active_tasks.write().await.insert(handle, runtime_info);

        self.publish_event(TaskExecutionEvent {
            task_handle: handle, instance_id: self.task_queue.lock().await.peek().unwrap().task.instance_id.clone(),
            batch_id: self.task_queue.lock().await.peek().unwrap().task.batch_id.clone(),
            sub_test_item: self.task_queue.lock().await.peek().unwrap().task.sub_test_item,
            event_type: TaskEventType::Scheduled, timestamp: Utc::now(),
            details: None, outcome: None,
        }).await;
        Ok(handle)
    }

    async fn schedule_tasks_batch(&self, tasks: Vec<TestTask>) -> Result<Vec<TaskHandle>, AppError> {
        let mut handles = Vec::new();
        for task in tasks {
            handles.push(self.schedule_task(task).await?);
        }
        Ok(handles)
    }
    
    // Phase3ä¸­çš„ç¬¬å››ä¸ªé—®é¢˜ï¼šç®€åŒ–å–æ¶ˆé€»è¾‘ã€‚å› ä¸ºæµ‹è¯•é€Ÿåº¦å¿«ï¼Œå¤æ‚å–æ¶ˆæœºåˆ¶ï¼ˆå¦‚ä¸­æ–­IOï¼‰å¯èƒ½ä¸éœ€è¦ã€‚
    // æ ‡è®°ä¸ºå–æ¶ˆï¼Œå¦‚æœä»»åŠ¡å°šæœªå¼€å§‹ï¼Œåˆ™ä»é˜Ÿåˆ—ç§»é™¤ã€‚å¦‚æœå·²å¼€å§‹ï¼Œåˆ™ä¸å¼ºåˆ¶ä¸­æ–­ï¼Œå…è®¸å…¶è‡ªç„¶ç»“æŸã€‚
    // ä½†æ‰§è¡Œå™¨åœ¨å…³é”®æ­¥éª¤ï¼ˆå¦‚é•¿æ—¶é—´ç­‰å¾…æˆ–å¾ªç¯å‰ï¼‰åº”æ£€æŸ¥æ­¤ä»»åŠ¡æ˜¯å¦å·²è¢«è¯·æ±‚å–æ¶ˆã€‚
    async fn cancel_task(&self, task_handle: &TaskHandle) -> Result<(), AppError> {
        // 1. å°è¯•ä»æ´»åŠ¨ä»»åŠ¡ä¸­æ ‡è®°ä¸ºå–æ¶ˆï¼Œå¹¶è·å– JoinHandle ä»¥å°è¯•ä¸­æ­¢
        let mut was_running = false;
        if let Some(mut info) = self.active_tasks.write().await.get_mut(task_handle) {
            if info.status == TaskStatus::Running || info.status == TaskStatus::Pending { // ç†è®ºä¸Šactive_tasksä¸»è¦å­˜Running
                info.status = TaskStatus::Cancelled; // æ ‡è®°ä¸ºå–æ¶ˆ
                was_running = true; // å‡è®¾åœ¨active_taskså°±æ˜¯æ›¾ç»æˆ–æ­£åœ¨è¿è¡Œ
                log::info!("ä»»åŠ¡ {} æ ‡è®°ä¸ºå–æ¶ˆ (åŸçŠ¶æ€: Running/Pending in active_tasks).", task_handle.0);
            }
        }
        if let Some(join_handle) = self.running_task_handles.write().await.remove(task_handle) {
             log::info!("å°è¯•ä¸­æ­¢æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ {}", task_handle.0);
             join_handle.abort(); // å°è¯•ä¸­æ­¢ Tokio ä»»åŠ¡
             was_running = true; // ç¡®è®¤æ˜¯åœ¨è¿è¡Œå¹¶å°è¯•ä¸­æ­¢
        }

        // 2. å°è¯•ä»å¾…å¤„ç†é˜Ÿåˆ—ä¸­ç§»é™¤
        let mut removed_from_queue = false;
        let mut queue = self.task_queue.lock().await;
        let mut temp_heap = BinaryHeap::new(); // ç”¨äºæš‚å­˜ä¸è¢«åˆ é™¤çš„ä»»åŠ¡
        while let Some(item) = queue.pop() {
            if item.handle == *task_handle {
                removed_from_queue = true;
                log::info!("ä»»åŠ¡ {} ä»å¾…å¤„ç†é˜Ÿåˆ—ä¸­ç§»é™¤.", task_handle.0);
                // ä¸å†æ”¾å› item
            } else {
                temp_heap.push(item);
            }
        }
        *queue = temp_heap; // å°†æœªåˆ é™¤çš„ä»»åŠ¡æ”¾å›åŸé˜Ÿåˆ—

        if was_running || removed_from_queue {
            self.publish_event(TaskExecutionEvent {
                task_handle: *task_handle,
                // ä»¥ä¸‹å­—æ®µå¯èƒ½éœ€è¦ä» active_tasks æˆ–å…¶ä»–åœ°æ–¹è·å–ï¼Œå¦‚æœä»»åŠ¡ä¿¡æ¯å·²ä¸åœ¨
                instance_id: "N/A_cancelled".to_string(), 
                batch_id: "N/A_cancelled".to_string(),
                sub_test_item: SubTestItem::Unknown, // éœ€è¦ä¸€ç§æ–¹å¼è·å–è¿™äº›ä¿¡æ¯
                event_type: TaskEventType::Cancelled,
                timestamp: Utc::now(),
                details: Some("ä»»åŠ¡è¢«è¯·æ±‚å–æ¶ˆ".to_string()),
                outcome: None,
            }).await;
             // ä» active_tasks ä¸­å½»åº•ç§»é™¤ï¼ˆå¦‚æœä»…æ ‡è®°è€Œæœªç§»é™¤ï¼‰
            self.active_tasks.write().await.remove(task_handle);
            Ok(())
        } else {
            log::warn!("å°è¯•å–æ¶ˆä»»åŠ¡ {}ï¼Œä½†åœ¨è¿è¡Œåˆ—è¡¨æˆ–é˜Ÿåˆ—ä¸­å‡æœªæ‰¾åˆ°å¯æ“ä½œé¡¹ã€‚", task_handle.0);
            Err(AppError::TaskNotFound(task_handle.0.clone()))
        }
    }

    async fn cancel_tasks_by_batch_id(&self, batch_id: &str) -> Result<usize, AppError> {
        let mut cancelled_count = 0;
        let mut tasks_to_cancel = Vec::new();

        // ä» active_tasks ä¸­æ”¶é›†å±äºè¯¥æ‰¹æ¬¡çš„ä»»åŠ¡å¥æŸ„
        let active_tasks_read = self.active_tasks.read().await;
        for (handle, info) in active_tasks_read.iter() {
            if info.task_definition.batch_id == batch_id && 
               (info.status == TaskStatus::Pending || info.status == TaskStatus::Running) {
                tasks_to_cancel.push(*handle);
            }
        }
        drop(active_tasks_read); // é‡Šæ”¾è¯»é”

        // ä» task_queue ä¸­æ”¶é›†å±äºè¯¥æ‰¹æ¬¡çš„ä»»åŠ¡å¥æŸ„
        let mut queue = self.task_queue.lock().await;
        let mut temp_heap_for_batch_cancel = BinaryHeap::new();
        let mut handles_in_queue = Vec::new();
        while let Some(item) = queue.pop() {
            if item.task.batch_id == batch_id {
                handles_in_queue.push(item.handle); // æ”¶é›†å¾…å–æ¶ˆçš„å¥æŸ„
            } else {
                temp_heap_for_batch_cancel.push(item); // ä¿ç•™ä¸ç›¸å…³çš„ä»»åŠ¡
            }
        }
        *queue = temp_heap_for_batch_cancel; // æ›´æ–°é˜Ÿåˆ—
        drop(queue); // é‡Šæ”¾é”

        tasks_to_cancel.extend(handles_in_queue);
        tasks_to_cancel.sort_unstable();
        tasks_to_cancel.dedup(); // å»é‡

        for handle in tasks_to_cancel {
            if self.cancel_task(&handle).await.is_ok() {
                cancelled_count += 1;
            }
        }
        log::info!("æ‰¹æ¬¡ {} ä¸‹å…±å–æ¶ˆ {} ä¸ªä»»åŠ¡ã€‚", batch_id, cancelled_count);
        Ok(cancelled_count)
    }


    async fn get_task_runtime_info(&self, task_handle: &TaskHandle) -> Result<Option<TaskRuntimeInfo>, AppError> {
        Ok(self.active_tasks.read().await.get(task_handle).cloned())
    }

    async fn list_tasks_by_batch_id(&self, batch_id: &str) -> Result<Vec<TaskRuntimeInfo>, AppError> {
        let active_tasks_map = self.active_tasks.read().await;
        let mut results = Vec::new();
        for info in active_tasks_map.values() {
            if info.task_definition.batch_id == batch_id {
                results.push(info.clone());
            }
        }
        // è¿˜åº”è€ƒè™‘é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        let queue = self.task_queue.lock().await;
        for item in queue.iter() {
            if item.task.batch_id == batch_id {
                 results.push(TaskRuntimeInfo { // ä»ScheduledTaskItemè½¬æ¢
                    handle: item.handle,
                    task_definition: item.task.clone(),
                    status: TaskStatus::Pending, // é˜Ÿåˆ—ä¸­çš„éƒ½æ˜¯Pending
                    current_retry_count: item.current_retry_count,
                    scheduled_at: item.scheduled_at,
                    started_at: None, completed_at: None, error_message: None,
                });
            }
        }
        results.sort_by_key(|info| info.scheduled_at); // æŒ‰è°ƒåº¦æ—¶é—´æ’åº
        Ok(results)
    }
    
    async fn get_active_task_count(&self) -> Result<usize, AppError> {
        let running_count = self.active_tasks.read().await.values().filter(|info| info.status == TaskStatus::Running).count();
        let pending_count = self.task_queue.lock().await.len();
        Ok(running_count + pending_count)
    }

    fn subscribe_to_task_events(&self) -> broadcast::Receiver<TaskExecutionEvent> {
        self.event_broadcaster.subscribe()
    }

    async fn set_max_concurrent_tasks(&self, limit: usize) -> Result<(), AppError> {
        if limit == 0 {
            return Err(AppError::InvalidInput("æœ€å¤§å¹¶å‘æ•°ä¸èƒ½ä¸º0".to_string()));
        }
        //å½“å‰çš„ Semaphore ä¸æ”¯æŒåŠ¨æ€è°ƒæ•´ permits æ•°é‡ã€‚
        //ä¸€ç§åšæ³•æ˜¯é‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„ Semaphoreï¼Œä½†è¿™ä¼šæ¯”è¾ƒå¤æ‚ï¼Œå°¤å…¶æ˜¯åœ¨å·²æœ‰ä»»åŠ¡è·å–äº†æ—§è®¸å¯æ—¶ã€‚
        //å¦ä¸€ç§æ˜¯ï¼Œåœ¨è·å–è®¸å¯çš„é€»è¾‘ä¸­ï¼Œé¢å¤–æ£€æŸ¥ä¸€ä¸ªAtomicUsizeç±»å‹çš„é™åˆ¶ã€‚
        //æˆ–è€…ï¼Œæ›´ç®€å•çš„æ˜¯åœ¨åˆ›å»ºè°ƒåº¦å™¨æ—¶è®¾ç½®ï¼Œåç»­ä¸å…è®¸ä¿®æ”¹ï¼Œæˆ–é‡å¯è°ƒåº¦å™¨æ¥åº”ç”¨æ–°é™åˆ¶ã€‚
        //æ­¤å¤„æˆ‘ä»¬ä»…æ›´æ–°å†…éƒ¨çš„ usize è®°å½•ï¼Œå¹¶åœ¨Semaphoreåˆ›å»ºæ—¶ä½¿ç”¨è¿™ä¸ªå€¼ã€‚
        //å¦‚æœéœ€è¦åŠ¨æ€è°ƒæ•´ï¼Œéœ€è¦æ›´å¤æ‚çš„ä¿¡å·é‡ç®¡ç†æˆ–è‡ªå®šä¹‰ä¿¡å·é‡ã€‚
        let mut max_tasks_guard = self.max_concurrent_tasks.write().await;
        *max_tasks_guard = limit;
        // æ³¨æ„ï¼šè¿™ä¸ä¼šæ”¹å˜ç°æœ‰ Semaphore çš„è®¸å¯æ•°ï¼Œåªå½±å“æ–°åˆ›å»ºçš„ Semaphore æˆ–è‡ªå®šä¹‰çš„è®¸å¯é€»è¾‘ã€‚
        // ä¸ºäº†çœŸæ­£åŠ¨æ€è°ƒæ•´ï¼Œéœ€è¦åœ¨ self.concurrency_semaphore.acquire_owned() å¤–é¢åŠ ä¸€å±‚é€»è¾‘
        // æˆ–è€…åœ¨åˆ›å»ºæ—¶å°±å›ºå®šã€‚æ­¤å¤„ä»…æ›´æ–°é…ç½®å€¼ã€‚
        log::warn!("set_max_concurrent_tasks ä»…æ›´æ–°é…ç½®å€¼ï¼Œä¸ä¼šåŠ¨æ€è°ƒæ•´è¿è¡Œä¸­çš„ä¿¡å·é‡ã€‚å¦‚éœ€è°ƒæ•´è¯·é‡å¯è°ƒåº¦å™¨æˆ–å®ç°æ›´å¤æ‚çš„ä¿¡å·é‡ç®¡ç†ã€‚æ–°çš„é…ç½®å€¼ä¸º: {}", limit);
        Ok(())
    }
    
    async fn get_max_concurrent_tasks(&self) -> Result<usize, AppError> {
        Ok(*self.max_concurrent_tasks.read().await)
    }

    async fn shutdown(&self, timeout_ms: Option<u64>) -> Result<(), AppError> {
        log::info!("å¼€å§‹å…³é—­ AdvancedTaskScheduler...");
        // 1. å‘é€å…³é—­ä¿¡å·ï¼Œåœæ­¢æ¥å—æ–°ä»»åŠ¡å’Œå¤„ç†å¾ªç¯æ‹¾å–æ–°ä»»åŠ¡
        self.shutdown_signal_tx.send(true).map_err(|e| AppError::InternalError(format!("å‘é€å…³é—­ä¿¡å·å¤±è´¥: {}", e)))?;
        
        // 2. æ¸…ç©ºä»»åŠ¡é˜Ÿåˆ— (å¯é€‰ï¼Œå–å†³äºæ˜¯å¦å¸Œæœ›å·²è°ƒåº¦çš„ä»»åŠ¡è¢«å–æ¶ˆ)
        self.task_queue.lock().await.clear();
        log::info!("ä»»åŠ¡é˜Ÿåˆ—å·²æ¸…ç©ºã€‚");

        // 3. ç­‰å¾…å½“å‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        let active_handles: Vec<TaskHandle> = self.running_task_handles.read().await.keys().cloned().collect();
        let mut join_handles_to_wait = Vec::new();
        
        let mut running_tasks_guard = self.running_task_handles.write().await;
        for handle in active_handles {
            if let Some(join_handle) = running_tasks_guard.remove(&handle) {
                 join_handles_to_wait.push(join_handle);
            }
        }
        drop(running_tasks_guard);

        if !join_handles_to_wait.is_empty() {
            log::info!("ç­‰å¾… {} ä¸ªæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å®Œæˆ...", join_handles_to_wait.len());
            let timeout_duration = Duration::from_millis(timeout_ms.unwrap_or(30000)); // é»˜è®¤30ç§’è¶…æ—¶
            
            for jh in join_handles_to_wait {
                match tokio::time::timeout(timeout_duration, jh).await {
                    Ok(Ok(_)) => log::debug!("ä¸€ä¸ªä»»åŠ¡åœ¨å…³é—­æœŸé—´æ­£å¸¸å®Œæˆã€‚"),
                    Ok(Err(e)) => log::warn!("ä¸€ä¸ªä»»åŠ¡åœ¨å…³é—­æœŸé—´panic: {:?}", e), // task panicked
                    Err(_) => log::warn!("ä¸€ä¸ªä»»åŠ¡åœ¨å…³é—­æœŸé—´è¶…æ—¶ï¼Œå¯èƒ½è¢«å¼ºåˆ¶ç»ˆæ­¢ã€‚"), // timeout
                }
            }
        }
        
        // å…³é—­ä¿¡å·é‡ï¼Œä»¥å”¤é†’ä»»ä½•åœ¨ acquire_owned() ä¸Šé˜»å¡çš„ç­‰å¾…è€…
        self.concurrency_semaphore.close();

        log::info!("AdvancedTaskScheduler å·²æˆåŠŸå…³é—­ã€‚");
        Ok(())
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ (æ­¥éª¤ 3.3)
æµ‹è¯• `AdvancedTaskScheduler` éœ€è¦ Mock `IChannelStateManager`, `IConfigurationRepository`, `IRuntimeRepository`, `IPlcCommunicationService` (é€šè¿‡å·¥å‚) å’Œ `ISpecificTestStepExecutor`ã€‚

```rust
// src/services/task_scheduling/tests/advanced_task_scheduler_tests.rs (ç»­)
use crate::services::task_scheduling::scheduler::*;
use crate::services::task_scheduling::task_models::*;
use crate::services::task_scheduling::test_executors::ISpecificTestStepExecutor;
use crate::services::state_management::{MockIChannelStateManager, IChannelStateManager}; // Mock
use crate::services::persistence::repositories::configuration_repository::{MockIConfigurationRepository, IConfigurationRepository}; // Mock
use crate::services::persistence::repositories::runtime_repository::{MockIRuntimeRepository, IRuntimeRepository}; // Mock
use crate::services::plc_communication::{MockIPlcCommunicationService, IPlcCommunicationService}; // Mock
use crate::models::enums::{TaskPriority, TaskStatus, SubTestItem, TestResult, OverallTestStatus, ModuleType};
use crate::models::runtime::{ChannelPointDefinition, ChannelTestInstance, TestOutcome};
use std::sync::Arc;
use tokio::sync::Mutex as TokioMutex; // Tokio Mutex for shared test state
use std::collections::HashMap;
use mockall::predicate::*;
use chrono::Utc;


// Mock SpecificTestStepExecutor
mock! {
    MyTestExecutor {}
    #[async_trait::async_trait]
    impl ISpecificTestStepExecutor for MyTestExecutor {
        fn item_type(&self) -> SubTestItem;
        async fn execute(&self, task: &TestTask, instance_snapshot: &ChannelTestInstance, definition: &ChannelPointDefinition, plc_service: Arc<dyn IPlcCommunicationService>) -> Result<TestOutcome, AppError>;
    }
}


#[tokio::test]
async fn test_scheduler_schedule_and_execute_task_successfully() {
    let mut mock_state_manager = MockIChannelStateManager::new();
    let mut mock_config_repo = MockIConfigurationRepository::new();
    let mut mock_runtime_repo = MockIRuntimeRepository::new();
    let mut mock_executor = MockMyTestExecutor::new();

    let task_def_id = "def_sched_test".to_string();
    let task_inst_id = "inst_sched_test".to_string();

    // Executor Mocks
    mock_executor.expect_item_type().return_const(SubTestItem::HardPoint);
    mock_executor.expect_execute()
        .times(1)
        .returning(|_task, _inst, _def, _plc| {
            Ok(TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() })
        });
    
    // Config Repo Mock
    mock_config_repo.expect_get_channel_definition_by_id()
        .with(eq(task_def_id.clone()))
        .times(1)
        .returning(move |_| Ok(Some(ChannelPointDefinition { id: task_def_id.clone(), module_type: ModuleType::AI, ..Default::default() })));

    // Runtime Repo Mock
    mock_runtime_repo.expect_get_channel_instance()
        .with(eq(task_inst_id.clone()))
        .times(1)
        .returning(move |_| Ok(Some(ChannelTestInstance { instance_id: task_inst_id.clone(), ..Default::default() })));

    // State Manager Mock
    mock_state_manager.expect_apply_raw_outcome()
        .withf(move |inst_id, outcome| inst_id == task_inst_id && outcome.result == TestResult::Passed)
        .times(1)
        .returning(|_, _| Ok(Default::default())); // Default StateTransition


    let mut executors_map = HashMap::new();
    executors_map.insert(SubTestItem::HardPoint, Arc::new(mock_executor) as Arc<dyn ISpecificTestStepExecutor>);

    let plc_factory = Arc::new(|| Arc::new(MockIPlcCommunicationService::new()) as Arc<dyn IPlcCommunicationService>);

    let scheduler = AdvancedTaskScheduler::new(
        Arc::new(mock_state_manager),
        Arc::new(mock_config_repo),
        Arc::new(mock_runtime_repo),
        plc_factory,
        executors_map,
        Some(1) // Max 1 concurrent task for predictable testing
    );
    scheduler.clone().start_processing_loop(); // Start the loop

    let task_to_schedule = TestTask {
        task_id: "task1".to_string(), instance_id: task_inst_id.clone(), definition_id: task_def_id.clone(),
        batch_id: "batch1".to_string(), sub_test_item: SubTestItem::HardPoint,
        priority: TaskPriority::Normal, created_at: Utc::now(), max_retries: 0, timeout_ms: None, metadata: None,
    };
    
    let mut event_rx = scheduler.subscribe_to_task_events();
    let handle = scheduler.schedule_task(task_to_schedule).await.unwrap();

    // Wait for events: Scheduled, Started, CompletedSuccessfully
    let mut received_event_types = Vec::new();
    for _ in 0..3 { // Expect 3 events
        match tokio::time::timeout(std::time::Duration::from_secs(5), event_rx.recv()).await {
            Ok(Ok(event)) if event.task_handle == handle => {
                received_event_types.push(event.event_type);
            }
            Ok(Ok(other_event)) => println!("Received event for other task: {:?}", other_event),
            Ok(Err(e)) => panic!("Event recv error: {:?}", e),
            Err(_) => panic!("Timeout waiting for task event"),
        }
    }
    assert!(received_event_types.contains(&TaskEventType::Scheduled));
    assert!(received_event_types.contains(&TaskEventType::Started));
    assert!(received_event_types.contains(&TaskEventType::CompletedSuccessfully));

    let info_opt = scheduler.get_task_runtime_info(&handle).await.unwrap();
    // After completion, task info might be moved from active_tasks.
    // The test needs to be adjusted based on how final status is stored/queried.
    // For this test, the mocks ensure it goes through, and events confirm it.
    
    scheduler.shutdown(Some(100)).await.unwrap();
}


#[tokio::test]
async fn test_scheduler_task_retry_then_success() {
    let mut mock_state_manager = MockIChannelStateManager::new();
    let mut mock_config_repo = MockIConfigurationRepository::new();
    let mut mock_runtime_repo = MockIRuntimeRepository::new();
    let mut mock_executor = MockMyTestExecutor::new();

    let task_def_id = "def_retry".to_string();
    let task_inst_id = "inst_retry".to_string();

    // Executor: first call fails, second call passes
    let attempt_count = Arc::new(TokioMutex::new(0));
    mock_executor.expect_item_type().return_const(SubTestItem::HardPoint);
    mock_executor.expect_execute()
        .times(2) // Expect two calls due to retry
        .returning({
            let ac = attempt_count.clone();
            move |_task, _inst, _def, _plc| {
                let mut count = futures::executor::block_on(ac.lock());
                *count += 1;
                if *count == 1 {
                    Ok(TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Failed, error_message: Some("First attempt failed".to_string()), ..Default::default() })
                } else {
                    Ok(TestOutcome { test_item: SubTestItem::HardPoint, result: TestResult::Passed, ..Default::default() })
                }
            }
        });
    
    mock_config_repo.expect_get_channel_definition_by_id().returning(move |_| Ok(Some(ChannelPointDefinition { id: task_def_id.clone(), module_type: ModuleType::AI, ..Default::default() })));
    mock_runtime_repo.expect_get_channel_instance().returning(move |_| Ok(Some(ChannelTestInstance { instance_id: task_inst_id.clone(), ..Default::default() })));
    // StateManager: expect apply_raw_outcome for the failure, then for the success
    mock_state_manager.expect_apply_raw_outcome().times(2).returning(|_, _| Ok(Default::default()));


    let mut executors_map = HashMap::new();
    executors_map.insert(SubTestItem::HardPoint, Arc::new(mock_executor) as Arc<dyn ISpecificTestStepExecutor>);
    let plc_factory = Arc::new(|| Arc::new(MockIPlcCommunicationService::new()) as Arc<dyn IPlcCommunicationService>);

    let scheduler = AdvancedTaskScheduler::new(
        Arc::new(mock_state_manager), Arc::new(mock_config_repo), Arc::new(mock_runtime_repo),
        plc_factory, executors_map, Some(1)
    );
    scheduler.clone().start_processing_loop();

    let task_to_schedule = TestTask {
        task_id: "task_retry".to_string(), instance_id: task_inst_id.clone(), definition_id: task_def_id.clone(),
        batch_id: "batch_retry".to_string(), sub_test_item: SubTestItem::HardPoint,
        priority: TaskPriority::Normal, created_at: Utc::now(), 
        max_retries: 1, // Allow 1 retry
        timeout_ms: None, metadata: None,
    };
    
    let mut event_rx = scheduler.subscribe_to_task_events();
    let handle = scheduler.schedule_task(task_to_schedule).await.unwrap();

    // Events: Scheduled, Started, AttemptFailed, Started (retry), CompletedSuccessfully
    let mut received_event_types = Vec::new();
    for _ in 0..5 { 
        match tokio::time::timeout(std::time::Duration::from_secs(5), event_rx.recv()).await {
            Ok(Ok(event)) if event.task_handle == handle => { received_event_types.push(event.event_type); }
            _ => break,
        }
    }
    assert!(received_event_types.contains(&TaskEventType::Scheduled));
    assert_eq!(received_event_types.iter().filter(|&&e| e == TaskEventType::Started).count(), 2); // Started twice
    assert!(received_event_types.contains(&TaskEventType::AttemptFailed));
    assert!(received_event_types.contains(&TaskEventType::CompletedSuccessfully));
    
    scheduler.shutdown(Some(100)).await.unwrap();
}


#[tokio::test]
async fn test_scheduler_concurrency_limit() {
    let mut mock_config_repo = MockIConfigurationRepository::new();
    let mut mock_runtime_repo = MockIRuntimeRepository::new();
    let mock_state_manager = Arc::new(MockIChannelStateManager::new()); // Not strictly needed for this test focus

    let active_task_counter = Arc::new(TokioMutex::new(0));
    let max_concurrent_seen = Arc::new(TokioMutex::new(0));
    
    // Mock executor that simulates work and tracks active tasks
    let mut mock_executors: HashMap<SubTestItem, Arc<dyn ISpecificTestStepExecutor>> = HashMap::new();

    for i in 0..5 { // Create 5 types of items to schedule 5 tasks
        let item_type = match i {
            0 => SubTestItem::HardPoint, 1 => SubTestItem::LowAlarm, 2 => SubTestItem::HighAlarm,
            3 => SubTestItem::LowLowAlarm, _ => SubTestItem::HighHighAlarm,
        };
        
        let mut exec = MockMyTestExecutor::new();
        exec.expect_item_type().return_const(item_type);
        exec.expect_execute().returning({
            let counter_clone = active_task_counter.clone();
            let max_seen_clone = max_concurrent_seen.clone();
            move |_task, _inst, _def, _plc| {
                let cc = counter_clone.clone();
                let msc = max_seen_clone.clone();
                async move { // mockall needs this async block for async trait methods
                    let mut current_active = cc.lock().await;
                    *current_active += 1;
                    let mut max_s = msc.lock().await;
                    if *current_active > *max_s {
                        *max_s = *current_active;
                    }
                    drop(current_active); // release lock before sleep
                    drop(max_s);

                    tokio::time::sleep(std::time::Duration::from_millis(200)).await; // Simulate work

                    let mut current_active_after = cc.lock().await;
                    *current_active_after -= 1;
                    drop(current_active_after);
                    Ok(TestOutcome { test_item: item_type, result: TestResult::Passed, ..Default::default() })
                }.tokio_test_scope() // Helper for async blocks in mockall if needed
            }
        });
        mock_executors.insert(item_type, Arc::new(exec));
    }


    mock_config_repo.expect_get_channel_definition_by_id().returning(|id| Ok(Some(ChannelPointDefinition { id: id.to_string(), module_type: ModuleType::AI, ..Default::default() })));
    mock_runtime_repo.expect_get_channel_instance().returning(|id| Ok(Some(ChannelTestInstance { instance_id: id.to_string(), ..Default::default() })));
    // State manager apply_raw_outcome will be called, mock it minimally
    let mut state_manager_mock_for_concurrency = MockIChannelStateManager::new();
    state_manager_mock_for_concurrency.expect_apply_raw_outcome().returning(|_,_| Ok(Default::default()));


    let plc_factory = Arc::new(|| Arc::new(MockIPlcCommunicationService::new()) as Arc<dyn IPlcCommunicationService>);
    let scheduler = AdvancedTaskScheduler::new(
        Arc::new(state_manager_mock_for_concurrency), Arc::new(mock_config_repo), Arc::new(mock_runtime_repo),
        plc_factory, mock_executors, Some(2) // Max 2 concurrent tasks
    );
    scheduler.clone().start_processing_loop();

    let mut event_rx = scheduler.subscribe_to_task_events();
    let mut task_handles = Vec::new();

    let items_to_schedule = [SubTestItem::HardPoint, SubTestItem::LowAlarm, SubTestItem::HighAlarm, SubTestItem::LowLowAlarm, SubTestItem::HighHighAlarm];
    for (i, &item) in items_to_schedule.iter().enumerate() {
        let task = TestTask {
            task_id: format!("task_conc_{}", i), instance_id: format!("inst_conc_{}", i), definition_id: format!("def_conc_{}", i),
            batch_id: "batch_conc".to_string(), sub_test_item: item,
            priority: TaskPriority::Normal, created_at: Utc::now(), max_retries: 0, timeout_ms: None, metadata: None,
        };
        task_handles.push(scheduler.schedule_task(task).await.unwrap());
    }

    // Wait for all tasks to complete (5 tasks * 1 event type (CompletedSuccessfully))
    let