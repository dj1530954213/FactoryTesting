# FAT_TEST ç³»ç»Ÿé‡æ„è¯¦ç»†å®æ–½æ­¥éª¤

## ğŸ“‹ é‡æ„å®æ–½æ¦‚è§ˆ

### ğŸ¯ å®æ–½åŸåˆ™
1. **é›¶åœæœºé‡æ„**: é€šè¿‡åˆ†é˜¶æ®µå®æ–½ï¼Œç¡®ä¿ç³»ç»ŸæŒç»­å¯ç”¨
2. **å‘åå…¼å®¹**: æ–°æ¥å£å…¼å®¹ç°æœ‰åŠŸèƒ½ï¼Œé€æ­¥æ›¿æ¢æ—§å®ç°
3. **æµ‹è¯•é©±åŠ¨**: æ¯ä¸ªæ­¥éª¤éƒ½æœ‰å®Œæ•´çš„æµ‹è¯•è¦†ç›–
4. **æŒç»­éªŒè¯**: æ¯ä¸ªé˜¶æ®µå®Œæˆåè¿›è¡Œé›†æˆæµ‹è¯•

### ğŸ—“ï¸ å®æ–½è®¡åˆ’ (4ä¸ªé˜¶æ®µ)

#### Phase 1: æ•°æ®è®¿é—®å±‚é‡æ„ (Repository Layer)
- **ç›®æ ‡**: å»ºç«‹ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£
- **å·¥æœŸ**: 1-2å‘¨
- **å…³é”®äº§å‡º**: Repositoryæ¥å£å’Œå®ç°ç±»

#### Phase 2: çŠ¶æ€ç®¡ç†å™¨é‡æ„ (State Management)
- **ç›®æ ‡**: å»ºç«‹ä¸¥æ ¼çš„çŠ¶æ€ç®¡ç†æœºåˆ¶
- **å·¥æœŸ**: 1-2å‘¨
- **å…³é”®äº§å‡º**: å¢å¼ºçš„ChannelStateManager

#### Phase 3: ä»»åŠ¡è°ƒåº¦å™¨é‡æ„ (Task Scheduling)
- **ç›®æ ‡**: ä¼˜åŒ–æµ‹è¯•ä»»åŠ¡ç®¡ç†å’Œè°ƒåº¦
- **å·¥æœŸ**: 2-3å‘¨
- **å…³é”®äº§å‡º**: æ–°çš„TaskSchedulerå’ŒTestExecutor

#### Phase 4: åº”ç”¨æœåŠ¡å±‚é‡æ„ (Application Services)
- **ç›®æ ‡**: é‡æ„åº”ç”¨æœåŠ¡ï¼Œå®ç°æœåŠ¡ç»„åˆæ¨¡å¼
- **å·¥æœŸ**: 1-2å‘¨
- **å…³é”®äº§å‡º**: é‡æ„çš„åº”ç”¨æœåŠ¡

---

## ğŸš€ Phase 1: æ•°æ®è®¿é—®å±‚é‡æ„

### æ­¥éª¤ 1.1: åˆ›å»ºRepositoryåŸºç¡€æ¥å£

#### ğŸ¯ ç›®æ ‡
å»ºç«‹ç»Ÿä¸€çš„æ•°æ®è®¿é—®æŠ½è±¡ï¼Œä¸ºæ‰€æœ‰æ•°æ®æ“ä½œæä¾›ä¸€è‡´çš„æ¥å£ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.1.1 åˆ›å»ºåŸºç¡€Repositoryæ¥å£
```rust
// src/repositories/mod.rs
use async_trait::async_trait;
use serde::{Serialize, de::DeserializeOwned};
use std::fmt::Debug;
use crate::models::errors::RepositoryError;

/// åŸºç¡€Repositoryæ¥å£
#[async_trait]
pub trait IRepository<T, K>: Send + Sync 
where 
    T: Send + Sync + Clone + Debug,
    K: Send + Sync + Clone + Debug,
{
    /// æ ¹æ®é”®è·å–å®ä½“
    async fn get(&self, key: &K) -> Result<Option<T>, RepositoryError>;
    
    /// ä¿å­˜å®ä½“
    async fn save(&self, entity: &T) -> Result<(), RepositoryError>;
    
    /// åˆ é™¤å®ä½“
    async fn delete(&self, key: &K) -> Result<bool, RepositoryError>;
    
    /// æ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨
    async fn exists(&self, key: &K) -> Result<bool, RepositoryError>;
    
    /// è·å–æ‰€æœ‰å®ä½“
    async fn list_all(&self) -> Result<Vec<T>, RepositoryError>;
    
    /// æ ¹æ®æ¡ä»¶æŸ¥è¯¢
    async fn query(&self, criteria: &QueryCriteria) -> Result<Vec<T>, RepositoryError>;
}

/// æŸ¥è¯¢æ¡ä»¶
#[derive(Debug, Clone)]
pub struct QueryCriteria {
    pub filters: Vec<Filter>,
    pub sort_by: Option<String>,
    pub limit: Option<usize>,
    pub offset: Option<usize>,
}

/// è¿‡æ»¤æ¡ä»¶
#[derive(Debug, Clone)]
pub struct Filter {
    pub field: String,
    pub operator: FilterOperator,
    pub value: FilterValue,
}

#[derive(Debug, Clone)]
pub enum FilterOperator {
    Equal,
    NotEqual,
    GreaterThan,
    LessThan,
    Contains,
    In,
}

#[derive(Debug, Clone)]
pub enum FilterValue {
    String(String),
    Number(f64),
    Boolean(bool),
    List(Vec<String>),
}
```

##### 1.1.2 åˆ›å»ºRepositoryé”™è¯¯ç±»å‹
```rust
// src/models/errors.rs (æ‰©å±•ç°æœ‰é”™è¯¯ç±»å‹)
use thiserror::Error;
use serde::Serialize;

#[derive(Error, Debug, Clone, Serialize)]
pub enum RepositoryError {
    #[error("Entity not found: {0}")]
    NotFound(String),
    
    #[error("Serialization error: {0}")]
    SerializationError(String),
    
    #[error("Deserialization error: {0}")]
    DeserializationError(String),
    
    #[error("Database error: {0}")]
    DatabaseError(String),
    
    #[error("Concurrency conflict: {0}")]
    ConcurrencyError(String),
    
    #[error("Validation error: {0}")]
    ValidationError(String),
    
    #[error("Access denied: {0}")]
    AccessDenied(String),
    
    #[error("Internal error: {0}")]
    InternalError(String),
}

impl From<std::io::Error> for RepositoryError {
    fn from(err: std::io::Error) -> Self {
        RepositoryError::InternalError(err.to_string())
    }
}

impl From<serde_json::Error> for RepositoryError {
    fn from(err: serde_json::Error) -> Self {
        RepositoryError::SerializationError(err.to_string())
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

##### 1.1.3 åˆ›å»ºRepositoryæµ‹è¯•æ¡†æ¶
```rust
// src/repositories/tests/mod.rs
use super::*;
use tokio;
use uuid::Uuid;

/// Repositoryæµ‹è¯•ç”¨ä¾‹åŸºç¡€trait
#[async_trait]
pub trait RepositoryTestSuite<T, K, R>
where
    T: Send + Sync + Clone + Debug + PartialEq,
    K: Send + Sync + Clone + Debug,
    R: IRepository<T, K>,
{
    /// åˆ›å»ºæµ‹è¯•ç”¨Repositoryå®ä¾‹
    async fn create_repository() -> R;
    
    /// åˆ›å»ºæµ‹è¯•å®ä½“
    fn create_test_entity() -> T;
    
    /// è·å–å®ä½“çš„é”®
    fn get_entity_key(entity: &T) -> K;
    
    /// åŸºç¡€CRUDæµ‹è¯•
    async fn test_crud_operations() {
        let repo = Self::create_repository().await;
        let entity = Self::create_test_entity();
        let key = Self::get_entity_key(&entity);
        
        // æµ‹è¯•ä¿å­˜
        repo.save(&entity).await.expect("ä¿å­˜å¤±è´¥");
        
        // æµ‹è¯•è·å–
        let retrieved = repo.get(&key).await.expect("è·å–å¤±è´¥");
        assert!(retrieved.is_some(), "å®ä½“åº”è¯¥å­˜åœ¨");
        assert_eq!(retrieved.unwrap(), entity, "å®ä½“æ•°æ®åº”è¯¥ä¸€è‡´");
        
        // æµ‹è¯•å­˜åœ¨æ€§æ£€æŸ¥
        let exists = repo.exists(&key).await.expect("å­˜åœ¨æ€§æ£€æŸ¥å¤±è´¥");
        assert!(exists, "å®ä½“åº”è¯¥å­˜åœ¨");
        
        // æµ‹è¯•åˆ é™¤
        let deleted = repo.delete(&key).await.expect("åˆ é™¤å¤±è´¥");
        assert!(deleted, "åº”è¯¥åˆ é™¤æˆåŠŸ");
        
        // éªŒè¯åˆ é™¤
        let exists_after_delete = repo.exists(&key).await.expect("åˆ é™¤åå­˜åœ¨æ€§æ£€æŸ¥å¤±è´¥");
        assert!(!exists_after_delete, "å®ä½“åº”è¯¥ä¸å­˜åœ¨");
    }
    
    /// æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•
    async fn test_query_operations() {
        let repo = Self::create_repository().await;
        
        // åˆ›å»ºå¤šä¸ªæµ‹è¯•å®ä½“
        let entities = (0..5).map(|_| Self::create_test_entity()).collect::<Vec<_>>();
        
        // ä¿å­˜æ‰€æœ‰å®ä½“
        for entity in &entities {
            repo.save(entity).await.expect("æ‰¹é‡ä¿å­˜å¤±è´¥");
        }
        
        // æµ‹è¯•åˆ—è¡¨æŸ¥è¯¢
        let all_entities = repo.list_all().await.expect("åˆ—è¡¨æŸ¥è¯¢å¤±è´¥");
        assert!(all_entities.len() >= entities.len(), "åº”è¯¥åŒ…å«æ‰€æœ‰ä¿å­˜çš„å®ä½“");
        
        // æµ‹è¯•æ¡ä»¶æŸ¥è¯¢
        let criteria = QueryCriteria {
            filters: vec![],
            sort_by: None,
            limit: Some(3),
            offset: None,
        };
        let limited_results = repo.query(&criteria).await.expect("æ¡ä»¶æŸ¥è¯¢å¤±è´¥");
        assert!(limited_results.len() <= 3, "é™åˆ¶æŸ¥è¯¢ç»“æœæ•°é‡");
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_repository_interface() {
        // æµ‹è¯•å°†åœ¨å…·ä½“Repositoryå®ç°ä¸­è¿›è¡Œ
    }
}
```

### æ­¥éª¤ 1.2: åˆ›å»ºé…ç½®æ•°æ®Repository

#### ğŸ¯ ç›®æ ‡
å®ç°ä¸“é—¨ç®¡ç†é…ç½®æ•°æ®çš„Repositoryï¼Œç¡®ä¿é…ç½®æ•°æ®çš„ä¸€è‡´æ€§å’Œå®Œæ•´æ€§ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.2.1 å®šä¹‰é…ç½®Repositoryæ¥å£
```rust
// src/repositories/configuration_repository.rs
use async_trait::async_trait;
use crate::models::structs::{ChannelPointDefinition, TestParameterSet};
use crate::models::enums::ModuleType;
use crate::models::errors::RepositoryError;
use super::{IRepository, QueryCriteria};

/// é…ç½®æ•°æ®Repositoryæ¥å£
#[async_trait]
pub trait IConfigurationRepository: Send + Sync {
    // ç‚¹ä½å®šä¹‰ç®¡ç†
    async fn get_channel_definition(&self, id: &str) -> Result<Option<ChannelPointDefinition>, RepositoryError>;
    async fn save_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<(), RepositoryError>;
    async fn delete_channel_definition(&self, id: &str) -> Result<bool, RepositoryError>;
    async fn list_channel_definitions(&self) -> Result<Vec<ChannelPointDefinition>, RepositoryError>;
    async fn query_channel_definitions(&self, criteria: &QueryCriteria) -> Result<Vec<ChannelPointDefinition>, RepositoryError>;
    
    // æ‰¹é‡æ“ä½œ
    async fn save_channel_definitions_batch(&self, definitions: &[ChannelPointDefinition]) -> Result<(), RepositoryError>;
    async fn import_from_excel(&self, file_path: &str, config_name: &str) -> Result<Vec<ChannelPointDefinition>, RepositoryError>;
    async fn export_to_excel(&self, definitions: &[ChannelPointDefinition], file_path: &str) -> Result<(), RepositoryError>;
    
    // é…ç½®é›†ç®¡ç†
    async fn save_configuration_set(&self, name: &str, definitions: &[ChannelPointDefinition]) -> Result<(), RepositoryError>;
    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, RepositoryError>;
    async fn list_configuration_sets(&self) -> Result<Vec<String>, RepositoryError>;
    async fn delete_configuration_set(&self, name: &str) -> Result<bool, RepositoryError>;
    
    // æµ‹è¯•å‚æ•°ç®¡ç†
    async fn get_test_parameters(&self, module_type: ModuleType) -> Result<Option<TestParameterSet>, RepositoryError>;
    async fn save_test_parameters(&self, module_type: ModuleType, params: &TestParameterSet) -> Result<(), RepositoryError>;
    async fn list_test_parameters(&self) -> Result<Vec<(ModuleType, TestParameterSet)>, RepositoryError>;
    
    // æ¨¡æ¿ç®¡ç†
    async fn save_definition_template(&self, template_name: &str, template: &ChannelPointDefinition) -> Result<(), RepositoryError>;
    async fn get_definition_template(&self, template_name: &str) -> Result<Option<ChannelPointDefinition>, RepositoryError>;
    async fn list_definition_templates(&self) -> Result<Vec<String>, RepositoryError>;
    
    // éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥
    async fn validate_definitions(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ValidationIssue>, RepositoryError>;
    async fn check_consistency(&self) -> Result<ConsistencyReport, RepositoryError>;
}

/// éªŒè¯é—®é¢˜
#[derive(Debug, Clone)]
pub struct ValidationIssue {
    pub severity: ValidationSeverity,
    pub message: String,
    pub field: Option<String>,
    pub suggestion: Option<String>,
}

#[derive(Debug, Clone)]
pub enum ValidationSeverity {
    Error,
    Warning,
    Info,
}

/// ä¸€è‡´æ€§æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct ConsistencyReport {
    pub total_definitions: usize,
    pub duplicates: Vec<String>,
    pub orphaned_references: Vec<String>,
    pub missing_parameters: Vec<String>,
    pub issues: Vec<ValidationIssue>,
}
```

##### 1.2.2 å®ç°å†…å­˜é…ç½®Repository
```rust
// src/repositories/configuration_repository.rs (continued)
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;

/// å†…å­˜é…ç½®Repositoryå®ç°
pub struct MemoryConfigurationRepository {
    definitions: Arc<RwLock<HashMap<String, ChannelPointDefinition>>>,
    configuration_sets: Arc<RwLock<HashMap<String, Vec<String>>>>, // name -> definition_ids
    test_parameters: Arc<RwLock<HashMap<ModuleType, TestParameterSet>>>,
    templates: Arc<RwLock<HashMap<String, ChannelPointDefinition>>>,
}

impl MemoryConfigurationRepository {
    pub fn new() -> Self {
        Self {
            definitions: Arc::new(RwLock::new(HashMap::new())),
            configuration_sets: Arc::new(RwLock::new(HashMap::new())),
            test_parameters: Arc::new(RwLock::new(HashMap::new())),
            templates: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// åˆ›å»ºé¢„å¡«å……æµ‹è¯•æ•°æ®çš„å®ä¾‹
    pub async fn new_with_test_data() -> Self {
        let repo = Self::new();
        repo.populate_test_data().await;
        repo
    }
    
    async fn populate_test_data(&self) {
        // æ·»åŠ é»˜è®¤æµ‹è¯•å‚æ•°
        let ai_params = TestParameterSet {
            default_range: Some((0.0, 100.0)),
            test_points: vec![0.0, 25.0, 50.0, 75.0, 100.0],
            tolerance: 1.0,
            test_sequence: vec![
                SubTestItem::HardPoint,
                SubTestItem::LowAlarm,
                SubTestItem::HighAlarm,
            ],
        };
        
        let mut params = self.test_parameters.write().await;
        params.insert(ModuleType::AI, ai_params);
    }
}

#[async_trait]
impl IConfigurationRepository for MemoryConfigurationRepository {
    async fn get_channel_definition(&self, id: &str) -> Result<Option<ChannelPointDefinition>, RepositoryError> {
        let definitions = self.definitions.read().await;
        Ok(definitions.get(id).cloned())
    }
    
    async fn save_channel_definition(&self, definition: &ChannelPointDefinition) -> Result<(), RepositoryError> {
        let mut definitions = self.definitions.write().await;
        definitions.insert(definition.id.clone(), definition.clone());
        Ok(())
    }
    
    async fn delete_channel_definition(&self, id: &str) -> Result<bool, RepositoryError> {
        let mut definitions = self.definitions.write().await;
        Ok(definitions.remove(id).is_some())
    }
    
    async fn list_channel_definitions(&self) -> Result<Vec<ChannelPointDefinition>, RepositoryError> {
        let definitions = self.definitions.read().await;
        Ok(definitions.values().cloned().collect())
    }
    
    async fn query_channel_definitions(&self, criteria: &QueryCriteria) -> Result<Vec<ChannelPointDefinition>, RepositoryError> {
        let definitions = self.definitions.read().await;
        let mut results: Vec<ChannelPointDefinition> = definitions.values().cloned().collect();
        
        // åº”ç”¨è¿‡æ»¤å™¨
        for filter in &criteria.filters {
            results = self.apply_filter(results, filter)?;
        }
        
        // åº”ç”¨æ’åº
        if let Some(sort_field) = &criteria.sort_by {
            self.sort_definitions(&mut results, sort_field);
        }
        
        // åº”ç”¨åˆ†é¡µ
        if let Some(offset) = criteria.offset {
            results = results.into_iter().skip(offset).collect();
        }
        
        if let Some(limit) = criteria.limit {
            results.truncate(limit);
        }
        
        Ok(results)
    }
    
    async fn save_channel_definitions_batch(&self, definitions: &[ChannelPointDefinition]) -> Result<(), RepositoryError> {
        let mut def_map = self.definitions.write().await;
        for definition in definitions {
            def_map.insert(definition.id.clone(), definition.clone());
        }
        Ok(())
    }
    
    async fn import_from_excel(&self, file_path: &str, config_name: &str) -> Result<Vec<ChannelPointDefinition>, RepositoryError> {
        use calamine::{Reader, Xlsx, open_workbook};
        
        // æ‰“å¼€Excelå·¥ä½œç°¿
        let mut workbook: Xlsx<_> = open_workbook(file_path)
            .map_err(|e| RepositoryError::DeserializationError(format!("æ— æ³•æ‰“å¼€Excelæ–‡ä»¶: {}", e)))?;
        
        // è·å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
        let worksheet_name = workbook.sheet_names().get(0)
            .ok_or_else(|| RepositoryError::DeserializationError("Excelæ–‡ä»¶æ²¡æœ‰å·¥ä½œè¡¨".to_string()))?
            .clone();
        
        let range = workbook.worksheet_range(&worksheet_name)
            .map_err(|e| RepositoryError::DeserializationError(format!("æ— æ³•è¯»å–å·¥ä½œè¡¨: {}", e)))?;
        
        let mut definitions = Vec::new();
        
        // è·³è¿‡è¡¨å¤´ï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹è§£æ
        for (row_index, row) in range.rows().enumerate().skip(1) {
            if row.is_empty() || row.len() < 52 {
                continue;
            }
            
            // è§£ææ¯ä¸€è¡Œçš„æ•°æ®ï¼Œæ„å»ºChannelPointDefinition
            let definition = self.parse_excel_row(row, row_index + 2)?; // +2æ˜¯å› ä¸ºExcelè¡Œå·ä»1å¼€å§‹ï¼Œæˆ‘ä»¬è·³è¿‡äº†è¡¨å¤´
            definitions.push(definition);
        }
        
        // éªŒè¯å¯¼å…¥çš„æ•°æ®
        let validation_issues = self.validate_definitions(&definitions).await?;
        if validation_issues.iter().any(|issue| matches!(issue.severity, ValidationSeverity::Error)) {
            return Err(RepositoryError::ValidationError(
                format!("å¯¼å…¥çš„æ•°æ®å­˜åœ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥Excelæ–‡ä»¶æ ¼å¼")
            ));
        }
        
        // ä¿å­˜ä¸ºé…ç½®é›†
        if !definitions.is_empty() {
            self.save_configuration_set(config_name, &definitions).await?;
        }
        
        log::info!("ä»Excelå¯¼å…¥é…ç½®å®Œæˆ: æ–‡ä»¶={}, é…ç½®é›†={}, å¯¼å…¥æ•°é‡={}", file_path, config_name, definitions.len());
        Ok(definitions)
    }
    
    /// è§£æExcelè¡Œæ•°æ®ä¸ºChannelPointDefinition
    fn parse_excel_row(&self, row: &[calamine::DataType], row_number: usize) -> Result<ChannelPointDefinition, RepositoryError> {
        use calamine::DataType;
        
        // å®šä¹‰Excelåˆ—çš„é¡ºåºæ˜ å°„ï¼ˆåŸºäºå®é™…è¡¨å¤´ï¼‰
        let get_cell_string = |index: usize| -> String {
            if index < row.len() {
                match &row[index] {
                    DataType::String(s) => s.trim().to_string(),
                    DataType::Float(f) => f.to_string(),
                    DataType::Int(i) => i.to_string(),
                    DataType::Bool(b) => b.to_string(),
                    _ => String::new(),
                }
            } else {
                String::new()
            }
        };
        
        let get_cell_float = |index: usize| -> Option<f64> {
            if index < row.len() {
                match &row[index] {
                    DataType::Float(f) => Some(*f),
                    DataType::Int(i) => Some(*i as f64),
                    DataType::String(s) => {
                        let s = s.trim();
                        if s.is_empty() || s == "/" {
                            None
                        } else {
                            s.parse().ok()
                        }
                    },
                    _ => None,
                }
            } else {
                None
            }
        };
        
        let get_cell_bool = |index: usize| -> Option<bool> {
            if index < row.len() {
                match &row[index] {
                    DataType::Bool(b) => Some(*b),
                    DataType::String(s) => {
                        let s = s.trim();
                        match s {
                            "æ˜¯" | "true" | "True" | "TRUE" | "1" => Some(true),
                            "å¦" | "false" | "False" | "FALSE" | "0" => Some(false),
                            _ => None,
                        }
                    },
                    DataType::Int(i) => Some(*i != 0),
                    _ => None,
                }
            } else {
                None
            }
        };
        
        let get_optional_string = |index: usize| -> Option<String> {
            let s = get_cell_string(index);
            if s.is_empty() || s == "/" {
                None
            } else {
                Some(s)
            }
        };
        
        // è§£ææ¨¡å—ç±»å‹
        let module_type_str = get_cell_string(2); // ç¬¬2åˆ—ï¼šæ¨¡å—ç±»å‹
        let module_type = module_type_str.parse::<ModuleType>()
            .map_err(|_| RepositoryError::ValidationError(
                format!("ç¬¬{}è¡Œ: æ— æ•ˆçš„æ¨¡å—ç±»å‹ '{}'", row_number, module_type_str)
            ))?;
        
        // è§£ææ•°æ®ç±»å‹
        let data_type_str = get_cell_string(10); // ç¬¬10åˆ—ï¼šæ•°æ®ç±»å‹
        let data_type = data_type_str.parse::<PointDataType>()
            .map_err(|_| RepositoryError::ValidationError(
                format!("ç¬¬{}è¡Œ: æ— æ•ˆçš„æ•°æ®ç±»å‹ '{}'", row_number, data_type_str)
            ))?;
        
        // æ„å»ºå®šä¹‰å¯¹è±¡ï¼ˆæ ¹æ®å®é™…Excelåˆ—ç´¢å¼•ï¼‰
        let definition = ChannelPointDefinition {
            id: Uuid::new_v4().to_string(),
            tag: get_cell_string(6),                    // ç¬¬6åˆ—ï¼šä½å·
            variable_name: get_cell_string(8),          // ç¬¬8åˆ—ï¼šå˜é‡åç§°ï¼ˆHMIï¼‰
            variable_description: get_cell_string(9),   // ç¬¬9åˆ—ï¼šå˜é‡æè¿°
            station_name: get_cell_string(7),           // ç¬¬7åˆ—ï¼šåœºç«™å
            module_name: get_cell_string(1),            // ç¬¬1åˆ—ï¼šæ¨¡å—åç§°
            module_type,                                 // ç¬¬2åˆ—ï¼šæ¨¡å—ç±»å‹
            channel_tag_in_module: get_cell_string(5),  // ç¬¬5åˆ—ï¼šé€šé“ä½å·
            data_type,                                   // ç¬¬10åˆ—ï¼šæ•°æ®ç±»å‹
            power_supply_type: get_cell_string(3),      // ç¬¬3åˆ—ï¼šä¾›ç”µç±»å‹ï¼ˆæœ‰æº/æ— æºï¼‰
            wire_system: get_cell_string(4),            // ç¬¬4åˆ—ï¼šçº¿åˆ¶
            plc_absolute_address: get_optional_string(51), // ç¬¬51åˆ—ï¼šPLCç»å¯¹åœ°å€
            plc_communication_address: get_cell_string(52), // ç¬¬52åˆ—ï¼šä¸Šä½æœºé€šè®¯åœ°å€
            range_lower_limit: get_cell_float(14),      // ç¬¬14åˆ—ï¼šé‡ç¨‹ä½é™
            range_upper_limit: get_cell_float(15),      // ç¬¬15åˆ—ï¼šé‡ç¨‹é«˜é™
            engineering_unit: None, // Excelä¸­æ²¡æœ‰å¯¹åº”åˆ—
            sll_set_value: get_cell_float(16),          // ç¬¬16åˆ—ï¼šSLLè®¾å®šå€¼
            sll_set_point_address: get_optional_string(17), // ç¬¬17åˆ—ï¼šSLLè®¾å®šç‚¹ä½
            sll_feedback_address: get_optional_string(18), // ç¬¬18åˆ—ï¼šSLLè®¾å®šç‚¹ä½_PLCåœ°å€
            sl_set_value: get_cell_float(20),           // ç¬¬20åˆ—ï¼šSLè®¾å®šå€¼
            sl_set_point_address: get_optional_string(21), // ç¬¬21åˆ—ï¼šSLè®¾å®šç‚¹ä½
            sl_feedback_address: get_optional_string(22),  // ç¬¬22åˆ—ï¼šSLè®¾å®šç‚¹ä½_PLCåœ°å€
            sh_set_value: get_cell_float(24),           // ç¬¬24åˆ—ï¼šSHè®¾å®šå€¼
            sh_set_point_address: get_optional_string(25), // ç¬¬25åˆ—ï¼šSHè®¾å®šç‚¹ä½
            sh_feedback_address: get_optional_string(26),  // ç¬¬26åˆ—ï¼šSHè®¾å®šç‚¹ä½_PLCåœ°å€
            shh_set_value: get_cell_float(28),          // ç¬¬28åˆ—ï¼šSHHè®¾å®šå€¼
            shh_set_point_address: get_optional_string(29), // ç¬¬29åˆ—ï¼šSHHè®¾å®šç‚¹ä½
            shh_feedback_address: get_optional_string(30),  // ç¬¬30åˆ—ï¼šSHHè®¾å®šç‚¹ä½_PLCåœ°å€
            maintenance_value_set_point_address: get_optional_string(46), // ç¬¬46åˆ—ï¼šç»´æŠ¤å€¼è®¾å®šç‚¹ä½_PLCåœ°å€
            maintenance_enable_switch_point_address: get_optional_string(49), // ç¬¬49åˆ—ï¼šç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½_PLCåœ°å€
            access_property: get_optional_string(11),   // ç¬¬11åˆ—ï¼šè¯»å†™å±æ€§
            save_history: get_cell_bool(12),            // ç¬¬12åˆ—ï¼šä¿å­˜å†å²
            power_failure_protection: get_cell_bool(13), // ç¬¬13åˆ—ï¼šæ‰ç”µä¿æŠ¤
            test_rig_plc_address: None, // Excelä¸­æ²¡æœ‰å¯¹åº”åˆ—ï¼Œå¯ä»¥åç»­æ·»åŠ 
        };
        
        Ok(definition)
    }
    
    async fn export_to_excel(&self, definitions: &[ChannelPointDefinition], file_path: &str) -> Result<(), RepositoryError> {
        use rust_xlsxwriter::{Workbook, Worksheet, Format};
        
        // åˆ›å»ºå·¥ä½œç°¿
        let mut workbook = Workbook::new();
        let mut worksheet = workbook.add_worksheet();
        
        // è®¾ç½®è¡¨å¤´æ ¼å¼
        let header_format = Format::new()
            .set_bold()
            .set_background_color("#E0E0E0")
            .set_border(rust_xlsxwriter::FormatBorder::Thin);
        
        // å®šä¹‰è¡¨å¤´ï¼ˆåŸºäºå®é™…Excelæ ¼å¼ï¼‰
        let headers = vec![
            "åºå·", "æ¨¡å—åç§°", "æ¨¡å—ç±»å‹", "ä¾›ç”µç±»å‹ï¼ˆæœ‰æº/æ— æºï¼‰", "çº¿åˆ¶", 
            "é€šé“ä½å·", "ä½å·", "åœºç«™å", "å˜é‡åç§°ï¼ˆHMIï¼‰", "å˜é‡æè¿°", 
            "æ•°æ®ç±»å‹", "è¯»å†™å±æ€§", "ä¿å­˜å†å²", "æ‰ç”µä¿æŠ¤", "é‡ç¨‹ä½é™", "é‡ç¨‹é«˜é™",
            "SLLè®¾å®šå€¼", "SLLè®¾å®šç‚¹ä½", "SLLè®¾å®šç‚¹ä½_PLCåœ°å€", "SLLè®¾å®šç‚¹ä½_é€šè®¯åœ°å€",
            "SLè®¾å®šå€¼", "SLè®¾å®šç‚¹ä½", "SLè®¾å®šç‚¹ä½_PLCåœ°å€", "SLè®¾å®šç‚¹ä½_é€šè®¯åœ°å€",
            "SHè®¾å®šå€¼", "SHè®¾å®šç‚¹ä½", "SHè®¾å®šç‚¹ä½_PLCåœ°å€", "SHè®¾å®šç‚¹ä½_é€šè®¯åœ°å€",
            "SHHè®¾å®šå€¼", "SHHè®¾å®šç‚¹ä½", "SHHè®¾å®šç‚¹ä½_PLCåœ°å€", "SHHè®¾å®šç‚¹ä½_é€šè®¯åœ°å€",
            "LLæŠ¥è­¦", "LLæŠ¥è­¦_PLCåœ°å€", "LLæŠ¥è­¦_é€šè®¯åœ°å€", "LæŠ¥è­¦", "LæŠ¥è­¦_PLCåœ°å€", "LæŠ¥è­¦_é€šè®¯åœ°å€",
            "HæŠ¥è­¦", "HæŠ¥è­¦_PLCåœ°å€", "HæŠ¥è­¦_é€šè®¯åœ°å€", "HHæŠ¥è­¦", "HHæŠ¥è­¦_PLCåœ°å€", "HHæŠ¥è­¦_é€šè®¯åœ°å€",
            "ç»´æŠ¤å€¼è®¾å®š", "ç»´æŠ¤å€¼è®¾å®šç‚¹ä½", "ç»´æŠ¤å€¼è®¾å®šç‚¹ä½_PLCåœ°å€", "ç»´æŠ¤å€¼è®¾å®šç‚¹ä½_é€šè®¯åœ°å€",
            "ç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½", "ç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½_PLCåœ°å€", "ç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½_é€šè®¯åœ°å€",
            "PLCç»å¯¹åœ°å€", "ä¸Šä½æœºé€šè®¯åœ°å€"
        ];
        
        // å†™å…¥è¡¨å¤´
        for (col_index, header) in headers.iter().enumerate() {
            worksheet.write_string_with_format(0, col_index as u16, header, &header_format)
                .map_err(|e| RepositoryError::SerializationError(format!("å†™å…¥è¡¨å¤´å¤±è´¥: {}", e)))?;
        }
        
        // å†™å…¥æ•°æ®è¡Œ
        for (row_index, definition) in definitions.iter().enumerate() {
            let row = (row_index + 1) as u32; // +1 è·³è¿‡è¡¨å¤´
            
            // å†™å…¥æ¯åˆ—æ•°æ®ï¼ˆæŒ‰ç…§å®é™…Excelæ ¼å¼ï¼‰
            let row_data = vec![
                (row_index + 1).to_string(),                                    // 0: åºå·
                definition.module_name.clone(),                                 // 1: æ¨¡å—åç§°
                format!("{:?}", definition.module_type),                        // 2: æ¨¡å—ç±»å‹
                definition.power_supply_type.clone(),                           // 3: ä¾›ç”µç±»å‹ï¼ˆæœ‰æº/æ— æºï¼‰
                definition.wire_system.clone(),                                 // 4: çº¿åˆ¶
                definition.channel_tag_in_module.clone(),                       // 5: é€šé“ä½å·
                definition.tag.clone(),                                         // 6: ä½å·
                definition.station_name.clone(),                                // 7: åœºç«™å
                definition.variable_name.clone(),                               // 8: å˜é‡åç§°ï¼ˆHMIï¼‰
                definition.variable_description.clone(),                        // 9: å˜é‡æè¿°
                format!("{:?}", definition.data_type),                          // 10: æ•°æ®ç±»å‹
                definition.access_property.clone().unwrap_or_default(),         // 11: è¯»å†™å±æ€§
                definition.save_history.map_or(String::new(), |v| if v { "æ˜¯".to_string() } else { "å¦".to_string() }), // 12: ä¿å­˜å†å²
                definition.power_failure_protection.map_or(String::new(), |v| if v { "æ˜¯".to_string() } else { "å¦".to_string() }), // 13: æ‰ç”µä¿æŠ¤
                definition.range_lower_limit.map_or(String::new(), |v| v.to_string()), // 14: é‡ç¨‹ä½é™
                definition.range_upper_limit.map_or(String::new(), |v| v.to_string()), // 15: é‡ç¨‹é«˜é™
                definition.sll_set_value.map_or(String::new(), |v| v.to_string()),     // 16: SLLè®¾å®šå€¼
                definition.sll_set_point_address.clone().unwrap_or_default(),   // 17: SLLè®¾å®šç‚¹ä½
                definition.sll_feedback_address.clone().unwrap_or_default(),    // 18: SLLè®¾å®šç‚¹ä½_PLCåœ°å€
                "".to_string(), // 19: SLLè®¾å®šç‚¹ä½_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                definition.sl_set_value.map_or(String::new(), |v| v.to_string()),      // 20: SLè®¾å®šå€¼
                definition.sl_set_point_address.clone().unwrap_or_default(),    // 21: SLè®¾å®šç‚¹ä½
                definition.sl_feedback_address.clone().unwrap_or_default(),     // 22: SLè®¾å®šç‚¹ä½_PLCåœ°å€
                "".to_string(), // 23: SLè®¾å®šç‚¹ä½_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                definition.sh_set_value.map_or(String::new(), |v| v.to_string()),      // 24: SHè®¾å®šå€¼
                definition.sh_set_point_address.clone().unwrap_or_default(),    // 25: SHè®¾å®šç‚¹ä½
                definition.sh_feedback_address.clone().unwrap_or_default(),     // 26: SHè®¾å®šç‚¹ä½_PLCåœ°å€
                "".to_string(), // 27: SHè®¾å®šç‚¹ä½_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                definition.shh_set_value.map_or(String::new(), |v| v.to_string()),     // 28: SHHè®¾å®šå€¼
                definition.shh_set_point_address.clone().unwrap_or_default(),   // 29: SHHè®¾å®šç‚¹ä½
                definition.shh_feedback_address.clone().unwrap_or_default(),    // 30: SHHè®¾å®šç‚¹ä½_PLCåœ°å€
                "".to_string(), // 31: SHHè®¾å®šç‚¹ä½_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 32: LLæŠ¥è­¦ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 33: LLæŠ¥è­¦_PLCåœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 34: LLæŠ¥è­¦_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 35: LæŠ¥è­¦ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 36: LæŠ¥è­¦_PLCåœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 37: LæŠ¥è­¦_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 38: HæŠ¥è­¦ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 39: HæŠ¥è­¦_PLCåœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 40: HæŠ¥è­¦_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 41: HHæŠ¥è­¦ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 42: HHæŠ¥è­¦_PLCåœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 43: HHæŠ¥è­¦_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 44: ç»´æŠ¤å€¼è®¾å®šï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 45: ç»´æŠ¤å€¼è®¾å®šç‚¹ä½ï¼ˆé¢„ç•™ï¼‰
                definition.maintenance_value_set_point_address.clone().unwrap_or_default(), // 46: ç»´æŠ¤å€¼è®¾å®šç‚¹ä½_PLCåœ°å€
                "".to_string(), // 47: ç»´æŠ¤å€¼è®¾å®šç‚¹ä½_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                "".to_string(), // 48: ç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½ï¼ˆé¢„ç•™ï¼‰
                definition.maintenance_enable_switch_point_address.clone().unwrap_or_default(), // 49: ç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½_PLCåœ°å€
                "".to_string(), // 50: ç»´æŠ¤ä½¿èƒ½å¼€å…³ç‚¹ä½_é€šè®¯åœ°å€ï¼ˆé¢„ç•™ï¼‰
                definition.plc_absolute_address.clone().unwrap_or_default(),    // 51: PLCç»å¯¹åœ°å€
                definition.plc_communication_address.clone(),                   // 52: ä¸Šä½æœºé€šè®¯åœ°å€
            ];
            
            for (col_index, cell_value) in row_data.iter().enumerate() {
                worksheet.write_string(row, col_index as u16, cell_value)
                    .map_err(|e| RepositoryError::SerializationError(format!("å†™å…¥æ•°æ®å¤±è´¥: {}", e)))?;
            }
        }
        
        // è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for col_index in 0..headers.len() {
            worksheet.autofit();
        }
        
        // ä¿å­˜æ–‡ä»¶
        workbook.save(file_path)
            .map_err(|e| RepositoryError::SerializationError(format!("ä¿å­˜Excelæ–‡ä»¶å¤±è´¥: {}", e)))?;
        
        log::info!("Excelå¯¼å‡ºå®Œæˆ: æ–‡ä»¶={}, å¯¼å‡ºæ•°é‡={}", file_path, definitions.len());
        Ok(())
     }
    
    async fn save_configuration_set(&self, name: &str, definitions: &[ChannelPointDefinition]) -> Result<(), RepositoryError> {
        // å…ˆä¿å­˜æ‰€æœ‰å®šä¹‰
        self.save_channel_definitions_batch(definitions).await?;
        
        // ç„¶åä¿å­˜é…ç½®é›†
        let definition_ids: Vec<String> = definitions.iter().map(|d| d.id.clone()).collect();
        let mut sets = self.configuration_sets.write().await;
        sets.insert(name.to_string(), definition_ids);
        Ok(())
    }
    
    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, RepositoryError> {
        let sets = self.configuration_sets.read().await;
        let definition_ids = sets.get(name)
            .ok_or_else(|| RepositoryError::NotFound(format!("é…ç½®é›†ä¸å­˜åœ¨: {}", name)))?;
        
        let definitions = self.definitions.read().await;
        let mut results = Vec::new();
        
        for id in definition_ids {
            if let Some(definition) = definitions.get(id) {
                results.push(definition.clone());
            }
        }
        
        Ok(results)
    }
    
    async fn list_configuration_sets(&self) -> Result<Vec<String>, RepositoryError> {
        let sets = self.configuration_sets.read().await;
        Ok(sets.keys().cloned().collect())
    }
    
    async fn delete_configuration_set(&self, name: &str) -> Result<bool, RepositoryError> {
        let mut sets = self.configuration_sets.write().await;
        Ok(sets.remove(name).is_some())
    }
    
    async fn get_test_parameters(&self, module_type: ModuleType) -> Result<Option<TestParameterSet>, RepositoryError> {
        let params = self.test_parameters.read().await;
        Ok(params.get(&module_type).cloned())
    }
    
    async fn save_test_parameters(&self, module_type: ModuleType, params: &TestParameterSet) -> Result<(), RepositoryError> {
        let mut param_map = self.test_parameters.write().await;
        param_map.insert(module_type, params.clone());
        Ok(())
    }
    
    async fn list_test_parameters(&self) -> Result<Vec<(ModuleType, TestParameterSet)>, RepositoryError> {
        let params = self.test_parameters.read().await;
        Ok(params.iter().map(|(k, v)| (*k, v.clone())).collect())
    }
    
    async fn save_definition_template(&self, template_name: &str, template: &ChannelPointDefinition) -> Result<(), RepositoryError> {
        let mut templates = self.templates.write().await;
        templates.insert(template_name.to_string(), template.clone());
        Ok(())
    }
    
    async fn get_definition_template(&self, template_name: &str) -> Result<Option<ChannelPointDefinition>, RepositoryError> {
        let templates = self.templates.read().await;
        Ok(templates.get(template_name).cloned())
    }
    
    async fn list_definition_templates(&self) -> Result<Vec<String>, RepositoryError> {
        let templates = self.templates.read().await;
        Ok(templates.keys().cloned().collect())
    }
    
    async fn validate_definitions(&self, definitions: &[ChannelPointDefinition]) -> Result<Vec<ValidationIssue>, RepositoryError> {
        let mut issues = Vec::new();
        
        for definition in definitions {
            // æ£€æŸ¥å¿…å¡«å­—æ®µ
            if definition.tag.is_empty() {
                issues.push(ValidationIssue {
                    severity: ValidationSeverity::Error,
                    message: format!("ç‚¹ä½ {} çš„æ ‡ç­¾ä¸èƒ½ä¸ºç©º", definition.id),
                    field: Some("tag".to_string()),
                    suggestion: Some("è¯·å¡«å†™æœ‰æ•ˆçš„ç‚¹ä½æ ‡ç­¾".to_string()),
                });
            }
            
            if definition.plc_communication_address.is_empty() {
                issues.push(ValidationIssue {
                    severity: ValidationSeverity::Error,
                    message: format!("ç‚¹ä½ {} çš„PLCé€šä¿¡åœ°å€ä¸èƒ½ä¸ºç©º", definition.id),
                    field: Some("plc_communication_address".to_string()),
                    suggestion: Some("è¯·å¡«å†™æœ‰æ•ˆçš„PLCåœ°å€".to_string()),
                });
            }
            
            // æ£€æŸ¥é‡ç¨‹é…ç½®
            if let (Some(low), Some(high)) = (definition.range_lower_limit, definition.range_upper_limit) {
                if low >= high {
                    issues.push(ValidationIssue {
                        severity: ValidationSeverity::Error,
                        message: format!("ç‚¹ä½ {} çš„é‡ç¨‹é…ç½®é”™è¯¯: ä¸‹é™ {} åº”å°äºä¸Šé™ {}", definition.id, low, high),
                        field: Some("range".to_string()),
                        suggestion: Some("è¯·ç¡®ä¿ä¸‹é™å°äºä¸Šé™".to_string()),
                    });
                }
            }
        }
        
        Ok(issues)
    }
    
    async fn check_consistency(&self) -> Result<ConsistencyReport, RepositoryError> {
        let definitions = self.definitions.read().await;
        let sets = self.configuration_sets.read().await;
        
        let mut report = ConsistencyReport {
            total_definitions: definitions.len(),
            duplicates: Vec::new(),
            orphaned_references: Vec::new(),
            missing_parameters: Vec::new(),
            issues: Vec::new(),
        };
        
        // æ£€æŸ¥é‡å¤çš„æ ‡ç­¾
        let mut tag_counts = HashMap::new();
        for definition in definitions.values() {
            *tag_counts.entry(&definition.tag).or_insert(0) += 1;
        }
        
        for (tag, count) in tag_counts {
            if count > 1 {
                report.duplicates.push(tag.clone());
            }
        }
        
        // æ£€æŸ¥é…ç½®é›†ä¸­çš„å­¤ç«‹å¼•ç”¨
        for (set_name, def_ids) in sets.iter() {
            for def_id in def_ids {
                if !definitions.contains_key(def_id) {
                    report.orphaned_references.push(format!("{}:{}", set_name, def_id));
                }
            }
        }
        
        Ok(report)
    }
    
    // è¾…åŠ©æ–¹æ³•
    fn apply_filter(&self, mut definitions: Vec<ChannelPointDefinition>, filter: &Filter) -> Result<Vec<ChannelPointDefinition>, RepositoryError> {
        match filter.field.as_str() {
            "module_type" => {
                if let FilterValue::String(ref value) = filter.value {
                    let module_type = value.parse::<ModuleType>()
                        .map_err(|_| RepositoryError::ValidationError(format!("æ— æ•ˆçš„æ¨¡å—ç±»å‹: {}", value)))?;
                    definitions.retain(|d| d.module_type == module_type);
                }
            }
            "tag" => {
                if let FilterValue::String(ref value) = filter.value {
                    match filter.operator {
                        FilterOperator::Equal => definitions.retain(|d| d.tag == *value),
                        FilterOperator::Contains => definitions.retain(|d| d.tag.contains(value)),
                        _ => return Err(RepositoryError::ValidationError("ä¸æ”¯æŒçš„æ“ä½œç¬¦".to_string())),
                    }
                }
            }
            _ => return Err(RepositoryError::ValidationError(format!("ä¸æ”¯æŒçš„è¿‡æ»¤å­—æ®µ: {}", filter.field))),
        }
        Ok(definitions)
    }
    
    fn sort_definitions(&self, definitions: &mut Vec<ChannelPointDefinition>, sort_field: &str) {
        match sort_field {
            "tag" => definitions.sort_by(|a, b| a.tag.cmp(&b.tag)),
            "module_type" => definitions.sort_by(|a, b| format!("{:?}", a.module_type).cmp(&format!("{:?}", b.module_type))),
            _ => {} // å¿½ç•¥ä¸æ”¯æŒçš„æ’åºå­—æ®µ
        }
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

##### 1.2.3 é…ç½®Repositoryæµ‹è¯•
```rust
// src/repositories/tests/configuration_repository_tests.rs
use super::super::configuration_repository::*;
use tokio;

/// é…ç½®Repositoryæµ‹è¯•å¥—ä»¶
struct ConfigurationRepositoryTestSuite;

impl ConfigurationRepositoryTestSuite {
    fn create_test_definition() -> ChannelPointDefinition {
        ChannelPointDefinition {
            id: uuid::Uuid::new_v4().to_string(),
            tag: "TEST_AI_001".to_string(),
            variable_name: "Test AI Point".to_string(),
            variable_description: "Test AI Point Description".to_string(),
            station_name: "Test Station".to_string(),
            module_name: "AI Module".to_string(),
            module_type: ModuleType::AI,
            channel_tag_in_module: "CH01".to_string(),
            data_type: PointDataType::Float,
            power_supply_type: "æœ‰æº".to_string(),
            wire_system: "4çº¿åˆ¶".to_string(),
            plc_absolute_address: Some("DB1.DBD0".to_string()),
            plc_communication_address: "DB1.DBD0".to_string(),
            range_lower_limit: Some(0.0),
            range_upper_limit: Some(100.0),
            engineering_unit: Some("mA".to_string()),
            sll_set_value: Some(10.0),
            sll_set_point_address: Some("DB1.DBD4".to_string()),
            sll_feedback_address: Some("DB1.DBX8.0".to_string()),
            sl_set_value: Some(20.0),
            sl_set_point_address: Some("DB1.DBD8".to_string()),
            sl_feedback_address: Some("DB1.DBX8.1".to_string()),
            sh_set_value: Some(80.0),
            sh_set_point_address: Some("DB1.DBD12".to_string()),
            sh_feedback_address: Some("DB1.DBX8.2".to_string()),
            shh_set_value: Some(90.0),
            shh_set_point_address: Some("DB1.DBD16".to_string()),
            shh_feedback_address: Some("DB1.DBX8.3".to_string()),
            maintenance_value_set_point_address: Some("DB1.DBD20".to_string()),
            maintenance_enable_switch_point_address: Some("DB1.DBX8.4".to_string()),
            access_property: Some("RW".to_string()),
            save_history: Some(true),
            power_failure_protection: Some(true),
            test_rig_plc_address: Some("DB2.DBD0".to_string()),
        }
    }
}

#[tokio::test]
async fn test_configuration_repository_basic_operations() {
    let repo = MemoryConfigurationRepository::new();
    let definition = ConfigurationRepositoryTestSuite::create_test_definition();
    let id = definition.id.clone();
    
    // æµ‹è¯•ä¿å­˜
    repo.save_channel_definition(&definition).await.expect("ä¿å­˜å¤±è´¥");
    
    // æµ‹è¯•è·å–
    let retrieved = repo.get_channel_definition(&id).await.expect("è·å–å¤±è´¥");
    assert!(retrieved.is_some(), "åº”è¯¥èƒ½è·å–åˆ°å®šä¹‰");
    assert_eq!(retrieved.unwrap().tag, definition.tag, "æ ‡ç­¾åº”è¯¥ä¸€è‡´");
    
    // æµ‹è¯•åˆ—è¡¨
    let all_definitions = repo.list_channel_definitions().await.expect("åˆ—è¡¨æŸ¥è¯¢å¤±è´¥");
    assert!(all_definitions.len() >= 1, "åº”è¯¥åŒ…å«è‡³å°‘ä¸€ä¸ªå®šä¹‰");
    
    // æµ‹è¯•åˆ é™¤
    let deleted = repo.delete_channel_definition(&id).await.expect("åˆ é™¤å¤±è´¥");
    assert!(deleted, "åº”è¯¥åˆ é™¤æˆåŠŸ");
    
    // éªŒè¯åˆ é™¤
    let after_delete = repo.get_channel_definition(&id).await.expect("åˆ é™¤åæŸ¥è¯¢å¤±è´¥");
    assert!(after_delete.is_none(), "åˆ é™¤ååº”è¯¥ä¸å­˜åœ¨");
}

#[tokio::test]
async fn test_configuration_set_operations() {
    let repo = MemoryConfigurationRepository::new();
    let definition1 = ConfigurationRepositoryTestSuite::create_test_definition();
    let mut definition2 = ConfigurationRepositoryTestSuite::create_test_definition();
    definition2.tag = "TEST_AI_002".to_string();
    
    let definitions = vec![definition1.clone(), definition2.clone()];
    let set_name = "test_config_set";
    
    // æµ‹è¯•ä¿å­˜é…ç½®é›†
    repo.save_configuration_set(set_name, &definitions).await.expect("ä¿å­˜é…ç½®é›†å¤±è´¥");
    
    // æµ‹è¯•åŠ è½½é…ç½®é›†
    let loaded_definitions = repo.load_configuration_set(set_name).await.expect("åŠ è½½é…ç½®é›†å¤±è´¥");
    assert_eq!(loaded_definitions.len(), 2, "åº”è¯¥åŠ è½½2ä¸ªå®šä¹‰");
    
    // æµ‹è¯•åˆ—è¡¨é…ç½®é›†
    let sets = repo.list_configuration_sets().await.expect("åˆ—è¡¨é…ç½®é›†å¤±è´¥");
    assert!(sets.contains(&set_name.to_string()), "åº”è¯¥åŒ…å«æµ‹è¯•é…ç½®é›†");
    
    // æµ‹è¯•åˆ é™¤é…ç½®é›†
    let deleted = repo.delete_configuration_set(set_name).await.expect("åˆ é™¤é…ç½®é›†å¤±è´¥");
    assert!(deleted, "åº”è¯¥åˆ é™¤æˆåŠŸ");
}

#[tokio::test]
async fn test_query_operations() {
    let repo = MemoryConfigurationRepository::new();
    
    // åˆ›å»ºä¸åŒç±»å‹çš„å®šä¹‰
    let mut ai_definition = ConfigurationRepositoryTestSuite::create_test_definition();
    ai_definition.module_type = ModuleType::AI;
    ai_definition.tag = "AI_001".to_string();
    
    let mut di_definition = ConfigurationRepositoryTestSuite::create_test_definition();
    di_definition.module_type = ModuleType::DI;
    di_definition.tag = "DI_001".to_string();
    
    repo.save_channel_definition(&ai_definition).await.expect("ä¿å­˜AIå®šä¹‰å¤±è´¥");
    repo.save_channel_definition(&di_definition).await.expect("ä¿å­˜DIå®šä¹‰å¤±è´¥");
    
    // æµ‹è¯•æŒ‰æ¨¡å—ç±»å‹è¿‡æ»¤
    let criteria = QueryCriteria {
        filters: vec![Filter {
            field: "module_type".to_string(),
            operator: FilterOperator::Equal,
            value: FilterValue::String("AI".to_string()),
        }],
        sort_by: None,
        limit: None,
        offset: None,
    };
    
    let ai_results = repo.query_channel_definitions(&criteria).await.expect("æŸ¥è¯¢å¤±è´¥");
    assert_eq!(ai_results.len(), 1, "åº”è¯¥åªè¿”å›AIç±»å‹çš„å®šä¹‰");
    assert_eq!(ai_results[0].module_type, ModuleType::AI, "åº”è¯¥æ˜¯AIç±»å‹");
    
    // æµ‹è¯•æŒ‰æ ‡ç­¾è¿‡æ»¤
    let tag_criteria = QueryCriteria {
        filters: vec![Filter {
            field: "tag".to_string(),
            operator: FilterOperator::Contains,
            value: FilterValue::String("AI".to_string()),
        }],
        sort_by: Some("tag".to_string()),
        limit: None,
        offset: None,
    };
    
    let tag_results = repo.query_channel_definitions(&tag_criteria).await.expect("æ ‡ç­¾æŸ¥è¯¢å¤±è´¥");
    assert!(tag_results.len() >= 1, "åº”è¯¥åŒ…å«æ ‡ç­¾ä¸­å«æœ‰AIçš„å®šä¹‰");
}

#[tokio::test]
async fn test_validation_operations() {
    let repo = MemoryConfigurationRepository::new();
    
    // åˆ›å»ºæ— æ•ˆå®šä¹‰
    let mut invalid_definition = ConfigurationRepositoryTestSuite::create_test_definition();
    invalid_definition.tag = "".to_string(); // ç©ºæ ‡ç­¾
    invalid_definition.plc_communication_address = "".to_string(); // ç©ºåœ°å€
    invalid_definition.range_lower_limit = Some(100.0);
    invalid_definition.range_upper_limit = Some(50.0); // ä¸‹é™å¤§äºä¸Šé™
    
    let definitions = vec![invalid_definition];
    
    // æµ‹è¯•éªŒè¯
    let issues = repo.validate_definitions(&definitions).await.expect("éªŒè¯å¤±è´¥");
    assert!(issues.len() >= 3, "åº”è¯¥å‘ç°è‡³å°‘3ä¸ªé—®é¢˜");
    
    // æ£€æŸ¥é”™è¯¯ç±»å‹
    let error_count = issues.iter().filter(|i| matches!(i.severity, ValidationSeverity::Error)).count();
    assert!(error_count >= 3, "åº”è¯¥æœ‰è‡³å°‘3ä¸ªé”™è¯¯");
}

#[tokio::test]
async fn test_consistency_check() {
    let repo = MemoryConfigurationRepository::new();
    
    // åˆ›å»ºé‡å¤æ ‡ç­¾çš„å®šä¹‰
    let mut def1 = ConfigurationRepositoryTestSuite::create_test_definition();
    def1.tag = "DUPLICATE_TAG".to_string();
    
    let mut def2 = ConfigurationRepositoryTestSuite::create_test_definition();
    def2.tag = "DUPLICATE_TAG".to_string();
    
    repo.save_channel_definition(&def1).await.expect("ä¿å­˜å®šä¹‰1å¤±è´¥");
    repo.save_channel_definition(&def2).await.expect("ä¿å­˜å®šä¹‰2å¤±è´¥");
    
    // æµ‹è¯•ä¸€è‡´æ€§æ£€æŸ¥
    let report = repo.check_consistency().await.expect("ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥");
    assert_eq!(report.total_definitions, 2, "åº”è¯¥æœ‰2ä¸ªå®šä¹‰");
    assert!(report.duplicates.contains(&"DUPLICATE_TAG".to_string()), "åº”è¯¥å‘ç°é‡å¤æ ‡ç­¾");
}

#[tokio::test] 
async fn test_test_parameters_operations() {
    let repo = MemoryConfigurationRepository::new_with_test_data().await;
    
    // æµ‹è¯•è·å–æµ‹è¯•å‚æ•°
    let ai_params = repo.get_test_parameters(ModuleType::AI).await.expect("è·å–AIå‚æ•°å¤±è´¥");
    assert!(ai_params.is_some(), "åº”è¯¥æœ‰AIå‚æ•°");
    
    let params = ai_params.unwrap();
    assert_eq!(params.test_points.len(), 5, "åº”è¯¥æœ‰5ä¸ªæµ‹è¯•ç‚¹");
    
    // æµ‹è¯•ä¿å­˜æ–°å‚æ•°
    let new_params = TestParameterSet {
        default_range: Some((0.0, 10.0)),
        test_points: vec![0.0, 50.0, 100.0],
        tolerance: 0.5,
        test_sequence: vec![SubTestItem::HardPoint],
    };
    
    repo.save_test_parameters(ModuleType::DI, &new_params).await.expect("ä¿å­˜DIå‚æ•°å¤±è´¥");
    
    // éªŒè¯ä¿å­˜
    let saved_params = repo.get_test_parameters(ModuleType::DI).await.expect("è·å–DIå‚æ•°å¤±è´¥");
    assert!(saved_params.is_some(), "åº”è¯¥æœ‰DIå‚æ•°");
    assert_eq!(saved_params.unwrap().test_points.len(), 3, "åº”è¯¥æœ‰3ä¸ªæµ‹è¯•ç‚¹");
    
    // æµ‹è¯•åˆ—è¡¨æ‰€æœ‰å‚æ•°
    let all_params = repo.list_test_parameters().await.expect("åˆ—è¡¨å‚æ•°å¤±è´¥");
    assert!(all_params.len() >= 2, "åº”è¯¥æœ‰è‡³å°‘2ç§ç±»å‹çš„å‚æ•°");
}

/// å‹åŠ›æµ‹è¯•
#[tokio::test]
async fn test_large_dataset_performance() {
    let repo = MemoryConfigurationRepository::new();
    
    // åˆ›å»ºå¤§é‡å®šä¹‰
    let mut definitions = Vec::new();
    for i in 0..1000 {
        let mut def = ConfigurationRepositoryTestSuite::create_test_definition();
        def.tag = format!("PERF_TEST_{:04}", i);
        definitions.push(def);
    }
    
    let start = std::time::Instant::now();
    
    // æ‰¹é‡ä¿å­˜
    repo.save_channel_definitions_batch(&definitions).await.expect("æ‰¹é‡ä¿å­˜å¤±è´¥");
    
    let save_duration = start.elapsed();
    println!("æ‰¹é‡ä¿å­˜1000ä¸ªå®šä¹‰è€—æ—¶: {:?}", save_duration);
    
    // æŸ¥è¯¢æµ‹è¯•
    let query_start = std::time::Instant::now();
    let all_defs = repo.list_channel_definitions().await.expect("æŸ¥è¯¢å¤±è´¥");
    let query_duration = query_start.elapsed();
    
    println!("æŸ¥è¯¢1000ä¸ªå®šä¹‰è€—æ—¶: {:?}", query_duration);
    assert_eq!(all_defs.len(), 1000, "åº”è¯¥è¿”å›1000ä¸ªå®šä¹‰");
    
    // ç¡®ä¿æ€§èƒ½åœ¨åˆç†èŒƒå›´å†…
    assert!(save_duration.as_millis() < 1000, "æ‰¹é‡ä¿å­˜åº”è¯¥åœ¨1ç§’å†…å®Œæˆ");
    assert!(query_duration.as_millis() < 100, "æŸ¥è¯¢åº”è¯¥åœ¨100æ¯«ç§’å†…å®Œæˆ");
}
```

### âœ… æ­¥éª¤1.2å®Œæˆæ ‡å‡†

1. **æ¥å£å®Œæ•´æ€§**: æ‰€æœ‰IConfigurationRepositoryæ–¹æ³•éƒ½æœ‰å®Œæ•´å®ç°
2. **æµ‹è¯•è¦†ç›–**: å•å…ƒæµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°90%ä»¥ä¸Š
3. **æ€§èƒ½æŒ‡æ ‡**: 1000ä¸ªå®šä¹‰çš„CRUDæ“ä½œåœ¨åˆç†æ—¶é—´å†…å®Œæˆ
4. **éªŒè¯åŠŸèƒ½**: æ•°æ®éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥æ­£å¸¸å·¥ä½œ
5. **é”™è¯¯å¤„ç†**: å„ç§å¼‚å¸¸æƒ…å†µéƒ½æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†

---

## ğŸš€ Phase 1 åç»­æ­¥éª¤é¢„è§ˆ

æ¥ä¸‹æ¥æˆ‘ä»¬å°†å®æ–½ï¼š

### æ­¥éª¤ 1.3: åˆ›å»ºè¿è¡Œæ—¶æ•°æ®Repository
- å®ç°IRuntimeRepositoryæ¥å£
- ç®¡ç†ChannelTestInstanceå’ŒTestBatchçš„è¿è¡Œæ—¶æ•°æ®
- æä¾›é«˜æ€§èƒ½çš„å†…å­˜ç¼“å­˜æœºåˆ¶

### æ­¥éª¤ 1.4: åˆ›å»ºæŒä¹…åŒ–æ•°æ®Repository
- å®ç°IPersistentRepositoryæ¥å£
- ç®¡ç†éœ€è¦æ°¸ä¹…ä¿å­˜çš„æµ‹è¯•è®°å½•å’Œå®¡è®¡æ•°æ®
- é›†æˆSQLiteæ•°æ®åº“

### æ­¥éª¤ 1.5: Repositoryé›†æˆæµ‹è¯•
- å¤šRepositoryååŒå·¥ä½œæµ‹è¯•
- æ•°æ®ä¸€è‡´æ€§éªŒè¯
- æ€§èƒ½å’Œå¹¶å‘æµ‹è¯•

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

### æ­¥éª¤ 1.3: åˆ›å»ºè¿è¡Œæ—¶æ•°æ®Repository

#### ğŸ¯ ç›®æ ‡
å®ç°ä¸“é—¨ç®¡ç†è¿è¡Œæ—¶æ•°æ®çš„Repositoryï¼Œæä¾›é«˜æ€§èƒ½çš„å†…å­˜ç¼“å­˜å’ŒçŠ¶æ€ç®¡ç†ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.3.1 å®šä¹‰è¿è¡Œæ—¶Repositoryæ¥å£
```rust
// src/repositories/runtime_repository.rs
use async_trait::async_trait;
use crate::models::structs::{ChannelTestInstance, TestBatchInfo};
use crate::models::enums::OverallTestStatus;
use crate::models::errors::RepositoryError;
use super::{IRepository, QueryCriteria};
use std::collections::HashMap;

/// è¿è¡Œæ—¶æ•°æ®Repositoryæ¥å£
#[async_trait]
pub trait IRuntimeRepository: Send + Sync {
    // é€šé“å®ä¾‹ç®¡ç†
    async fn get_channel_instance(&self, instance_id: &str) -> Result<Option<ChannelTestInstance>, RepositoryError>;
    async fn save_channel_instance(&self, instance: &ChannelTestInstance) -> Result<(), RepositoryError>;
    async fn delete_channel_instance(&self, instance_id: &str) -> Result<bool, RepositoryError>;
    async fn list_channel_instances(&self) -> Result<Vec<ChannelTestInstance>, RepositoryError>;
    async fn query_channel_instances(&self, criteria: &QueryCriteria) -> Result<Vec<ChannelTestInstance>, RepositoryError>;
    
    // æ‰¹æ¬¡çº§åˆ«æ“ä½œ
    async fn list_batch_instances(&self, batch_id: &str) -> Result<Vec<ChannelTestInstance>, RepositoryError>;
    async fn count_batch_instances(&self, batch_id: &str) -> Result<usize, RepositoryError>;
    async fn get_batch_statistics(&self, batch_id: &str) -> Result<BatchStatistics, RepositoryError>;
    
    // çŠ¶æ€æŸ¥è¯¢
    async fn list_instances_by_status(&self, status: OverallTestStatus) -> Result<Vec<ChannelTestInstance>, RepositoryError>;
    async fn count_instances_by_status(&self, batch_id: &str, status: OverallTestStatus) -> Result<usize, RepositoryError>;
    
    // æ‰¹é‡æ“ä½œ
    async fn save_channel_instances_batch(&self, instances: &[ChannelTestInstance]) -> Result<(), RepositoryError>;
    async fn update_instances_status(&self, instance_ids: &[String], status: OverallTestStatus) -> Result<usize, RepositoryError>;
    
    // æ‰¹æ¬¡ç®¡ç†
    async fn get_test_batch(&self, batch_id: &str) -> Result<Option<TestBatchInfo>, RepositoryError>;
    async fn save_test_batch(&self, batch: &TestBatchInfo) -> Result<(), RepositoryError>;
    async fn delete_test_batch(&self, batch_id: &str) -> Result<bool, RepositoryError>;
    async fn list_test_batches(&self) -> Result<Vec<TestBatchInfo>, RepositoryError>;
    async fn list_active_batches(&self) -> Result<Vec<TestBatchInfo>, RepositoryError>;
    
    // ç¼“å­˜ç®¡ç†
    async fn clear_cache(&self) -> Result<(), RepositoryError>;
    async fn get_cache_stats(&self) -> Result<CacheStatistics, RepositoryError>;
    async fn invalidate_batch_cache(&self, batch_id: &str) -> Result<(), RepositoryError>;
    
    // äº‹åŠ¡æ”¯æŒ
    async fn begin_transaction(&self) -> Result<TransactionHandle, RepositoryError>;
    async fn commit_transaction(&self, handle: TransactionHandle) -> Result<(), RepositoryError>;
    async fn rollback_transaction(&self, handle: TransactionHandle) -> Result<(), RepositoryError>;
}

/// æ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct BatchStatistics {
    pub total_instances: usize,
    pub not_tested: usize,
    pub testing: usize,
    pub passed: usize,
    pub failed: usize,
    pub skipped: usize,
    pub progress_percentage: f64,
}

/// ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct CacheStatistics {
    pub total_entries: usize,
    pub hit_count: u64,
    pub miss_count: u64,
    pub hit_rate: f64,
    pub memory_usage_bytes: usize,
}

/// äº‹åŠ¡å¥æŸ„
#[derive(Debug, Clone)]
pub struct TransactionHandle {
    pub id: String,
    pub start_time: chrono::DateTime<chrono::Utc>,
}
```

##### 1.3.2 å®ç°å†…å­˜è¿è¡Œæ—¶Repository
```rust
// src/repositories/runtime_repository.rs (continued)
use std::sync::Arc;
use tokio::sync::RwLock;
use uuid::Uuid;
use chrono::Utc;

/// å†…å­˜è¿è¡Œæ—¶Repositoryå®ç°
pub struct MemoryRuntimeRepository {
    instances: Arc<RwLock<HashMap<String, ChannelTestInstance>>>,
    batches: Arc<RwLock<HashMap<String, TestBatchInfo>>>,
    batch_instance_mapping: Arc<RwLock<HashMap<String, Vec<String>>>>, // batch_id -> instance_ids
    cache_stats: Arc<RwLock<CacheStatistics>>,
    transactions: Arc<RwLock<HashMap<String, TransactionState>>>,
}

#[derive(Debug, Clone)]
struct TransactionState {
    handle: TransactionHandle,
    snapshot_instances: HashMap<String, ChannelTestInstance>,
    snapshot_batches: HashMap<String, TestBatchInfo>,
}

impl MemoryRuntimeRepository {
    pub fn new() -> Self {
        Self {
            instances: Arc::new(RwLock::new(HashMap::new())),
            batches: Arc::new(RwLock::new(HashMap::new())),
            batch_instance_mapping: Arc::new(RwLock::new(HashMap::new())),
            cache_stats: Arc::new(RwLock::new(CacheStatistics {
                total_entries: 0,
                hit_count: 0,
                miss_count: 0,
                hit_rate: 0.0,
                memory_usage_bytes: 0,
            })),
            transactions: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    async fn update_cache_stats(&self, hit: bool) {
        let mut stats = self.cache_stats.write().await;
        if hit {
            stats.hit_count += 1;
        } else {
            stats.miss_count += 1;
        }
        let total = stats.hit_count + stats.miss_count;
        if total > 0 {
            stats.hit_rate = stats.hit_count as f64 / total as f64;
        }
    }
    
    async fn add_instance_to_batch_mapping(&self, batch_id: &str, instance_id: &str) {
        let mut mapping = self.batch_instance_mapping.write().await;
        mapping.entry(batch_id.to_string())
            .or_insert_with(Vec::new)
            .push(instance_id.to_string());
    }
    
    async fn remove_instance_from_batch_mapping(&self, batch_id: &str, instance_id: &str) {
        let mut mapping = self.batch_instance_mapping.write().await;
        if let Some(instance_ids) = mapping.get_mut(batch_id) {
            instance_ids.retain(|id| id != instance_id);
            if instance_ids.is_empty() {
                mapping.remove(batch_id);
            }
        }
    }
}

#[async_trait]
impl IRuntimeRepository for MemoryRuntimeRepository {
    async fn get_channel_instance(&self, instance_id: &str) -> Result<Option<ChannelTestInstance>, RepositoryError> {
        let instances = self.instances.read().await;
        let found = instances.get(instance_id).is_some();
        self.update_cache_stats(found).await;
        Ok(instances.get(instance_id).cloned())
    }
    
    async fn save_channel_instance(&self, instance: &ChannelTestInstance) -> Result<(), RepositoryError> {
        let instance_id = instance.instance_id.clone();
        let batch_id = instance.test_batch_id.clone();
        
        let mut instances = self.instances.write().await;
        let is_new = !instances.contains_key(&instance_id);
        instances.insert(instance_id.clone(), instance.clone());
        
        // æ›´æ–°æ‰¹æ¬¡æ˜ å°„
        if is_new {
            self.add_instance_to_batch_mapping(&batch_id, &instance_id).await;
        }
        
        // æ›´æ–°ç¼“å­˜ç»Ÿè®¡
        let mut stats = self.cache_stats.write().await;
        stats.total_entries = instances.len();
        
        Ok(())
    }
    
    async fn delete_channel_instance(&self, instance_id: &str) -> Result<bool, RepositoryError> {
        let mut instances = self.instances.write().await;
        if let Some(instance) = instances.get(instance_id) {
            let batch_id = instance.test_batch_id.clone();
            instances.remove(instance_id);
            
            // æ›´æ–°æ‰¹æ¬¡æ˜ å°„
            self.remove_instance_from_batch_mapping(&batch_id, instance_id).await;
            
            // æ›´æ–°ç¼“å­˜ç»Ÿè®¡
            let mut stats = self.cache_stats.write().await;
            stats.total_entries = instances.len();
            
            Ok(true)
        } else {
            Ok(false)
        }
    }
    
    async fn list_channel_instances(&self) -> Result<Vec<ChannelTestInstance>, RepositoryError> {
        let instances = self.instances.read().await;
        Ok(instances.values().cloned().collect())
    }
    
    async fn query_channel_instances(&self, criteria: &QueryCriteria) -> Result<Vec<ChannelTestInstance>, RepositoryError> {
        let instances = self.instances.read().await;
        let mut results: Vec<ChannelTestInstance> = instances.values().cloned().collect();
        
        // åº”ç”¨è¿‡æ»¤å™¨
        for filter in &criteria.filters {
            results = self.apply_instance_filter(results, filter)?;
        }
        
        // åº”ç”¨æ’åº
        if let Some(sort_field) = &criteria.sort_by {
            self.sort_instances(&mut results, sort_field);
        }
        
        // åº”ç”¨åˆ†é¡µ
        if let Some(offset) = criteria.offset {
            results = results.into_iter().skip(offset).collect();
        }
        
        if let Some(limit) = criteria.limit {
            results.truncate(limit);
        }
        
        Ok(results)
    }
    
    async fn list_batch_instances(&self, batch_id: &str) -> Result<Vec<ChannelTestInstance>, RepositoryError> {
        let mapping = self.batch_instance_mapping.read().await;
        let instances = self.instances.read().await;
        
        if let Some(instance_ids) = mapping.get(batch_id) {
            let mut results = Vec::new();
            for instance_id in instance_ids {
                if let Some(instance) = instances.get(instance_id) {
                    results.push(instance.clone());
                }
            }
            Ok(results)
        } else {
            Ok(Vec::new())
        }
    }
    
    async fn count_batch_instances(&self, batch_id: &str) -> Result<usize, RepositoryError> {
        let mapping = self.batch_instance_mapping.read().await;
        Ok(mapping.get(batch_id).map_or(0, |ids| ids.len()))
    }
    
    async fn get_batch_statistics(&self, batch_id: &str) -> Result<BatchStatistics, RepositoryError> {
        let instances = self.list_batch_instances(batch_id).await?;
        
        let mut stats = BatchStatistics {
            total_instances: instances.len(),
            not_tested: 0,
            testing: 0,
            passed: 0,
            failed: 0,
            skipped: 0,
            progress_percentage: 0.0,
        };
        
        for instance in &instances {
            match instance.overall_status {
                OverallTestStatus::NotTested => stats.not_tested += 1,
                OverallTestStatus::HardPointTesting | OverallTestStatus::ManualTesting => stats.testing += 1,
                OverallTestStatus::TestCompletedPassed => stats.passed += 1,
                OverallTestStatus::TestCompletedFailed => stats.failed += 1,
                OverallTestStatus::Skipped => stats.skipped += 1,
                _ => {} // å…¶ä»–çŠ¶æ€
            }
        }
        
        if stats.total_instances > 0 {
            let completed = stats.passed + stats.failed + stats.skipped;
            stats.progress_percentage = (completed as f64 / stats.total_instances as f64) * 100.0;
        }
        
        Ok(stats)
    }
    
    async fn list_instances_by_status(&self, status: OverallTestStatus) -> Result<Vec<ChannelTestInstance>, RepositoryError> {
        let instances = self.instances.read().await;
        Ok(instances.values()
            .filter(|instance| instance.overall_status == status)
            .cloned()
            .collect())
    }
    
    async fn count_instances_by_status(&self, batch_id: &str, status: OverallTestStatus) -> Result<usize, RepositoryError> {
        let instances = self.list_batch_instances(batch_id).await?;
        Ok(instances.iter()
            .filter(|instance| instance.overall_status == status)
            .count())
    }
    
    async fn save_channel_instances_batch(&self, instances: &[ChannelTestInstance]) -> Result<(), RepositoryError> {
        for instance in instances {
            self.save_channel_instance(instance).await?;
        }
        Ok(())
    }
    
    async fn update_instances_status(&self, instance_ids: &[String], status: OverallTestStatus) -> Result<usize, RepositoryError> {
        let mut instances = self.instances.write().await;
        let mut updated_count = 0;
        
        for instance_id in instance_ids {
            if let Some(instance) = instances.get_mut(instance_id) {
                instance.overall_status = status;
                instance.last_updated_time = Utc::now();
                updated_count += 1;
            }
        }
        
        Ok(updated_count)
    }
    
    async fn get_test_batch(&self, batch_id: &str) -> Result<Option<TestBatchInfo>, RepositoryError> {
        let batches = self.batches.read().await;
        Ok(batches.get(batch_id).cloned())
    }
    
    async fn save_test_batch(&self, batch: &TestBatchInfo) -> Result<(), RepositoryError> {
        let mut batches = self.batches.write().await;
        batches.insert(batch.batch_id.clone(), batch.clone());
        Ok(())
    }
    
    async fn delete_test_batch(&self, batch_id: &str) -> Result<bool, RepositoryError> {
        let mut batches = self.batches.write().await;
        let mut mapping = self.batch_instance_mapping.write().await;
        
        let existed = batches.remove(batch_id).is_some();
        mapping.remove(batch_id);
        
        Ok(existed)
    }
    
    async fn list_test_batches(&self) -> Result<Vec<TestBatchInfo>, RepositoryError> {
        let batches = self.batches.read().await;
        Ok(batches.values().cloned().collect())
    }
    
    async fn list_active_batches(&self) -> Result<Vec<TestBatchInfo>, RepositoryError> {
        let batches = self.batches.read().await;
        // ç®€åŒ–å®ç°ï¼šå‡è®¾æ‰€æœ‰æ‰¹æ¬¡éƒ½æ˜¯æ´»è·ƒçš„
        // å®é™…å®ç°å¯èƒ½éœ€è¦æ ¹æ®æ‰¹æ¬¡çŠ¶æ€æˆ–æœ€åæ´»åŠ¨æ—¶é—´è¿‡æ»¤
        Ok(batches.values().cloned().collect())
    }
    
    async fn clear_cache(&self) -> Result<(), RepositoryError> {
        let mut instances = self.instances.write().await;
        let mut batches = self.batches.write().await;
        let mut mapping = self.batch_instance_mapping.write().await;
        let mut stats = self.cache_stats.write().await;
        
        instances.clear();
        batches.clear();
        mapping.clear();
        
        *stats = CacheStatistics {
            total_entries: 0,
            hit_count: 0,
            miss_count: 0,
            hit_rate: 0.0,
            memory_usage_bytes: 0,
        };
        
        Ok(())
    }
    
    async fn get_cache_stats(&self) -> Result<CacheStatistics, RepositoryError> {
        let stats = self.cache_stats.read().await;
        Ok(stats.clone())
    }
    
    async fn invalidate_batch_cache(&self, batch_id: &str) -> Result<(), RepositoryError> {
        // ä»ç¼“å­˜ä¸­ç§»é™¤æŒ‡å®šæ‰¹æ¬¡çš„æ‰€æœ‰å®ä¾‹
        let mapping = self.batch_instance_mapping.read().await;
        if let Some(instance_ids) = mapping.get(batch_id) {
            let mut instances = self.instances.write().await;
            for instance_id in instance_ids {
                instances.remove(instance_id);
            }
        }
        
        // ç§»é™¤æ‰¹æ¬¡æœ¬èº«
        let mut batches = self.batches.write().await;
        batches.remove(batch_id);
        
        Ok(())
    }
    
    async fn begin_transaction(&self) -> Result<TransactionHandle, RepositoryError> {
        let handle = TransactionHandle {
            id: Uuid::new_v4().to_string(),
            start_time: Utc::now(),
        };
        
        // åˆ›å»ºå½“å‰çŠ¶æ€çš„å¿«ç…§
        let instances = self.instances.read().await;
        let batches = self.batches.read().await;
        
        let transaction_state = TransactionState {
            handle: handle.clone(),
            snapshot_instances: instances.clone(),
            snapshot_batches: batches.clone(),
        };
        
        let mut transactions = self.transactions.write().await;
        transactions.insert(handle.id.clone(), transaction_state);
        
        Ok(handle)
    }
    
    async fn commit_transaction(&self, handle: TransactionHandle) -> Result<(), RepositoryError> {
        let mut transactions = self.transactions.write().await;
        if transactions.remove(&handle.id).is_some() {
            Ok(())
        } else {
            Err(RepositoryError::NotFound(format!("äº‹åŠ¡ä¸å­˜åœ¨: {}", handle.id)))
        }
    }
    
    async fn rollback_transaction(&self, handle: TransactionHandle) -> Result<(), RepositoryError> {
        let mut transactions = self.transactions.write().await;
        if let Some(transaction_state) = transactions.remove(&handle.id) {
            // æ¢å¤å¿«ç…§çŠ¶æ€
            let mut instances = self.instances.write().await;
            let mut batches = self.batches.write().await;
            
            *instances = transaction_state.snapshot_instances;
            *batches = transaction_state.snapshot_batches;
            
            Ok(())
        } else {
            Err(RepositoryError::NotFound(format!("äº‹åŠ¡ä¸å­˜åœ¨: {}", handle.id)))
        }
    }
    
    // è¾…åŠ©æ–¹æ³•
    fn apply_instance_filter(&self, mut instances: Vec<ChannelTestInstance>, filter: &Filter) -> Result<Vec<ChannelTestInstance>, RepositoryError> {
        match filter.field.as_str() {
            "batch_id" => {
                if let FilterValue::String(ref value) = filter.value {
                    instances.retain(|i| i.test_batch_id == *value);
                }
            }
            "overall_status" => {
                if let FilterValue::String(ref value) = filter.value {
                    let status = value.parse::<OverallTestStatus>()
                        .map_err(|_| RepositoryError::ValidationError(format!("æ— æ•ˆçš„çŠ¶æ€: {}", value)))?;
                    instances.retain(|i| i.overall_status == status);
                }
            }
            "definition_id" => {
                if let FilterValue::String(ref value) = filter.value {
                    instances.retain(|i| i.definition_id == *value);
                }
            }
            _ => return Err(RepositoryError::ValidationError(format!("ä¸æ”¯æŒçš„è¿‡æ»¤å­—æ®µ: {}", filter.field))),
        }
        Ok(instances)
    }
    
    fn sort_instances(&self, instances: &mut Vec<ChannelTestInstance>, sort_field: &str) {
        match sort_field {
            "instance_id" => instances.sort_by(|a, b| a.instance_id.cmp(&b.instance_id)),
            "last_updated_time" => instances.sort_by(|a, b| a.last_updated_time.cmp(&b.last_updated_time)),
            "overall_status" => instances.sort_by(|a, b| format!("{:?}", a.overall_status).cmp(&format!("{:?}", b.overall_status))),
            _ => {} // å¿½ç•¥ä¸æ”¯æŒçš„æ’åºå­—æ®µ
        }
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

##### 1.3.3 è¿è¡Œæ—¶Repositoryæµ‹è¯•
```rust
// src/repositories/tests/runtime_repository_tests.rs
use super::super::runtime_repository::*;
use crate::models::structs::ChannelTestInstance;
use crate::models::enums::OverallTestStatus;
use tokio;

struct RuntimeRepositoryTestSuite;

impl RuntimeRepositoryTestSuite {
    fn create_test_instance(batch_id: &str, tag: &str) -> ChannelTestInstance {
        ChannelTestInstance {
            instance_id: uuid::Uuid::new_v4().to_string(),
            definition_id: uuid::Uuid::new_v4().to_string(),
            test_batch_id: batch_id.to_string(),
            overall_status: OverallTestStatus::NotTested,
            current_step_details: None,
            error_message: None,
            start_time: None,
            last_updated_time: chrono::Utc::now(),
            final_test_time: None,
            total_test_duration_ms: None,
            sub_test_results: std::collections::HashMap::new(),
            hardpoint_readings: None,
            manual_test_current_value_input: None,
            manual_test_current_value_output: None,
        }
    }
    
    fn create_test_batch() -> TestBatchInfo {
        TestBatchInfo {
            batch_id: uuid::Uuid::new_v4().to_string(),
            product_model: Some("æµ‹è¯•äº§å“".to_string()),
            serial_number: Some("SN001".to_string()),
            customer_name: Some("æµ‹è¯•å®¢æˆ·".to_string()),
            creation_time: chrono::Utc::now(),
            status_summary: Some("æµ‹è¯•ä¸­".to_string()),
            total_points: 0,
            tested_points: 0,
            passed_points: 0,
            failed_points: 0,
        }
    }
}

#[tokio::test]
async fn test_runtime_repository_basic_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch_id = "test_batch_001";
    let instance = RuntimeRepositoryTestSuite::create_test_instance(batch_id, "TEST_001");
    let instance_id = instance.instance_id.clone();
    
    // æµ‹è¯•ä¿å­˜å®ä¾‹
    repo.save_channel_instance(&instance).await.expect("ä¿å­˜å®ä¾‹å¤±è´¥");
    
    // æµ‹è¯•è·å–å®ä¾‹
    let retrieved = repo.get_channel_instance(&instance_id).await.expect("è·å–å®ä¾‹å¤±è´¥");
    assert!(retrieved.is_some(), "åº”è¯¥èƒ½è·å–åˆ°å®ä¾‹");
    assert_eq!(retrieved.unwrap().test_batch_id, batch_id, "æ‰¹æ¬¡IDåº”è¯¥ä¸€è‡´");
    
    // æµ‹è¯•åˆ—è¡¨å®ä¾‹
    let all_instances = repo.list_channel_instances().await.expect("åˆ—è¡¨æŸ¥è¯¢å¤±è´¥");
    assert!(all_instances.len() >= 1, "åº”è¯¥åŒ…å«è‡³å°‘ä¸€ä¸ªå®ä¾‹");
    
    // æµ‹è¯•åˆ é™¤å®ä¾‹
    let deleted = repo.delete_channel_instance(&instance_id).await.expect("åˆ é™¤å¤±è´¥");
    assert!(deleted, "åº”è¯¥åˆ é™¤æˆåŠŸ");
    
    // éªŒè¯åˆ é™¤
    let after_delete = repo.get_channel_instance(&instance_id).await.expect("åˆ é™¤åæŸ¥è¯¢å¤±è´¥");
    assert!(after_delete.is_none(), "åˆ é™¤ååº”è¯¥ä¸å­˜åœ¨");
}

#[tokio::test]
async fn test_batch_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch = RuntimeRepositoryTestSuite::create_test_batch();
    let batch_id = batch.batch_id.clone();
    
    // åˆ›å»ºæµ‹è¯•å®ä¾‹
    let instance1 = RuntimeRepositoryTestSuite::create_test_instance(&batch_id, "TEST_001");
    let instance2 = RuntimeRepositoryTestSuite::create_test_instance(&batch_id, "TEST_002");
    let mut instance3 = RuntimeRepositoryTestSuite::create_test_instance(&batch_id, "TEST_003");
    instance3.overall_status = OverallTestStatus::TestCompletedPassed;
    
    // ä¿å­˜æ‰¹æ¬¡å’Œå®ä¾‹
    repo.save_test_batch(&batch).await.expect("ä¿å­˜æ‰¹æ¬¡å¤±è´¥");
    repo.save_channel_instance(&instance1).await.expect("ä¿å­˜å®ä¾‹1å¤±è´¥");
    repo.save_channel_instance(&instance2).await.expect("ä¿å­˜å®ä¾‹2å¤±è´¥");
    repo.save_channel_instance(&instance3).await.expect("ä¿å­˜å®ä¾‹3å¤±è´¥");
    
    // æµ‹è¯•æ‰¹æ¬¡å®ä¾‹åˆ—è¡¨
    let batch_instances = repo.list_batch_instances(&batch_id).await.expect("è·å–æ‰¹æ¬¡å®ä¾‹å¤±è´¥");
    assert_eq!(batch_instances.len(), 3, "åº”è¯¥æœ‰3ä¸ªå®ä¾‹");
    
    // æµ‹è¯•æ‰¹æ¬¡å®ä¾‹è®¡æ•°
    let count = repo.count_batch_instances(&batch_id).await.expect("è®¡æ•°å¤±è´¥");
    assert_eq!(count, 3, "è®¡æ•°åº”è¯¥ä¸º3");
    
    // æµ‹è¯•æ‰¹æ¬¡ç»Ÿè®¡
    let stats = repo.get_batch_statistics(&batch_id).await.expect("è·å–ç»Ÿè®¡å¤±è´¥");
    assert_eq!(stats.total_instances, 3, "æ€»å®ä¾‹æ•°åº”è¯¥ä¸º3");
    assert_eq!(stats.not_tested, 2, "æœªæµ‹è¯•å®ä¾‹æ•°åº”è¯¥ä¸º2");
    assert_eq!(stats.passed, 1, "é€šè¿‡å®ä¾‹æ•°åº”è¯¥ä¸º1");
    assert!(stats.progress_percentage > 0.0, "è¿›åº¦åº”è¯¥å¤§äº0");
    
    // æµ‹è¯•æŒ‰çŠ¶æ€æŸ¥è¯¢
    let not_tested = repo.list_instances_by_status(OverallTestStatus::NotTested).await.expect("æŒ‰çŠ¶æ€æŸ¥è¯¢å¤±è´¥");
    assert_eq!(not_tested.len(), 2, "åº”è¯¥æœ‰2ä¸ªæœªæµ‹è¯•å®ä¾‹");
    
    let passed_count = repo.count_instances_by_status(&batch_id, OverallTestStatus::TestCompletedPassed).await.expect("æŒ‰çŠ¶æ€è®¡æ•°å¤±è´¥");
    assert_eq!(passed_count, 1, "åº”è¯¥æœ‰1ä¸ªé€šè¿‡å®ä¾‹");
}

#[tokio::test]
async fn test_batch_update_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch_id = "test_batch_002";
    
    // åˆ›å»ºå¤šä¸ªå®ä¾‹
    let instances: Vec<ChannelTestInstance> = (0..5)
        .map(|i| RuntimeRepositoryTestSuite::create_test_instance(batch_id, &format!("TEST_{:03}", i)))
        .collect();
    
    let instance_ids: Vec<String> = instances.iter().map(|i| i.instance_id.clone()).collect();
    
    // æ‰¹é‡ä¿å­˜
    repo.save_channel_instances_batch(&instances).await.expect("æ‰¹é‡ä¿å­˜å¤±è´¥");
    
    // éªŒè¯æ‰¹é‡ä¿å­˜
    let saved_instances = repo.list_batch_instances(batch_id).await.expect("è·å–ä¿å­˜çš„å®ä¾‹å¤±è´¥");
    assert_eq!(saved_instances.len(), 5, "åº”è¯¥æœ‰5ä¸ªå®ä¾‹");
    
    // æµ‹è¯•æ‰¹é‡çŠ¶æ€æ›´æ–°
    let updated_count = repo.update_instances_status(&instance_ids[0..3], OverallTestStatus::HardPointTesting).await.expect("æ‰¹é‡æ›´æ–°å¤±è´¥");
    assert_eq!(updated_count, 3, "åº”è¯¥æ›´æ–°3ä¸ªå®ä¾‹");
    
    // éªŒè¯æ›´æ–°ç»“æœ
    let testing_instances = repo.list_instances_by_status(OverallTestStatus::HardPointTesting).await.expect("æŸ¥è¯¢æµ‹è¯•ä¸­å®ä¾‹å¤±è´¥");
    assert_eq!(testing_instances.len(), 3, "åº”è¯¥æœ‰3ä¸ªæµ‹è¯•ä¸­å®ä¾‹");
}

#[tokio::test]
async fn test_query_operations() {
    let repo = MemoryRuntimeRepository::new();
    let batch_id_1 = "batch_001";
    let batch_id_2 = "batch_002";
    
    // åˆ›å»ºä¸åŒæ‰¹æ¬¡çš„å®ä¾‹
    let instance1 = RuntimeRepositoryTestSuite::create_test_instance(batch_id_1, "TEST_001");
    let instance2 = RuntimeRepositoryTestSuite::create_test_instance(batch_id_1, "TEST_002");
    let instance3 = RuntimeRepositoryTestSuite::create_test_instance(batch_id_2, "TEST_003");
    
    repo.save_channel_instance(&instance1).await.expect("ä¿å­˜å®ä¾‹1å¤±è´¥");
    repo.save_channel_instance(&instance2).await.expect("ä¿å­˜å®ä¾‹2å¤±è´¥");
    repo.save_channel_instance(&instance3).await.expect("ä¿å­˜å®ä¾‹3å¤±è´¥");
    
    // æµ‹è¯•æŒ‰æ‰¹æ¬¡è¿‡æ»¤
    let criteria = QueryCriteria {
        filters: vec![Filter {
            field: "batch_id".to_string(),
            operator: FilterOperator::Equal,
            value: FilterValue::String(batch_id_1.to_string()),
        }],
        sort_by: Some("instance_id".to_string()),
        limit: None,
        offset: None,
    };
    
    let batch1_results = repo.query_channel_instances(&criteria).await.expect("æŸ¥è¯¢å¤±è´¥");
    assert_eq!(batch1_results.len(), 2, "æ‰¹æ¬¡1åº”è¯¥æœ‰2ä¸ªå®ä¾‹");
    
    // æµ‹è¯•åˆ†é¡µæŸ¥è¯¢
    let paging_criteria = QueryCriteria {
        filters: vec![],
        sort_by: Some("instance_id".to_string()),
        limit: Some(2),
        offset: Some(1),
    };
    
    let paging_results = repo.query_channel_instances(&paging_criteria).await.expect("åˆ†é¡µæŸ¥è¯¢å¤±è´¥");
    assert!(paging_results.len() <= 2, "åˆ†é¡µç»“æœä¸åº”è¶…è¿‡é™åˆ¶");
}

#[tokio::test]
async fn test_cache_operations() {
    let repo = MemoryRuntimeRepository::new();
    let instance = RuntimeRepositoryTestSuite::create_test_instance("test_batch", "TEST_001");
    let instance_id = instance.instance_id.clone();
    
    // æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­
    let _ = repo.get_channel_instance(&instance_id).await.expect("æŸ¥è¯¢å¤±è´¥");
    let stats = repo.get_cache_stats().await.expect("è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥");
    assert_eq!(stats.miss_count, 1, "åº”è¯¥æœ‰1æ¬¡æœªå‘½ä¸­");
    
    // ä¿å­˜å®ä¾‹
    repo.save_channel_instance(&instance).await.expect("ä¿å­˜å¤±è´¥");
    
    // æµ‹è¯•ç¼“å­˜å‘½ä¸­
    let _ = repo.get_channel_instance(&instance_id).await.expect("æŸ¥è¯¢å¤±è´¥");
    let stats = repo.get_cache_stats().await.expect("è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥");
    assert_eq!(stats.hit_count, 1, "åº”è¯¥æœ‰1æ¬¡å‘½ä¸­");
    assert!(stats.hit_rate > 0.0, "å‘½ä¸­ç‡åº”è¯¥å¤§äº0");
    
    // æµ‹è¯•æ¸…é™¤ç¼“å­˜
    repo.clear_cache().await.expect("æ¸…é™¤ç¼“å­˜å¤±è´¥");
    let stats = repo.get_cache_stats().await.expect("è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥");
    assert_eq!(stats.total_entries, 0, "ç¼“å­˜åº”è¯¥ä¸ºç©º");
    assert_eq!(stats.hit_count, 0, "å‘½ä¸­è®¡æ•°åº”è¯¥é‡ç½®");
    assert_eq!(stats.miss_count, 0, "æœªå‘½ä¸­è®¡æ•°åº”è¯¥é‡ç½®");
}

#[tokio::test]
async fn test_transaction_operations() {
    let repo = MemoryRuntimeRepository::new();
    let instance = RuntimeRepositoryTestSuite::create_test_instance("test_batch", "TEST_001");
    
    // ä¿å­˜åˆå§‹æ•°æ®
    repo.save_channel_instance(&instance).await.expect("ä¿å­˜åˆå§‹æ•°æ®å¤±è´¥");
    
    // å¼€å§‹äº‹åŠ¡
    let transaction = repo.begin_transaction().await.expect("å¼€å§‹äº‹åŠ¡å¤±è´¥");
    
    // ä¿®æ”¹æ•°æ®
    let mut modified_instance = instance.clone();
    modified_instance.overall_status = OverallTestStatus::TestCompletedPassed;
    repo.save_channel_instance(&modified_instance).await.expect("ä¿®æ”¹æ•°æ®å¤±è´¥");
    
    // éªŒè¯ä¿®æ”¹
    let current = repo.get_channel_instance(&instance.instance_id).await.expect("æŸ¥è¯¢å½“å‰æ•°æ®å¤±è´¥");
    assert_eq!(current.unwrap().overall_status, OverallTestStatus::TestCompletedPassed, "æ•°æ®åº”è¯¥å·²ä¿®æ”¹");
    
    // å›æ»šäº‹åŠ¡
    repo.rollback_transaction(transaction).await.expect("å›æ»šäº‹åŠ¡å¤±è´¥");
    
    // éªŒè¯å›æ»š
    let after_rollback = repo.get_channel_instance(&instance.instance_id).await.expect("æŸ¥è¯¢å›æ»šåæ•°æ®å¤±è´¥");
    assert_eq!(after_rollback.unwrap().overall_status, OverallTestStatus::NotTested, "æ•°æ®åº”è¯¥å·²å›æ»š");
}

/// æ€§èƒ½æµ‹è¯•
#[tokio::test]
async fn test_performance_with_large_dataset() {
    let repo = MemoryRuntimeRepository::new();
    let batch_id = "performance_test_batch";
    
    // åˆ›å»ºå¤§é‡å®ä¾‹
    let start = std::time::Instant::now();
    let instances: Vec<ChannelTestInstance> = (0..10000)
        .map(|i| RuntimeRepositoryTestSuite::create_test_instance(batch_id, &format!("PERF_TEST_{:05}", i)))
        .collect();
    
    let creation_time = start.elapsed();
    println!("åˆ›å»º10000ä¸ªå®ä¾‹è€—æ—¶: {:?}", creation_time);
    
    // æ‰¹é‡ä¿å­˜
    let save_start = std::time::Instant::now();
    repo.save_channel_instances_batch(&instances).await.expect("æ‰¹é‡ä¿å­˜å¤±è´¥");
    let save_time = save_start.elapsed();
    println!("æ‰¹é‡ä¿å­˜10000ä¸ªå®ä¾‹è€—æ—¶: {:?}", save_time);
    
    // æŸ¥è¯¢æµ‹è¯•
    let query_start = std::time::Instant::now();
    let all_instances = repo.list_batch_instances(batch_id).await.expect("æŸ¥è¯¢å¤±è´¥");
    let query_time = query_start.elapsed();
    println!("æŸ¥è¯¢10000ä¸ªå®ä¾‹è€—æ—¶: {:?}", query_time);
    
    assert_eq!(all_instances.len(), 10000, "åº”è¯¥è¿”å›10000ä¸ªå®ä¾‹");
    
    // ç»Ÿè®¡æµ‹è¯•
    let stats_start = std::time::Instant::now();
    let stats = repo.get_batch_statistics(batch_id).await.expect("ç»Ÿè®¡å¤±è´¥");
    let stats_time = stats_start.elapsed();
    println!("ç»Ÿè®¡10000ä¸ªå®ä¾‹è€—æ—¶: {:?}", stats_time);
    
    assert_eq!(stats.total_instances, 10000, "ç»Ÿè®¡æ€»æ•°åº”è¯¥ä¸º10000");
    
    // ç¡®ä¿æ€§èƒ½åœ¨åˆç†èŒƒå›´å†…
    assert!(save_time.as_millis() < 2000, "æ‰¹é‡ä¿å­˜åº”è¯¥åœ¨2ç§’å†…å®Œæˆ");
    assert!(query_time.as_millis() < 500, "æŸ¥è¯¢åº”è¯¥åœ¨500æ¯«ç§’å†…å®Œæˆ");
    assert!(stats_time.as_millis() < 200, "ç»Ÿè®¡åº”è¯¥åœ¨200æ¯«ç§’å†…å®Œæˆ");
}
```

### âœ… æ­¥éª¤1.3å®Œæˆæ ‡å‡†

1. **æ¥å£å®Œæ•´æ€§**: æ‰€æœ‰IRuntimeRepositoryæ–¹æ³•éƒ½æœ‰å®Œæ•´å®ç°
2. **æ€§èƒ½ä¼˜åŒ–**: æ”¯æŒé«˜å¹¶å‘è¯»å†™å’Œå¤§æ•°æ®é›†æ“ä½œ
3. **ç¼“å­˜æœºåˆ¶**: å®Œæ•´çš„ç¼“å­˜ç»Ÿè®¡å’Œç®¡ç†åŠŸèƒ½
4. **äº‹åŠ¡æ”¯æŒ**: æä¾›åŸºæœ¬çš„äº‹åŠ¡å›æ»šèƒ½åŠ›
5. **æµ‹è¯•è¦†ç›–**: åŒ…å«æ€§èƒ½æµ‹è¯•å’Œå¹¶å‘æµ‹è¯•

---

## ğŸš€ Phase 1 åç»­æ­¥éª¤é¢„è§ˆ

æ¥ä¸‹æ¥æˆ‘ä»¬å°†å®æ–½ï¼š

### æ­¥éª¤ 1.4: åˆ›å»ºæŒä¹…åŒ–æ•°æ®Repository
- å®ç°IPersistentRepositoryæ¥å£
- ç®¡ç†éœ€è¦æ°¸ä¹…ä¿å­˜çš„æµ‹è¯•è®°å½•å’Œå®¡è®¡æ•°æ®
- é›†æˆSQLiteæ•°æ®åº“

### æ­¥éª¤ 1.5: Repositoryé›†æˆæµ‹è¯•
- å¤šRepositoryååŒå·¥ä½œæµ‹è¯•
- æ•°æ®ä¸€è‡´æ€§éªŒè¯
- æ€§èƒ½å’Œå¹¶å‘æµ‹è¯•

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

### æ­¥éª¤ 1.4: åˆ›å»ºæŒä¹…åŒ–æ•°æ®Repository

#### ğŸ¯ ç›®æ ‡
å®ç°ä¸“é—¨ç®¡ç†æŒä¹…åŒ–æ•°æ®çš„Repositoryï¼Œç¡®ä¿é‡è¦æ•°æ®çš„é•¿æœŸä¿å­˜å’ŒæŸ¥è¯¢ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 1.4.1 å®šä¹‰æŒä¹…åŒ–Repositoryæ¥å£
```rust
// src/repositories/persistent_repository.rs
use async_trait::async_trait;
use crate::models::structs::{TestRecord, TestBatchPersistent, AuditRecord};
use crate::models::errors::RepositoryError;
use super::{IRepository, QueryCriteria};
use chrono::{DateTime, Utc};

/// æŒä¹…åŒ–æ•°æ®Repositoryæ¥å£
#[async_trait]
pub trait IPersistentRepository: Send + Sync {
    // æµ‹è¯•è®°å½•ç®¡ç†
    async fn save_test_record(&self, record: &TestRecord) -> Result<(), RepositoryError>;
    async fn get_test_record(&self, record_id: &str) -> Result<Option<TestRecord>, RepositoryError>;
    async fn list_test_records(&self, batch_id: &str) -> Result<Vec<TestRecord>, RepositoryError>;
    async fn query_test_records(&self, criteria: &QueryCriteria) -> Result<Vec<TestRecord>, RepositoryError>;
    
    // æ‰¹æ¬¡æŒä¹…åŒ–ç®¡ç†
    async fn save_batch_persistent(&self, batch: &TestBatchPersistent) -> Result<(), RepositoryError>;
    async fn get_batch_persistent(&self, batch_id: &str) -> Result<Option<TestBatchPersistent>, RepositoryError>;
    async fn list_historical_batches(&self, from_date: DateTime<Utc>, to_date: DateTime<Utc>) -> Result<Vec<TestBatchPersistent>, RepositoryError>;
    
    // å®¡è®¡è®°å½•ç®¡ç†
    async fn save_audit_record(&self, record: &AuditRecord) -> Result<(), RepositoryError>;
    async fn list_audit_records(&self, entity_id: &str) -> Result<Vec<AuditRecord>, RepositoryError>;
    
    // æŠ¥è¡¨å’Œç»Ÿè®¡
    async fn generate_batch_report(&self, batch_id: &str) -> Result<BatchReport, RepositoryError>;
    async fn get_test_statistics(&self, from_date: DateTime<Utc>, to_date: DateTime<Utc>) -> Result<TestStatistics, RepositoryError>;
}
```

### âœ… æ­¥éª¤1.4å®Œæˆæ ‡å‡†

1. **æ¥å£å®Œæ•´æ€§**: æ‰€æœ‰IPersistentRepositoryæ–¹æ³•éƒ½æœ‰å®Œæ•´å®ç°
2. **æ•°æ®æŒä¹…åŒ–**: é‡è¦æ•°æ®èƒ½å¤Ÿå¯é ä¿å­˜åˆ°SQLiteæ•°æ®åº“
3. **æŸ¥è¯¢æ€§èƒ½**: å¤æ‚æŸ¥è¯¢åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
4. **æŠ¥è¡¨åŠŸèƒ½**: èƒ½å¤Ÿç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æŠ¥è¡¨
5. **å®¡è®¡è·Ÿè¸ª**: å®Œæ•´çš„æ“ä½œå®¡è®¡è®°å½•

---

## ğŸš€ Phase 2: çŠ¶æ€ç®¡ç†å™¨é‡æ„

### æ­¥éª¤ 2.1: åˆ›å»ºå¢å¼ºçš„çŠ¶æ€ç®¡ç†å™¨æ¥å£

#### ğŸ¯ ç›®æ ‡
é‡æ–°è®¾è®¡çŠ¶æ€ç®¡ç†å™¨ï¼Œç¡®ä¿ä¸¥æ ¼çš„çŠ¶æ€æ§åˆ¶å’Œä¸€è‡´æ€§ä¿è¯ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 2.1.1 å®šä¹‰çŠ¶æ€ç®¡ç†å™¨æ ¸å¿ƒæ¥å£
```rust
// src/services/state_management/channel_state_manager.rs
use async_trait::async_trait;
use crate::models::structs::{ChannelTestInstance, StateTransition, TestOutcome};
use crate::models::enums::{OverallTestStatus, SubTestItem};
use crate::models::errors::StateError;
use crate::repositories::{IRuntimeRepository, IPersistentRepository};
use std::sync::Arc;
use tokio::sync::{RwLock, broadcast};

/// çŠ¶æ€ç®¡ç†å™¨æ¥å£ - ç³»ç»Ÿä¸­å”¯ä¸€å…è®¸ä¿®æ”¹å®ä¾‹çŠ¶æ€çš„ç»„ä»¶
#[async_trait]
pub trait IChannelStateManager: Send + Sync {
    // çŠ¶æ€æŸ¥è¯¢ (åªè¯»æ“ä½œ)
    async fn get_current_state(&self, instance_id: &str) -> Result<ChannelRuntimeState, StateError>;
    async fn can_transition_to(&self, instance_id: &str, target_status: OverallTestStatus) -> Result<bool, StateError>;
    async fn get_transition_history(&self, instance_id: &str) -> Result<Vec<StateTransition>, StateError>;
    
    // çŠ¶æ€ä¿®æ”¹ (å”¯ä¸€ä¿®æ”¹å…¥å£)
    async fn apply_test_outcome(&self, instance_id: &str, outcome: TestOutcome) -> Result<StateTransition, StateError>;
    async fn force_state_transition(&self, instance_id: &str, target_status: OverallTestStatus, reason: String) -> Result<StateTransition, StateError>;
    async fn reset_for_retest(&self, instance_id: &str) -> Result<StateTransition, StateError>;
    
    // æ‰¹é‡çŠ¶æ€æ“ä½œ
    async fn batch_state_update(&self, updates: Vec<StateUpdateRequest>) -> Result<Vec<StateTransition>, StateError>;
    async fn batch_reset_for_retest(&self, instance_ids: Vec<String>) -> Result<Vec<StateTransition>, StateError>;
    
    // çŠ¶æ€äº‹ä»¶è®¢é˜…
    async fn subscribe_state_changes(&self) -> Result<broadcast::Receiver<StateChangeEvent>, StateError>;
    async fn subscribe_instance_changes(&self, instance_id: &str) -> Result<broadcast::Receiver<StateChangeEvent>, StateError>;
    
    // çŠ¶æ€éªŒè¯å’Œå®¡è®¡
    async fn validate_state_consistency(&self, instance_id: &str) -> Result<StateValidationResult, StateError>;
    async fn audit_state_changes(&self, from_time: DateTime<Utc>, to_time: DateTime<Utc>) -> Result<Vec<StateAuditRecord>, StateError>;
}

/// çŠ¶æ€æ›´æ–°è¯·æ±‚
#[derive(Debug, Clone)]
pub struct StateUpdateRequest {
    pub instance_id: String,
    pub outcome: TestOutcome,
    pub force_transition: bool,
    pub reason: Option<String>,
}

/// çŠ¶æ€å˜æ›´äº‹ä»¶
#[derive(Debug, Clone)]
pub struct StateChangeEvent {
    pub instance_id: String,
    pub old_status: OverallTestStatus,
    pub new_status: OverallTestStatus,
    pub transition_reason: String,
    pub timestamp: DateTime<Utc>,
    pub operator: Option<String>,
}

/// çŠ¶æ€éªŒè¯ç»“æœ
#[derive(Debug, Clone)]
pub struct StateValidationResult {
    pub is_valid: bool,
    pub issues: Vec<StateValidationIssue>,
    pub recommendations: Vec<String>,
}

/// çŠ¶æ€éªŒè¯é—®é¢˜
#[derive(Debug, Clone)]
pub struct StateValidationIssue {
    pub severity: ValidationSeverity,
    pub message: String,
    pub field: Option<String>,
}

/// çŠ¶æ€å®¡è®¡è®°å½•
#[derive(Debug, Clone)]
pub struct StateAuditRecord {
    pub instance_id: String,
    pub transition: StateTransition,
    pub context: StateAuditContext,
}

#[derive(Debug, Clone)]
pub struct StateAuditContext {
    pub user_id: Option<String>,
    pub operation_id: String,
    pub client_info: Option<String>,
}
```

##### 2.1.2 å®ç°å¢å¼ºçš„çŠ¶æ€ç®¡ç†å™¨
```rust
// src/services/state_management/channel_state_manager.rs (continued)
use std::collections::HashMap;
use uuid::Uuid;
use chrono::Utc;

/// å¢å¼ºçš„é€šé“çŠ¶æ€ç®¡ç†å™¨å®ç°
pub struct EnhancedChannelStateManager {
    runtime_repo: Arc<dyn IRuntimeRepository>,
    persistent_repo: Arc<dyn IPersistentRepository>,
    state_transitions: Arc<RwLock<HashMap<String, Vec<StateTransition>>>>,
    event_broadcaster: broadcast::Sender<StateChangeEvent>,
    transition_rules: Arc<StateTransitionRules>,
}

impl EnhancedChannelStateManager {
    pub fn new(
        runtime_repo: Arc<dyn IRuntimeRepository>,
        persistent_repo: Arc<dyn IPersistentRepository>,
    ) -> Self {
        let (event_broadcaster, _) = broadcast::channel(1000);
        
        Self {
            runtime_repo,
            persistent_repo,
            state_transitions: Arc::new(RwLock::new(HashMap::new())),
            event_broadcaster,
            transition_rules: Arc::new(StateTransitionRules::new()),
        }
    }
    
    /// éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦åˆæ³•
    async fn validate_transition(
        &self,
        current_status: OverallTestStatus,
        target_status: OverallTestStatus,
        force: bool,
    ) -> Result<bool, StateError> {
        if force {
            return Ok(true);
        }
        
        self.transition_rules.is_valid_transition(current_status, target_status)
    }
    
    /// åˆ›å»ºçŠ¶æ€è½¬æ¢è®°å½•
    fn create_transition(
        &self,
        instance_id: &str,
        old_status: OverallTestStatus,
        new_status: OverallTestStatus,
        reason: &str,
    ) -> StateTransition {
        StateTransition {
            transition_id: Uuid::new_v4().to_string(),
            instance_id: instance_id.to_string(),
            old_status,
            new_status,
            reason: reason.to_string(),
            timestamp: Utc::now(),
            duration_ms: None,
        }
    }
    
    /// å‘å¸ƒçŠ¶æ€å˜æ›´äº‹ä»¶
    async fn publish_state_change(&self, event: StateChangeEvent) -> Result<(), StateError> {
        if let Err(_) = self.event_broadcaster.send(event) {
            // å¦‚æœæ²¡æœ‰è®¢é˜…è€…ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸éœ€è¦æŠ¥é”™
        }
        Ok(())
    }
    
    /// ä¿å­˜çŠ¶æ€è½¬æ¢å†å²
    async fn save_transition_history(&self, transition: &StateTransition) -> Result<(), StateError> {
        let mut transitions = self.state_transitions.write().await;
        transitions
            .entry(transition.instance_id.clone())
            .or_insert_with(Vec::new)
            .push(transition.clone());
        Ok(())
    }
}

#[async_trait]
impl IChannelStateManager for EnhancedChannelStateManager {
    async fn get_current_state(&self, instance_id: &str) -> Result<ChannelRuntimeState, StateError> {
        let instance = self.runtime_repo
            .get_channel_instance(instance_id)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?
            .ok_or_else(|| StateError::InstanceNotFound(instance_id.to_string()))?;
        
        Ok(ChannelRuntimeState {
            overall_status: instance.overall_status,
            current_phase: TestPhase::from_status(instance.overall_status),
            error_info: instance.error_message.map(|msg| ErrorInfo::new(msg)),
            timestamps: TimestampCollection::from_instance(&instance),
            progress_info: ProgressInfo::calculate_from_results(&instance.sub_test_results),
        })
    }
    
    async fn can_transition_to(&self, instance_id: &str, target_status: OverallTestStatus) -> Result<bool, StateError> {
        let current_state = self.get_current_state(instance_id).await?;
        self.validate_transition(current_state.overall_status, target_status, false).await
    }
    
    async fn get_transition_history(&self, instance_id: &str) -> Result<Vec<StateTransition>, StateError> {
        let transitions = self.state_transitions.read().await;
        Ok(transitions
            .get(instance_id)
            .cloned()
            .unwrap_or_default())
    }
    
    async fn apply_test_outcome(&self, instance_id: &str, outcome: TestOutcome) -> Result<StateTransition, StateError> {
        // è·å–å½“å‰å®ä¾‹
        let mut instance = self.runtime_repo
            .get_channel_instance(instance_id)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?
            .ok_or_else(|| StateError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        
        // æ ¹æ®æµ‹è¯•ç»“æœç¡®å®šæ–°çŠ¶æ€
        let new_status = match outcome.result {
            TestResult::Passed => {
                if outcome.test_item == SubTestItem::HardPoint {
                    OverallTestStatus::HardPointTesting
                } else {
                    OverallTestStatus::TestCompletedPassed
                }
            }
            TestResult::Failed => OverallTestStatus::TestCompletedFailed,
            TestResult::Skipped => OverallTestStatus::Skipped,
            TestResult::InProgress => {
                match outcome.test_item {
                    SubTestItem::HardPoint => OverallTestStatus::HardPointTesting,
                    _ => OverallTestStatus::ManualTesting,
                }
            }
        };
        
        // éªŒè¯çŠ¶æ€è½¬æ¢
        if !self.validate_transition(old_status, new_status, false).await? {
            return Err(StateError::InvalidTransition {
                from: old_status,
                to: new_status,
                reason: "ä¸åˆæ³•çš„çŠ¶æ€è½¬æ¢".to_string(),
            });
        }
        
        // æ›´æ–°å®ä¾‹çŠ¶æ€
        instance.overall_status = new_status;
        instance.last_updated_time = Utc::now();
        
        // æ›´æ–°æµ‹è¯•ç»“æœ
        instance.sub_test_results.insert(outcome.test_item, SubTestExecutionResult {
            result: outcome.result,
            measured_value: outcome.measured_value,
            expected_value: outcome.expected_value,
            tolerance: outcome.tolerance,
            timestamp: Utc::now(),
            error_message: outcome.error_message,
            duration_ms: outcome.duration_ms,
        });
        
        // ä¿å­˜æ›´æ–°åçš„å®ä¾‹
        self.runtime_repo
            .save_channel_instance(&instance)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?;
        
        // åˆ›å»ºçŠ¶æ€è½¬æ¢è®°å½•
        let transition = self.create_transition(
            instance_id,
            old_status,
            new_status,
            &format!("æµ‹è¯•ç»“æœåº”ç”¨: {:?}", outcome.test_item),
        );
        
        // ä¿å­˜è½¬æ¢å†å²
        self.save_transition_history(&transition).await?;
        
        // å‘å¸ƒçŠ¶æ€å˜æ›´äº‹ä»¶
        let event = StateChangeEvent {
            instance_id: instance_id.to_string(),
            old_status,
            new_status,
            transition_reason: transition.reason.clone(),
            timestamp: transition.timestamp,
            operator: None,
        };
        self.publish_state_change(event).await?;
        
        Ok(transition)
    }
    
    async fn force_state_transition(&self, instance_id: &str, target_status: OverallTestStatus, reason: String) -> Result<StateTransition, StateError> {
        // è·å–å½“å‰å®ä¾‹
        let mut instance = self.runtime_repo
            .get_channel_instance(instance_id)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?
            .ok_or_else(|| StateError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        
        // å¼ºåˆ¶çŠ¶æ€è½¬æ¢ä¸éœ€è¦éªŒè¯åˆæ³•æ€§
        instance.overall_status = target_status;
        instance.last_updated_time = Utc::now();
        
        // ä¿å­˜æ›´æ–°åçš„å®ä¾‹
        self.runtime_repo
            .save_channel_instance(&instance)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?;
        
        // åˆ›å»ºçŠ¶æ€è½¬æ¢è®°å½•
        let transition = self.create_transition(
            instance_id,
            old_status,
            target_status,
            &format!("å¼ºåˆ¶è½¬æ¢: {}", reason),
        );
        
        // ä¿å­˜è½¬æ¢å†å²
        self.save_transition_history(&transition).await?;
        
        // å‘å¸ƒçŠ¶æ€å˜æ›´äº‹ä»¶
        let event = StateChangeEvent {
            instance_id: instance_id.to_string(),
            old_status,
            new_status: target_status,
            transition_reason: transition.reason.clone(),
            timestamp: transition.timestamp,
            operator: None,
        };
        self.publish_state_change(event).await?;
        
        Ok(transition)
    }
    
    async fn reset_for_retest(&self, instance_id: &str) -> Result<StateTransition, StateError> {
        // è·å–å½“å‰å®ä¾‹
        let mut instance = self.runtime_repo
            .get_channel_instance(instance_id)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?
            .ok_or_else(|| StateError::InstanceNotFound(instance_id.to_string()))?;
        
        let old_status = instance.overall_status;
        
        // é‡ç½®ä¸ºæœªæµ‹è¯•çŠ¶æ€
        instance.overall_status = OverallTestStatus::NotTested;
        instance.last_updated_time = Utc::now();
        instance.start_time = None;
        instance.final_test_time = None;
        instance.total_test_duration_ms = None;
        instance.error_message = None;
        instance.sub_test_results.clear();
        instance.hardpoint_readings = None;
        instance.manual_test_current_value_input = None;
        instance.manual_test_current_value_output = None;
        
        // ä¿å­˜æ›´æ–°åçš„å®ä¾‹
        self.runtime_repo
            .save_channel_instance(&instance)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?;
        
        // åˆ›å»ºçŠ¶æ€è½¬æ¢è®°å½•
        let transition = self.create_transition(
            instance_id,
            old_status,
            OverallTestStatus::NotTested,
            "é‡ç½®è¿›è¡Œé‡æµ‹",
        );
        
        // ä¿å­˜è½¬æ¢å†å²
        self.save_transition_history(&transition).await?;
        
        // å‘å¸ƒçŠ¶æ€å˜æ›´äº‹ä»¶
        let event = StateChangeEvent {
            instance_id: instance_id.to_string(),
            old_status,
            new_status: OverallTestStatus::NotTested,
            transition_reason: transition.reason.clone(),
            timestamp: transition.timestamp,
            operator: None,
        };
        self.publish_state_change(event).await?;
        
        Ok(transition)
    }
    
    async fn batch_state_update(&self, updates: Vec<StateUpdateRequest>) -> Result<Vec<StateTransition>, StateError> {
        let mut results = Vec::new();
        
        for update in updates {
            let result = if update.force_transition {
                if let Some(reason) = update.reason {
                    // ä»TestOutcomeä¸­æå–ç›®æ ‡çŠ¶æ€
                    let target_status = match update.outcome.result {
                        TestResult::Passed => OverallTestStatus::TestCompletedPassed,
                        TestResult::Failed => OverallTestStatus::TestCompletedFailed,
                        TestResult::Skipped => OverallTestStatus::Skipped,
                        TestResult::InProgress => OverallTestStatus::HardPointTesting,
                    };
                    self.force_state_transition(&update.instance_id, target_status, reason).await
                } else {
                    self.apply_test_outcome(&update.instance_id, update.outcome).await
                }
            } else {
                self.apply_test_outcome(&update.instance_id, update.outcome).await
            };
            
            match result {
                Ok(transition) => results.push(transition),
                Err(e) => {
                    // è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–æ›´æ–°
                    log::error!("æ‰¹é‡çŠ¶æ€æ›´æ–°å¤±è´¥ - å®ä¾‹ID: {}, é”™è¯¯: {:?}", update.instance_id, e);
                    // å¯ä»¥é€‰æ‹©è¿”å›é”™è¯¯æˆ–ç»§ç»­å¤„ç†
                    return Err(e);
                }
            }
        }
        
        Ok(results)
    }
    
    async fn batch_reset_for_retest(&self, instance_ids: Vec<String>) -> Result<Vec<StateTransition>, StateError> {
        let mut results = Vec::new();
        
        for instance_id in instance_ids {
            match self.reset_for_retest(&instance_id).await {
                Ok(transition) => results.push(transition),
                Err(e) => {
                    log::error!("æ‰¹é‡é‡ç½®å¤±è´¥ - å®ä¾‹ID: {}, é”™è¯¯: {:?}", instance_id, e);
                    return Err(e);
                }
            }
        }
        
        Ok(results)
    }
    
    async fn subscribe_state_changes(&self) -> Result<broadcast::Receiver<StateChangeEvent>, StateError> {
        Ok(self.event_broadcaster.subscribe())
    }
    
    async fn subscribe_instance_changes(&self, instance_id: &str) -> Result<broadcast::Receiver<StateChangeEvent>, StateError> {
        // åˆ›å»ºè¿‡æ»¤ç‰¹å®šå®ä¾‹çš„æ¥æ”¶å™¨
        let receiver = self.event_broadcaster.subscribe();
        Ok(receiver) // å®é™…å®ç°å¯èƒ½éœ€è¦è¿‡æ»¤é€»è¾‘
    }
    
    async fn validate_state_consistency(&self, instance_id: &str) -> Result<StateValidationResult, StateError> {
        let instance = self.runtime_repo
            .get_channel_instance(instance_id)
            .await
            .map_err(|e| StateError::RepositoryError(e.to_string()))?
            .ok_or_else(|| StateError::InstanceNotFound(instance_id.to_string()))?;
        
        let mut issues = Vec::new();
        let mut is_valid = true;
        
        // æ£€æŸ¥çŠ¶æ€ä¸æµ‹è¯•ç»“æœçš„ä¸€è‡´æ€§
        if instance.overall_status == OverallTestStatus::TestCompletedPassed {
            let has_failed_results = instance.sub_test_results.values()
                .any(|result| result.result == TestResult::Failed);
            
            if has_failed_results {
                is_valid = false;
                issues.push(StateValidationIssue {
                    severity: ValidationSeverity::Error,
                    message: "çŠ¶æ€ä¸ºå·²é€šè¿‡ï¼Œä½†å­˜åœ¨å¤±è´¥çš„æµ‹è¯•ç»“æœ".to_string(),
                    field: Some("overall_status".to_string()),
                });
            }
        }
        
        // æ£€æŸ¥æ—¶é—´æˆ³çš„é€»è¾‘æ€§
        if let (Some(start), Some(end)) = (instance.start_time, instance.final_test_time) {
            if start > end {
                is_valid = false;
                issues.push(StateValidationIssue {
                    severity: ValidationSeverity::Error,
                    message: "å¼€å§‹æ—¶é—´æ™šäºç»“æŸæ—¶é—´".to_string(),
                    field: Some("timestamps".to_string()),
                });
            }
        }
        
        let recommendations = if !is_valid {
            vec!["å»ºè®®é‡ç½®å®ä¾‹çŠ¶æ€å¹¶é‡æ–°è¿›è¡Œæµ‹è¯•".to_string()]
        } else {
            vec![]
        };
        
        Ok(StateValidationResult {
            is_valid,
            issues,
            recommendations,
        })
    }
    
    async fn audit_state_changes(&self, from_time: DateTime<Utc>, to_time: DateTime<Utc>) -> Result<Vec<StateAuditRecord>, StateError> {
        let transitions = self.state_transitions.read().await;
        let mut audit_records = Vec::new();
        
        for (instance_id, instance_transitions) in transitions.iter() {
            for transition in instance_transitions {
                if transition.timestamp >= from_time && transition.timestamp <= to_time {
                    audit_records.push(StateAuditRecord {
                        instance_id: instance_id.clone(),
                        transition: transition.clone(),
                        context: StateAuditContext {
                            user_id: None, // å¯ä»¥ä»ä¸Šä¸‹æ–‡ä¸­è·å–
                            operation_id: transition.transition_id.clone(),
                            client_info: None,
                        },
                    });
                }
            }
        }
        
        // æŒ‰æ—¶é—´æ’åº
        audit_records.sort_by(|a, b| a.transition.timestamp.cmp(&b.transition.timestamp));
        
        Ok(audit_records)
    }
}

/// çŠ¶æ€è½¬æ¢è§„åˆ™
pub struct StateTransitionRules {
    valid_transitions: HashMap<OverallTestStatus, Vec<OverallTestStatus>>,
}

impl StateTransitionRules {
    pub fn new() -> Self {
        let mut valid_transitions = HashMap::new();
        
        // å®šä¹‰åˆæ³•çš„çŠ¶æ€è½¬æ¢
        valid_transitions.insert(
            OverallTestStatus::NotTested,
            vec![
                OverallTestStatus::WiringConfirmed,
                OverallTestStatus::HardPointTesting,
                OverallTestStatus::Skipped,
            ],
        );
        
        valid_transitions.insert(
            OverallTestStatus::WiringConfirmed,
            vec![
                OverallTestStatus::HardPointTesting,
                OverallTestStatus::Skipped,
            ],
        );
        
        valid_transitions.insert(
            OverallTestStatus::HardPointTesting,
            vec![
                OverallTestStatus::ManualTesting,
                OverallTestStatus::TestCompletedPassed,
                OverallTestStatus::TestCompletedFailed,
                OverallTestStatus::NotTested, // é‡æµ‹
            ],
        );
        
        valid_transitions.insert(
            OverallTestStatus::ManualTesting,
            vec![
                OverallTestStatus::TestCompletedPassed,
                OverallTestStatus::TestCompletedFailed,
                OverallTestStatus::NotTested, // é‡æµ‹
            ],
        );
        
        valid_transitions.insert(
            OverallTestStatus::TestCompletedPassed,
            vec![
                OverallTestStatus::NotTested, // é‡æµ‹
            ],
        );
        
        valid_transitions.insert(
            OverallTestStatus::TestCompletedFailed,
            vec![
                OverallTestStatus::NotTested, // é‡æµ‹
            ],
        );
        
        valid_transitions.insert(
            OverallTestStatus::Skipped,
            vec![
                OverallTestStatus::NotTested, // é‡æµ‹
                OverallTestStatus::HardPointTesting,
            ],
        );
        
        Self { valid_transitions }
    }
    
    pub fn is_valid_transition(
        &self,
        from: OverallTestStatus,
        to: OverallTestStatus,
    ) -> Result<bool, StateError> {
        if let Some(allowed_transitions) = self.valid_transitions.get(&from) {
            Ok(allowed_transitions.contains(&to))
        } else {
            Ok(false)
        }
    }
}
```

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

##### 2.1.3 çŠ¶æ€ç®¡ç†å™¨æµ‹è¯•
```rust
// src/services/state_management/tests/channel_state_manager_tests.rs
use super::super::*;
use crate::repositories::runtime_repository::MemoryRuntimeRepository;
use crate::repositories::persistent_repository::MemoryPersistentRepository;
use tokio;

struct StateManagerTestSuite;

impl StateManagerTestSuite {
    async fn create_test_state_manager() -> EnhancedChannelStateManager {
        let runtime_repo = Arc::new(MemoryRuntimeRepository::new());
        let persistent_repo = Arc::new(MemoryPersistentRepository::new());
        EnhancedChannelStateManager::new(runtime_repo, persistent_repo)
    }
    
    async fn create_test_instance(manager: &EnhancedChannelStateManager) -> String {
        let instance = ChannelTestInstance {
            instance_id: uuid::Uuid::new_v4().to_string(),
            definition_id: uuid::Uuid::new_v4().to_string(),
            test_batch_id: "test_batch".to_string(),
            overall_status: OverallTestStatus::NotTested,
            current_step_details: None,
            error_message: None,
            start_time: None,
            last_updated_time: chrono::Utc::now(),
            final_test_time: None,
            total_test_duration_ms: None,
            sub_test_results: std::collections::HashMap::new(),
            hardpoint_readings: None,
            manual_test_current_value_input: None,
            manual_test_current_value_output: None,
        };
        
        let instance_id = instance.instance_id.clone();
        manager.runtime_repo
            .save_channel_instance(&instance)
            .await
            .expect("ä¿å­˜æµ‹è¯•å®ä¾‹å¤±è´¥");
        
        instance_id
    }
}

#[tokio::test]
async fn test_state_manager_basic_operations() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // æµ‹è¯•è·å–å½“å‰çŠ¶æ€
    let current_state = manager.get_current_state(&instance_id).await.expect("è·å–çŠ¶æ€å¤±è´¥");
    assert_eq!(current_state.overall_status, OverallTestStatus::NotTested, "åˆå§‹çŠ¶æ€åº”è¯¥æ˜¯æœªæµ‹è¯•");
    
    // æµ‹è¯•çŠ¶æ€è½¬æ¢éªŒè¯
    let can_transition = manager.can_transition_to(&instance_id, OverallTestStatus::HardPointTesting).await.expect("è½¬æ¢éªŒè¯å¤±è´¥");
    assert!(can_transition, "åº”è¯¥å…è®¸ä»æœªæµ‹è¯•è½¬æ¢åˆ°ç¡¬ç‚¹æµ‹è¯•");
    
    let cannot_transition = manager.can_transition_to(&instance_id, OverallTestStatus::TestCompletedPassed).await.expect("è½¬æ¢éªŒè¯å¤±è´¥");
    assert!(!cannot_transition, "ä¸åº”è¯¥å…è®¸ç›´æ¥ä»æœªæµ‹è¯•è½¬æ¢åˆ°æµ‹è¯•é€šè¿‡");
}

#[tokio::test]
async fn test_apply_test_outcome() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // åº”ç”¨ç¡¬ç‚¹æµ‹è¯•ç»“æœ
    let hardpoint_outcome = TestOutcome {
        test_item: SubTestItem::HardPoint,
        result: TestResult::Passed,
        measured_value: Some(50.0),
        expected_value: Some(50.0),
        tolerance: Some(1.0),
        duration_ms: Some(1000),
        error_message: None,
    };
    
    let transition = manager.apply_test_outcome(&instance_id, hardpoint_outcome).await.expect("åº”ç”¨æµ‹è¯•ç»“æœå¤±è´¥");
    assert_eq!(transition.old_status, OverallTestStatus::NotTested, "åŸçŠ¶æ€åº”è¯¥æ˜¯æœªæµ‹è¯•");
    assert_eq!(transition.new_status, OverallTestStatus::HardPointTesting, "æ–°çŠ¶æ€åº”è¯¥æ˜¯ç¡¬ç‚¹æµ‹è¯•ä¸­");
    
    // éªŒè¯çŠ¶æ€å·²æ›´æ–°
    let current_state = manager.get_current_state(&instance_id).await.expect("è·å–çŠ¶æ€å¤±è´¥");
    assert_eq!(current_state.overall_status, OverallTestStatus::HardPointTesting, "çŠ¶æ€åº”è¯¥å·²æ›´æ–°");
}

#[tokio::test]
async fn test_force_state_transition() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // å¼ºåˆ¶çŠ¶æ€è½¬æ¢ï¼ˆè·³è¿‡æ­£å¸¸æµç¨‹ï¼‰
    let transition = manager.force_state_transition(
        &instance_id,
        OverallTestStatus::TestCompletedPassed,
        "ç®¡ç†å‘˜å¼ºåˆ¶å®Œæˆ".to_string(),
    ).await.expect("å¼ºåˆ¶çŠ¶æ€è½¬æ¢å¤±è´¥");
    
    assert_eq!(transition.old_status, OverallTestStatus::NotTested, "åŸçŠ¶æ€åº”è¯¥æ˜¯æœªæµ‹è¯•");
    assert_eq!(transition.new_status, OverallTestStatus::TestCompletedPassed, "æ–°çŠ¶æ€åº”è¯¥æ˜¯æµ‹è¯•é€šè¿‡");
    assert!(transition.reason.contains("å¼ºåˆ¶è½¬æ¢"), "åŸå› åº”è¯¥åŒ…å«å¼ºåˆ¶è½¬æ¢");
}

#[tokio::test]
async fn test_reset_for_retest() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // å…ˆè®¾ç½®ä¸ºå·²å®ŒæˆçŠ¶æ€
    manager.force_state_transition(
        &instance_id,
        OverallTestStatus::TestCompletedPassed,
        "è®¾ç½®ä¸ºå·²å®Œæˆ".to_string(),
    ).await.expect("è®¾ç½®çŠ¶æ€å¤±è´¥");
    
    // é‡ç½®è¿›è¡Œé‡æµ‹
    let transition = manager.reset_for_retest(&instance_id).await.expect("é‡ç½®å¤±è´¥");
    assert_eq!(transition.new_status, OverallTestStatus::NotTested, "é‡ç½®åçŠ¶æ€åº”è¯¥æ˜¯æœªæµ‹è¯•");
    
    // éªŒè¯å®ä¾‹æ•°æ®å·²æ¸…ç†
    let instance = manager.runtime_repo
        .get_channel_instance(&instance_id)
        .await
        .expect("è·å–å®ä¾‹å¤±è´¥")
        .expect("å®ä¾‹åº”è¯¥å­˜åœ¨");
    
    assert!(instance.sub_test_results.is_empty(), "æµ‹è¯•ç»“æœåº”è¯¥å·²æ¸…ç©º");
    assert!(instance.start_time.is_none(), "å¼€å§‹æ—¶é—´åº”è¯¥å·²æ¸…ç©º");
    assert!(instance.error_message.is_none(), "é”™è¯¯ä¿¡æ¯åº”è¯¥å·²æ¸…ç©º");
}

#[tokio::test]
async fn test_batch_operations() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    
    // åˆ›å»ºå¤šä¸ªæµ‹è¯•å®ä¾‹
    let instance_ids: Vec<String> = (0..3).map(|_| {
        futures::executor::block_on(StateManagerTestSuite::create_test_instance(&manager))
    }).collect();
    
    // å‡†å¤‡æ‰¹é‡æ›´æ–°è¯·æ±‚
    let updates: Vec<StateUpdateRequest> = instance_ids.iter().map(|id| {
        StateUpdateRequest {
            instance_id: id.clone(),
            outcome: TestOutcome {
                test_item: SubTestItem::HardPoint,
                result: TestResult::Passed,
                measured_value: Some(25.0),
                expected_value: Some(25.0),
                tolerance: Some(1.0),
                duration_ms: Some(500),
                error_message: None,
            },
            force_transition: false,
            reason: None,
        }
    }).collect();
    
    // æ‰§è¡Œæ‰¹é‡æ›´æ–°
    let transitions = manager.batch_state_update(updates).await.expect("æ‰¹é‡æ›´æ–°å¤±è´¥");
    assert_eq!(transitions.len(), 3, "åº”è¯¥æœ‰3ä¸ªçŠ¶æ€è½¬æ¢");
    
    // éªŒè¯æ‰€æœ‰å®ä¾‹çŠ¶æ€éƒ½å·²æ›´æ–°
    for instance_id in &instance_ids {
        let state = manager.get_current_state(instance_id).await.expect("è·å–çŠ¶æ€å¤±è´¥");
        assert_eq!(state.overall_status, OverallTestStatus::HardPointTesting, "çŠ¶æ€åº”è¯¥å·²æ›´æ–°");
    }
    
    // æµ‹è¯•æ‰¹é‡é‡ç½®
    let reset_transitions = manager.batch_reset_for_retest(instance_ids.clone()).await.expect("æ‰¹é‡é‡ç½®å¤±è´¥");
    assert_eq!(reset_transitions.len(), 3, "åº”è¯¥æœ‰3ä¸ªé‡ç½®è½¬æ¢");
    
    // éªŒè¯æ‰€æœ‰å®ä¾‹éƒ½å·²é‡ç½®
    for instance_id in &instance_ids {
        let state = manager.get_current_state(instance_id).await.expect("è·å–çŠ¶æ€å¤±è´¥");
        assert_eq!(state.overall_status, OverallTestStatus::NotTested, "çŠ¶æ€åº”è¯¥å·²é‡ç½®");
    }
}

#[tokio::test]
async fn test_state_events() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // è®¢é˜…çŠ¶æ€å˜æ›´äº‹ä»¶
    let mut event_receiver = manager.subscribe_state_changes().await.expect("è®¢é˜…äº‹ä»¶å¤±è´¥");
    
    // åœ¨å¦ä¸€ä¸ªä»»åŠ¡ä¸­ç›‘å¬äº‹ä»¶
    let event_listener = tokio::spawn(async move {
        match tokio::time::timeout(std::time::Duration::from_secs(5), event_receiver.recv()).await {
            Ok(Ok(event)) => Some(event),
            _ => None,
        }
    });
    
    // è§¦å‘çŠ¶æ€å˜æ›´
    let outcome = TestOutcome {
        test_item: SubTestItem::HardPoint,
        result: TestResult::Passed,
        measured_value: Some(75.0),
        expected_value: Some(75.0),
        tolerance: Some(1.0),
        duration_ms: Some(800),
        error_message: None,
    };
    
    manager.apply_test_outcome(&instance_id, outcome).await.expect("åº”ç”¨æµ‹è¯•ç»“æœå¤±è´¥");
    
    // éªŒè¯äº‹ä»¶å·²å‘å¸ƒ
    let received_event = event_listener.await.expect("äº‹ä»¶ç›‘å¬ä»»åŠ¡å¤±è´¥");
    assert!(received_event.is_some(), "åº”è¯¥æ¥æ”¶åˆ°çŠ¶æ€å˜æ›´äº‹ä»¶");
    
    let event = received_event.unwrap();
    assert_eq!(event.instance_id, instance_id, "äº‹ä»¶å®ä¾‹IDåº”è¯¥åŒ¹é…");
    assert_eq!(event.old_status, OverallTestStatus::NotTested, "äº‹ä»¶åŸçŠ¶æ€åº”è¯¥åŒ¹é…");
    assert_eq!(event.new_status, OverallTestStatus::HardPointTesting, "äº‹ä»¶æ–°çŠ¶æ€åº”è¯¥åŒ¹é…");
}

#[tokio::test]
async fn test_state_validation() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // åˆ›å»ºä¸ä¸€è‡´çš„çŠ¶æ€ï¼ˆå¼ºåˆ¶è®¾ç½®ä¸ºé€šè¿‡ï¼Œä½†æ·»åŠ å¤±è´¥çš„æµ‹è¯•ç»“æœï¼‰
    manager.force_state_transition(
        &instance_id,
        OverallTestStatus::TestCompletedPassed,
        "æµ‹è¯•è®¾ç½®".to_string(),
    ).await.expect("å¼ºåˆ¶è½¬æ¢å¤±è´¥");
    
    // æ‰‹åŠ¨æ·»åŠ å¤±è´¥çš„æµ‹è¯•ç»“æœæ¥åˆ¶é€ ä¸ä¸€è‡´
    let mut instance = manager.runtime_repo
        .get_channel_instance(&instance_id)
        .await
        .expect("è·å–å®ä¾‹å¤±è´¥")
        .expect("å®ä¾‹åº”è¯¥å­˜åœ¨");
    
    instance.sub_test_results.insert(SubTestItem::HardPoint, SubTestExecutionResult {
        result: TestResult::Failed,
        measured_value: Some(10.0),
        expected_value: Some(50.0),
        tolerance: Some(1.0),
        timestamp: chrono::Utc::now(),
        error_message: Some("æµ‹è¯•å¤±è´¥".to_string()),
        duration_ms: Some(1000),
    });
    
    manager.runtime_repo
        .save_channel_instance(&instance)
        .await
        .expect("ä¿å­˜å®ä¾‹å¤±è´¥");
    
    // éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
    let validation_result = manager.validate_state_consistency(&instance_id).await.expect("çŠ¶æ€éªŒè¯å¤±è´¥");
    assert!(!validation_result.is_valid, "çŠ¶æ€åº”è¯¥è¢«æ£€æµ‹ä¸ºä¸ä¸€è‡´");
    assert!(!validation_result.issues.is_empty(), "åº”è¯¥æœ‰éªŒè¯é—®é¢˜");
    assert!(!validation_result.recommendations.is_empty(), "åº”è¯¥æœ‰ä¿®å¤å»ºè®®");
}

#[tokio::test]
async fn test_transition_history() {
    let manager = StateManagerTestSuite::create_test_state_manager().await;
    let instance_id = StateManagerTestSuite::create_test_instance(&manager).await;
    
    // æ‰§è¡Œå¤šæ¬¡çŠ¶æ€è½¬æ¢
    let outcome1 = TestOutcome {
        test_item: SubTestItem::HardPoint,
        result: TestResult::InProgress,
        measured_value: None,
        expected_value: None,
        tolerance: None,
        duration_ms: None,
        error_message: None,
    };
    
    manager.apply_test_outcome(&instance_id, outcome1).await.expect("ç¬¬ä¸€æ¬¡è½¬æ¢å¤±è´¥");
    
    let outcome2 = TestOutcome {
        test_item: SubTestItem::HardPoint,
        result: TestResult::Passed,
        measured_value: Some(50.0),
        expected_value: Some(50.0),
        tolerance: Some(1.0),
        duration_ms: Some(1000),
        error_message: None,
    };
    
    manager.apply_test_outcome(&instance_id, outcome2).await.expect("ç¬¬äºŒæ¬¡è½¬æ¢å¤±è´¥");
    
    // è·å–è½¬æ¢å†å²
    let history = manager.get_transition_history(&instance_id).await.expect("è·å–å†å²å¤±è´¥");
    assert_eq!(history.len(), 2, "åº”è¯¥æœ‰2ä¸ªçŠ¶æ€è½¬æ¢è®°å½•");
    
    // éªŒè¯è½¬æ¢é¡ºåº
    assert_eq!(history[0].old_status, OverallTestStatus::NotTested, "ç¬¬ä¸€æ¬¡è½¬æ¢çš„åŸçŠ¶æ€");
    assert_eq!(history[0].new_status, OverallTestStatus::HardPointTesting, "ç¬¬ä¸€æ¬¡è½¬æ¢çš„æ–°çŠ¶æ€");
    assert_eq!(history[1].old_status, OverallTestStatus::HardPointTesting, "ç¬¬äºŒæ¬¡è½¬æ¢çš„åŸçŠ¶æ€");
}

/// å‹åŠ›æµ‹è¯•
#[tokio::test]
async fn test_concurrent_state_operations() {
    let manager = Arc::new(StateManagerTestSuite::create_test_state_manager().await);
    
    // åˆ›å»ºå¤šä¸ªå®ä¾‹
    let instance_ids: Vec<String> = (0..100).map(|_| {
        futures::executor::block_on(StateManagerTestSuite::create_test_instance(&manager))
    }).collect();
    
    // å¹¶å‘æ‰§è¡ŒçŠ¶æ€æ“ä½œ
    let tasks: Vec<_> = instance_ids.into_iter().map(|instance_id| {
        let manager_clone = manager.clone();
        tokio::spawn(async move {
            let outcome = TestOutcome {
                test_item: SubTestItem::HardPoint,
                result: TestResult::Passed,
                measured_value: Some(50.0),
                expected_value: Some(50.0),
                tolerance: Some(1.0),
                duration_ms: Some(1000),
                error_message: None,
            };
            
            manager_clone.apply_test_outcome(&instance_id, outcome).await
        })
    }).collect();
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let results = futures::future::join_all(tasks).await;
    
    // éªŒè¯æ‰€æœ‰æ“ä½œéƒ½æˆåŠŸ
    for result in results {
        assert!(result.expect("ä»»åŠ¡åº”è¯¥æˆåŠŸ").is_ok(), "æ‰€æœ‰çŠ¶æ€æ“ä½œéƒ½åº”è¯¥æˆåŠŸ");
    }
}
```

### âœ… æ­¥éª¤2.1å®Œæˆæ ‡å‡†

1. **æ¥å£å®Œæ•´æ€§**: æ‰€æœ‰IChannelStateManageræ–¹æ³•éƒ½æœ‰å®Œæ•´å®ç°
2. **çŠ¶æ€ä¸€è‡´æ€§**: ä¸¥æ ¼çš„çŠ¶æ€è½¬æ¢è§„åˆ™å’ŒéªŒè¯æœºåˆ¶
3. **äº‹ä»¶æœºåˆ¶**: å®Œæ•´çš„çŠ¶æ€å˜æ›´äº‹ä»¶å‘å¸ƒå’Œè®¢é˜…
4. **å¹¶å‘å®‰å…¨**: æ”¯æŒé«˜å¹¶å‘çš„çŠ¶æ€æ“ä½œ
5. **å®¡è®¡è·Ÿè¸ª**: å®Œæ•´çš„çŠ¶æ€å˜æ›´å†å²è®°å½•

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...* 

## ğŸš€ Phase 3: ä»»åŠ¡è°ƒåº¦å™¨é‡æ„

### æ­¥éª¤ 3.1: åˆ›å»ºé«˜çº§ä»»åŠ¡è°ƒåº¦å™¨

#### ğŸ¯ ç›®æ ‡
åŸºäºåŸæœ‰C#ä»£ç é€»è¾‘ï¼Œè®¾è®¡æ›´ç¨³å®šå¯é çš„ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œå¼•æ“ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 3.1.1 å®šä¹‰ä»»åŠ¡è°ƒåº¦å™¨æ ¸å¿ƒæ¥å£
```rust
// src/services/task_scheduling/task_scheduler.rs
use async_trait::async_trait;
use crate::models::structs::{TestTask, TaskHandle, TaskInfo, BatchProgress};
use crate::models::enums::{TaskStatus, TaskPriority};
use crate::models::errors::SchedulerError;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{Semaphore, RwLock, broadcast};
use chrono::{DateTime, Utc};

/// é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨æ¥å£
#[async_trait]
pub trait ITaskScheduler: Send + Sync {
    // ä»»åŠ¡è°ƒåº¦
    async fn schedule_test_task(&self, task: TestTask) -> Result<TaskHandle, SchedulerError>;
    async fn schedule_batch_tasks(&self, batch_id: &str, tasks: Vec<TestTask>) -> Result<Vec<TaskHandle>, SchedulerError>;
    async fn schedule_priority_task(&self, task: TestTask, priority: TaskPriority) -> Result<TaskHandle, SchedulerError>;
    
    // ä»»åŠ¡æ§åˆ¶
    async fn pause_task(&self, task_handle: TaskHandle) -> Result<(), SchedulerError>;
    async fn resume_task(&self, task_handle: TaskHandle) -> Result<(), SchedulerError>;
    async fn cancel_task(&self, task_handle: TaskHandle) -> Result<(), SchedulerError>;
    async fn retry_task(&self, task_handle: TaskHandle) -> Result<TaskHandle, SchedulerError>;
    
    // æ‰¹æ¬¡æ§åˆ¶ (å‚è€ƒåŸæœ‰C#é€»è¾‘)
    async fn pause_batch(&self, batch_id: &str) -> Result<(), SchedulerError>;
    async fn resume_batch(&self, batch_id: &str) -> Result<(), SchedulerError>;
    async fn cancel_batch(&self, batch_id: &str) -> Result<(), SchedulerError>;
    async fn restart_batch(&self, batch_id: &str) -> Result<(), SchedulerError>;
    
    // çŠ¶æ€æŸ¥è¯¢
    async fn get_task_status(&self, task_handle: TaskHandle) -> Result<TaskStatus, SchedulerError>;
    async fn get_task_info(&self, task_handle: TaskHandle) -> Result<TaskInfo, SchedulerError>;
    async fn get_batch_progress(&self, batch_id: &str) -> Result<BatchProgress, SchedulerError>;
    async fn list_active_tasks(&self) -> Result<Vec<TaskInfo>, SchedulerError>;
    async fn list_batch_tasks(&self, batch_id: &str) -> Result<Vec<TaskInfo>, SchedulerError>;
    
    // èµ„æºç®¡ç†
    async fn set_concurrency_limit(&self, limit: usize) -> Result<(), SchedulerError>;
    async fn get_system_load(&self) -> Result<SystemLoad, SchedulerError>;
    async fn get_resource_usage(&self) -> Result<ResourceUsage, SchedulerError>;
    
    // å¥åº·æ£€æŸ¥å’Œç›‘æ§
    async fn health_check(&self) -> Result<SchedulerHealth, SchedulerError>;
    async fn get_performance_metrics(&self) -> Result<PerformanceMetrics, SchedulerError>;
    
    // äº‹ä»¶è®¢é˜…
    async fn subscribe_task_events(&self) -> Result<broadcast::Receiver<TaskEvent>, SchedulerError>;
    async fn subscribe_batch_events(&self) -> Result<broadcast::Receiver<BatchEvent>, SchedulerError>;
}
```

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

##### 3.1.2 å®šä¹‰ä»»åŠ¡è°ƒåº¦å™¨æ•°æ®ç»“æ„
```rust
/// æµ‹è¯•ä»»åŠ¡å®šä¹‰
#[derive(Debug, Clone)]
pub struct TestTask {
    pub task_id: String,
    pub instance_id: String,
    pub definition_id: String,
    pub batch_id: String,
    pub test_items: Vec<SubTestItem>,
    pub priority: TaskPriority,
    pub retry_count: u32,
    pub max_retries: u32,
    pub timeout_ms: Option<u64>,
    pub dependencies: Vec<String>, // ä¾èµ–çš„ä»»åŠ¡ID
    pub metadata: HashMap<String, String>,
}

/// ä»»åŠ¡å¥æŸ„
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct TaskHandle {
    pub id: u64,
}

/// ä»»åŠ¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct TaskInfo {
    pub handle: TaskHandle,
    pub task: TestTask,
    pub status: TaskStatus,
    pub created_at: DateTime<Utc>,
    pub started_at: Option<DateTime<Utc>>,
    pub completed_at: Option<DateTime<Utc>>,
    pub error_message: Option<String>,
    pub progress_percentage: f64,
    pub resource_usage: TaskResourceUsage,
}

/// æ‰¹æ¬¡è¿›åº¦
#[derive(Debug, Clone)]
pub struct BatchProgress {
    pub batch_id: String,
    pub total_tasks: usize,
    pub pending_tasks: usize,
    pub running_tasks: usize,
    pub completed_tasks: usize,
    pub failed_tasks: usize,
    pub cancelled_tasks: usize,
    pub progress_percentage: f64,
    pub estimated_completion_time: Option<DateTime<Utc>>,
}

/// ç³»ç»Ÿè´Ÿè½½ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct SystemLoad {
    pub active_tasks: usize,
    pub pending_tasks: usize,
    pub cpu_usage_percentage: f64,
    pub memory_usage_bytes: usize,
    pub available_slots: usize,
}

/// èµ„æºä½¿ç”¨æƒ…å†µ
#[derive(Debug, Clone)]
pub struct ResourceUsage {
    pub total_memory_bytes: usize,
    pub used_memory_bytes: usize,
    pub active_connections: usize,
    pub thread_pool_usage: f64,
}

/// è°ƒåº¦å™¨å¥åº·çŠ¶æ€
#[derive(Debug, Clone)]
pub struct SchedulerHealth {
    pub is_healthy: bool,
    pub uptime_seconds: u64,
    pub total_tasks_processed: u64,
    pub error_rate_percentage: f64,
    pub average_task_duration_ms: f64,
    pub issues: Vec<HealthIssue>,
}

/// æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    pub tasks_per_second: f64,
    pub average_queue_time_ms: f64,
    pub average_execution_time_ms: f64,
    pub success_rate_percentage: f64,
    pub retry_rate_percentage: f64,
}

/// ä»»åŠ¡äº‹ä»¶
#[derive(Debug, Clone)]
pub struct TaskEvent {
    pub task_handle: TaskHandle,
    pub event_type: TaskEventType,
    pub timestamp: DateTime<Utc>,
    pub details: Option<String>,
}

/// æ‰¹æ¬¡äº‹ä»¶
#[derive(Debug, Clone)]
pub struct BatchEvent {
    pub batch_id: String,
    pub event_type: BatchEventType,
    pub timestamp: DateTime<Utc>,
    pub details: Option<String>,
}

#[derive(Debug, Clone)]
pub enum TaskEventType {
    Scheduled,
    Started,
    Completed,
    Failed,
    Cancelled,
    Paused,
    Resumed,
    Retrying,
}

#[derive(Debug, Clone)]
pub enum BatchEventType {
    Started,
    Completed,
    Paused,
    Resumed,
    Cancelled,
    ProgressUpdated,
}
```

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

##### 3.1.3 å®ç°é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨ (Part 1)
```rust
// src/services/task_scheduling/advanced_task_scheduler.rs
use super::*;
use crate::services::test_execution::ITestExecutor;
use crate::services::state_management::IChannelStateManager;
use crate::repositories::IRuntimeRepository;
use std::collections::{HashMap, VecDeque, BinaryHeap};
use std::cmp::Reverse;
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use tokio::sync::Mutex;
use tokio::time::{Duration, Instant};

/// é«˜çº§ä»»åŠ¡è°ƒåº¦å™¨å®ç°
/// å‚è€ƒåŸæœ‰C#ä»£ç ä¸­çš„TestTaskManageré€»è¾‘è¿›è¡Œä¼˜åŒ–
pub struct AdvancedTaskScheduler {
    // æ ¸å¿ƒç»„ä»¶
    state_manager: Arc<dyn IChannelStateManager>,
    runtime_repo: Arc<dyn IRuntimeRepository>,
    test_executors: HashMap<SubTestItem, Arc<dyn ITestExecutor>>,
    
    // ä»»åŠ¡ç®¡ç†
    task_queue: Arc<Mutex<PriorityQueue<ScheduledTask>>>,
    active_tasks: Arc<RwLock<HashMap<TaskHandle, RunningTask>>>,
    completed_tasks: Arc<RwLock<HashMap<TaskHandle, CompletedTask>>>,
    batch_tasks: Arc<RwLock<HashMap<String, Vec<TaskHandle>>>>,
    
    // èµ„æºæ§åˆ¶
    concurrency_semaphore: Arc<Semaphore>,
    max_concurrent_tasks: AtomicUsize,
    
    // çŠ¶æ€ç»Ÿè®¡
    next_task_id: AtomicU64,
    total_tasks_processed: AtomicU64,
    startup_time: Instant,
    
    // äº‹ä»¶å‘å¸ƒ
    task_event_broadcaster: broadcast::Sender<TaskEvent>,
    batch_event_broadcaster: broadcast::Sender<BatchEvent>,
    
    // é‡è¯•ç­–ç•¥
    retry_policy: Arc<dyn IRetryPolicy>,
    
    // å¥åº·ç›‘æ§
    health_monitor: Arc<HealthMonitor>,
}

/// è°ƒåº¦ä»»åŠ¡åŒ…è£…å™¨
#[derive(Debug, Clone)]
struct ScheduledTask {
    handle: TaskHandle,
    task: TestTask,
    scheduled_at: DateTime<Utc>,
    retry_attempt: u32,
}

/// è¿è¡Œä¸­ä»»åŠ¡
#[derive(Debug, Clone)]
struct RunningTask {
    info: TaskInfo,
    started_at: Instant,
    abort_handle: Option<tokio::task::AbortHandle>,
}

/// å·²å®Œæˆä»»åŠ¡
#[derive(Debug, Clone)]
struct CompletedTask {
    info: TaskInfo,
    result: TaskResult,
}

/// ä¼˜å…ˆçº§é˜Ÿåˆ—å®ç°
struct PriorityQueue<T> {
    heap: BinaryHeap<Reverse<PrioritizedItem<T>>>,
}

#[derive(Debug, Clone)]
struct PrioritizedItem<T> {
    priority: TaskPriority,
    created_at: DateTime<Utc>,
    item: T,
}

impl<T> Ord for PrioritizedItem<T> {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.priority.cmp(&other.priority)
            .then_with(|| self.created_at.cmp(&other.created_at))
    }
}

impl<T> PartialOrd for PrioritizedItem<T> {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl<T> PartialEq for PrioritizedItem<T> {
    fn eq(&self, other: &Self) -> bool {
        self.priority == other.priority && self.created_at == other.created_at
    }
}

impl<T> Eq for PrioritizedItem<T> {}

impl AdvancedTaskScheduler {
    pub fn new(
        state_manager: Arc<dyn IChannelStateManager>,
        runtime_repo: Arc<dyn IRuntimeRepository>,
        test_executors: HashMap<SubTestItem, Arc<dyn ITestExecutor>>,
        max_concurrent_tasks: usize,
    ) -> Self {
        let (task_event_broadcaster, _) = broadcast::channel(1000);
        let (batch_event_broadcaster, _) = broadcast::channel(1000);
        
        Self {
            state_manager,
            runtime_repo,
            test_executors,
            task_queue: Arc::new(Mutex::new(PriorityQueue::new())),
            active_tasks: Arc::new(RwLock::new(HashMap::new())),
            completed_tasks: Arc::new(RwLock::new(HashMap::new())),
            batch_tasks: Arc::new(RwLock::new(HashMap::new())),
            concurrency_semaphore: Arc::new(Semaphore::new(max_concurrent_tasks)),
            max_concurrent_tasks: AtomicUsize::new(max_concurrent_tasks),
            next_task_id: AtomicU64::new(1),
            total_tasks_processed: AtomicU64::new(0),
            startup_time: Instant::now(),
            task_event_broadcaster,
            batch_event_broadcaster,
            retry_policy: Arc::new(DefaultRetryPolicy::new()),
            health_monitor: Arc::new(HealthMonitor::new()),
        }
    }
    
    /// å¯åŠ¨è°ƒåº¦å™¨å·¥ä½œå¾ªç¯
    pub async fn start(&self) -> Result<(), SchedulerError> {
        let scheduler = Arc::new(self);
        
        // å¯åŠ¨ä»»åŠ¡å¤„ç†å¾ªç¯
        let task_processor = scheduler.clone();
        tokio::spawn(async move {
            task_processor.task_processing_loop().await;
        });
        
        // å¯åŠ¨å¥åº·ç›‘æ§
        let health_monitor = scheduler.clone();
        tokio::spawn(async move {
            health_monitor.health_monitoring_loop().await;
        });
        
        Ok(())
    }
}
```

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

##### 3.1.4 ä»»åŠ¡è°ƒåº¦å™¨æ¥å£å®ç° (Part 2)
```rust
#[async_trait]
impl ITaskScheduler for AdvancedTaskScheduler {
    async fn schedule_test_task(&self, task: TestTask) -> Result<TaskHandle, SchedulerError> {
        let task_handle = TaskHandle {
            id: self.next_task_id.fetch_add(1, Ordering::Relaxed),
        };
        
        let scheduled_task = ScheduledTask {
            handle: task_handle,
            task: task.clone(),
            scheduled_at: Utc::now(),
            retry_attempt: 0,
        };
        
        // æ·»åŠ åˆ°é˜Ÿåˆ—
        {
            let mut queue = self.task_queue.lock().await;
            queue.push(scheduled_task);
        }
        
        // æ·»åŠ åˆ°æ‰¹æ¬¡æ˜ å°„
        {
            let mut batch_tasks = self.batch_tasks.write().await;
            batch_tasks.entry(task.batch_id.clone())
                .or_insert_with(Vec::new)
                .push(task_handle);
        }
        
        // å‘å¸ƒè°ƒåº¦äº‹ä»¶
        let _ = self.task_event_broadcaster.send(TaskEvent {
            task_handle,
            event_type: TaskEventType::Scheduled,
            timestamp: Utc::now(),
            details: None,
        });
        
        Ok(task_handle)
    }
    
    async fn schedule_batch_tasks(&self, batch_id: &str, tasks: Vec<TestTask>) -> Result<Vec<TaskHandle>, SchedulerError> {
        let mut handles = Vec::new();
        
        for task in tasks {
            let handle = self.schedule_test_task(task).await?;
            handles.push(handle);
        }
        
        // å‘å¸ƒæ‰¹æ¬¡å¼€å§‹äº‹ä»¶
        let _ = self.batch_event_broadcaster.send(BatchEvent {
            batch_id: batch_id.to_string(),
            event_type: BatchEventType::Started,
            timestamp: Utc::now(),
            details: Some(format!("æ‰¹æ¬¡å¼€å§‹ï¼ŒåŒ…å« {} ä¸ªä»»åŠ¡", handles.len())),
        });
        
        Ok(handles)
    }
    
    async fn schedule_priority_task(&self, mut task: TestTask, priority: TaskPriority) -> Result<TaskHandle, SchedulerError> {
        task.priority = priority;
        self.schedule_test_task(task).await
    }
    
    async fn pause_task(&self, task_handle: TaskHandle) -> Result<(), SchedulerError> {
        let mut active_tasks = self.active_tasks.write().await;
        if let Some(running_task) = active_tasks.get_mut(&task_handle) {
            running_task.info.status = TaskStatus::Paused;
            
            // å‘å¸ƒæš‚åœäº‹ä»¶
            let _ = self.task_event_broadcaster.send(TaskEvent {
                task_handle,
                event_type: TaskEventType::Paused,
                timestamp: Utc::now(),
                details: None,
            });
            
            Ok(())
        } else {
            Err(SchedulerError::TaskNotFound(task_handle))
        }
    }
    
    async fn resume_task(&self, task_handle: TaskHandle) -> Result<(), SchedulerError> {
        let mut active_tasks = self.active_tasks.write().await;
        if let Some(running_task) = active_tasks.get_mut(&task_handle) {
            running_task.info.status = TaskStatus::Running;
            
            // å‘å¸ƒæ¢å¤äº‹ä»¶
            let _ = self.task_event_broadcaster.send(TaskEvent {
                task_handle,
                event_type: TaskEventType::Resumed,
                timestamp: Utc::now(),
                details: None,
            });
            
            Ok(())
        } else {
            Err(SchedulerError::TaskNotFound(task_handle))
        }
    }
    
    async fn cancel_task(&self, task_handle: TaskHandle) -> Result<(), SchedulerError> {
        // é¦–å…ˆå°è¯•ä»é˜Ÿåˆ—ä¸­ç§»é™¤
        {
            let mut queue = self.task_queue.lock().await;
            if queue.remove_by_handle(task_handle) {
                // ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œç›´æ¥ç§»é™¤
                let _ = self.task_event_broadcaster.send(TaskEvent {
                    task_handle,
                    event_type: TaskEventType::Cancelled,
                    timestamp: Utc::now(),
                    details: Some("ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­è¢«å–æ¶ˆ".to_string()),
                });
                return Ok(());
            }
        }
        
        // å°è¯•å–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        let mut active_tasks = self.active_tasks.write().await;
        if let Some(running_task) = active_tasks.remove(&task_handle) {
            if let Some(abort_handle) = running_task.abort_handle {
                abort_handle.abort();
            }
            
            // å‘å¸ƒå–æ¶ˆäº‹ä»¶
            let _ = self.task_event_broadcaster.send(TaskEvent {
                task_handle,
                event_type: TaskEventType::Cancelled,
                timestamp: Utc::now(),
                details: Some("è¿è¡Œä¸­ä»»åŠ¡è¢«å–æ¶ˆ".to_string()),
            });
            
            Ok(())
        } else {
            Err(SchedulerError::TaskNotFound(task_handle))
        }
    }
    
    async fn retry_task(&self, task_handle: TaskHandle) -> Result<TaskHandle, SchedulerError> {
        // è·å–åŸä»»åŠ¡ä¿¡æ¯
        let completed_tasks = self.completed_tasks.read().await;
        if let Some(completed_task) = completed_tasks.get(&task_handle) {
            let mut new_task = completed_task.info.task.clone();
            new_task.retry_count = 0; // é‡ç½®é‡è¯•è®¡æ•°
            
            drop(completed_tasks);
            self.schedule_test_task(new_task).await
        } else {
            Err(SchedulerError::TaskNotFound(task_handle))
        }
    }
}
```

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

##### 3.1.5 ä»»åŠ¡è°ƒåº¦å™¨æµ‹è¯•
```rust
// src/services/task_scheduling/tests/advanced_task_scheduler_tests.rs
use super::super::*;
use tokio;

struct TaskSchedulerTestSuite;

impl TaskSchedulerTestSuite {
    async fn create_test_scheduler() -> AdvancedTaskScheduler {
        let state_manager = Arc::new(MockChannelStateManager::new());
        let runtime_repo = Arc::new(MockRuntimeRepository::new());
        let test_executors = HashMap::new();
        
        AdvancedTaskScheduler::new(
            state_manager,
            runtime_repo,
            test_executors,
            10, // max concurrent tasks
        )
    }
    
    fn create_test_task(batch_id: &str) -> TestTask {
        TestTask {
            task_id: uuid::Uuid::new_v4().to_string(),
            instance_id: uuid::Uuid::new_v4().to_string(),
            definition_id: uuid::Uuid::new_v4().to_string(),
            batch_id: batch_id.to_string(),
            test_items: vec![SubTestItem::HardPoint],
            priority: TaskPriority::Normal,
            retry_count: 0,
            max_retries: 3,
            timeout_ms: Some(30000),
            dependencies: vec![],
            metadata: HashMap::new(),
        }
    }
}

#[tokio::test]
async fn test_task_scheduling_basic() {
    let scheduler = TaskSchedulerTestSuite::create_test_scheduler().await;
    let task = TaskSchedulerTestSuite::create_test_task("test_batch");
    
    // æµ‹è¯•ä»»åŠ¡è°ƒåº¦
    let task_handle = scheduler.schedule_test_task(task).await.expect("è°ƒåº¦ä»»åŠ¡å¤±è´¥");
    assert!(task_handle.id > 0, "ä»»åŠ¡å¥æŸ„IDåº”è¯¥å¤§äº0");
    
    // æµ‹è¯•ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
    let status = scheduler.get_task_status(task_handle).await.expect("è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥");
    assert_eq!(status, TaskStatus::Pending, "æ–°è°ƒåº¦çš„ä»»åŠ¡åº”è¯¥æ˜¯å¾…æ‰§è¡ŒçŠ¶æ€");
}

#[tokio::test]
async fn test_batch_operations() {
    let scheduler = TaskSchedulerTestSuite::create_test_scheduler().await;
    let batch_id = "test_batch_001";
    
    // åˆ›å»ºæ‰¹æ¬¡ä»»åŠ¡
    let tasks = (0..5).map(|_| TaskSchedulerTestSuite::create_test_task(batch_id)).collect();
    let handles = scheduler.schedule_batch_tasks(batch_id, tasks).await.expect("æ‰¹æ¬¡è°ƒåº¦å¤±è´¥");
    
    assert_eq!(handles.len(), 5, "åº”è¯¥è°ƒåº¦5ä¸ªä»»åŠ¡");
    
    // æµ‹è¯•æ‰¹æ¬¡è¿›åº¦æŸ¥è¯¢
    let progress = scheduler.get_batch_progress(batch_id).await.expect("è·å–æ‰¹æ¬¡è¿›åº¦å¤±è´¥");
    assert_eq!(progress.total_tasks, 5, "æ‰¹æ¬¡åº”è¯¥åŒ…å«5ä¸ªä»»åŠ¡");
    assert_eq!(progress.pending_tasks, 5, "åº”è¯¥æœ‰5ä¸ªå¾…æ‰§è¡Œä»»åŠ¡");
    
    // æµ‹è¯•æ‰¹æ¬¡æš‚åœ
    scheduler.pause_batch(batch_id).await.expect("æš‚åœæ‰¹æ¬¡å¤±è´¥");
    
    // æµ‹è¯•æ‰¹æ¬¡æ¢å¤
    scheduler.resume_batch(batch_id).await.expect("æ¢å¤æ‰¹æ¬¡å¤±è´¥");
    
    // æµ‹è¯•æ‰¹æ¬¡å–æ¶ˆ
    scheduler.cancel_batch(batch_id).await.expect("å–æ¶ˆæ‰¹æ¬¡å¤±è´¥");
}

#[tokio::test]
async fn test_concurrent_execution() {
    let scheduler = Arc::new(TaskSchedulerTestSuite::create_test_scheduler().await);
    
    // å¹¶å‘è°ƒåº¦å¤šä¸ªä»»åŠ¡
    let tasks: Vec<_> = (0..20).map(|i| {
        let scheduler_clone = scheduler.clone();
        let task = TaskSchedulerTestSuite::create_test_task(&format!("batch_{}", i % 3));
        tokio::spawn(async move {
            scheduler_clone.schedule_test_task(task).await
        })
    }).collect();
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡è°ƒåº¦å®Œæˆ
    let results = futures::future::join_all(tasks).await;
    
    // éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸè°ƒåº¦
    for result in results {
        assert!(result.expect("ä»»åŠ¡è°ƒåº¦ä»»åŠ¡å¤±è´¥").is_ok(), "æ‰€æœ‰ä»»åŠ¡è°ƒåº¦éƒ½åº”è¯¥æˆåŠŸ");
    }
    
    // æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
    let load = scheduler.get_system_load().await.expect("è·å–ç³»ç»Ÿè´Ÿè½½å¤±è´¥");
    assert!(load.pending_tasks <= 20, "å¾…æ‰§è¡Œä»»åŠ¡æ•°åº”è¯¥ä¸è¶…è¿‡20");
}

#[tokio::test]
async fn test_retry_mechanism() {
    let scheduler = TaskSchedulerTestSuite::create_test_scheduler().await;
    let task = TaskSchedulerTestSuite::create_test_task("retry_test_batch");
    
    // è°ƒåº¦ä»»åŠ¡
    let original_handle = scheduler.schedule_test_task(task).await.expect("è°ƒåº¦ä»»åŠ¡å¤±è´¥");
    
    // æ¨¡æ‹Ÿä»»åŠ¡å®Œæˆï¼ˆè¿™é‡Œéœ€è¦å®é™…çš„æ‰§è¡Œé€»è¾‘ï¼‰
    // åœ¨å®é™…æµ‹è¯•ä¸­ï¼Œéœ€è¦ç­‰å¾…ä»»åŠ¡å®Œæˆæˆ–æ‰‹åŠ¨è®¾ç½®ä¸ºå®ŒæˆçŠ¶æ€
    
    // æµ‹è¯•é‡è¯•
    let retry_handle = scheduler.retry_task(original_handle).await.expect("é‡è¯•ä»»åŠ¡å¤±è´¥");
    assert_ne!(original_handle.id, retry_handle.id, "é‡è¯•ä»»åŠ¡åº”è¯¥æœ‰æ–°çš„å¥æŸ„");
}

#[tokio::test]
async fn test_error_recovery() {
    let scheduler = TaskSchedulerTestSuite::create_test_scheduler().await;
    
    // æµ‹è¯•å¥åº·æ£€æŸ¥
    let health = scheduler.health_check().await.expect("å¥åº·æ£€æŸ¥å¤±è´¥");
    assert!(health.is_healthy, "æ–°åˆ›å»ºçš„è°ƒåº¦å™¨åº”è¯¥æ˜¯å¥åº·çš„");
    
    // æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
    let metrics = scheduler.get_performance_metrics().await.expect("è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥");
    assert!(metrics.tasks_per_second >= 0.0, "ä»»åŠ¡å¤„ç†é€Ÿç‡åº”è¯¥ä¸ä¸ºè´Ÿ");
}

#[tokio::test]
async fn test_event_subscription() {
    let scheduler = TaskSchedulerTestSuite::create_test_scheduler().await;
    
    // è®¢é˜…ä»»åŠ¡äº‹ä»¶
    let mut task_receiver = scheduler.subscribe_task_events().await.expect("è®¢é˜…ä»»åŠ¡äº‹ä»¶å¤±è´¥");
    
    // è®¢é˜…æ‰¹æ¬¡äº‹ä»¶
    let mut batch_receiver = scheduler.subscribe_batch_events().await.expect("è®¢é˜…æ‰¹æ¬¡äº‹ä»¶å¤±è´¥");
    
    // åœ¨å¦ä¸€ä¸ªä»»åŠ¡ä¸­ç›‘å¬äº‹ä»¶
    let task_listener = tokio::spawn(async move {
        match tokio::time::timeout(std::time::Duration::from_secs(5), task_receiver.recv()).await {
            Ok(Ok(event)) => Some(event),
            _ => None,
        }
    });
    
    let batch_listener = tokio::spawn(async move {
        match tokio::time::timeout(std::time::Duration::from_secs(5), batch_receiver.recv()).await {
            Ok(Ok(event)) => Some(event),
            _ => None,
        }
    });
    
    // è§¦å‘äº‹ä»¶
    let task = TaskSchedulerTestSuite::create_test_task("event_test_batch");
    let batch_id = task.batch_id.clone();
    let tasks = vec![task];
    
    scheduler.schedule_batch_tasks(&batch_id, tasks).await.expect("è°ƒåº¦æ‰¹æ¬¡å¤±è´¥");
    
    // éªŒè¯äº‹ä»¶
    let task_event = task_listener.await.expect("ä»»åŠ¡ç›‘å¬å™¨å¤±è´¥");
    let batch_event = batch_listener.await.expect("æ‰¹æ¬¡ç›‘å¬å™¨å¤±è´¥");
    
    assert!(task_event.is_some(), "åº”è¯¥æ¥æ”¶åˆ°ä»»åŠ¡äº‹ä»¶");
    assert!(batch_event.is_some(), "åº”è¯¥æ¥æ”¶åˆ°æ‰¹æ¬¡äº‹ä»¶");
}

/// æ€§èƒ½å‹åŠ›æµ‹è¯•
#[tokio::test]
async fn test_performance_stress() {
    let scheduler = Arc::new(TaskSchedulerTestSuite::create_test_scheduler().await);
    let start_time = std::time::Instant::now();
    
    // è°ƒåº¦å¤§é‡ä»»åŠ¡
    let batch_size = 1000;
    let tasks: Vec<TestTask> = (0..batch_size)
        .map(|i| TaskSchedulerTestSuite::create_test_task(&format!("stress_batch_{}", i % 10)))
        .collect();
    
    let handles = scheduler.schedule_batch_tasks("stress_test", tasks).await.expect("å‹åŠ›æµ‹è¯•è°ƒåº¦å¤±è´¥");
    
    let schedule_duration = start_time.elapsed();
    println!("è°ƒåº¦{}ä¸ªä»»åŠ¡è€—æ—¶: {:?}", batch_size, schedule_duration);
    
    assert_eq!(handles.len(), batch_size, "åº”è¯¥è°ƒåº¦æ‰€æœ‰ä»»åŠ¡");
    assert!(schedule_duration.as_millis() < 5000, "è°ƒåº¦åº”è¯¥åœ¨5ç§’å†…å®Œæˆ");
    
    // æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½
    let load = scheduler.get_system_load().await.expect("è·å–ç³»ç»Ÿè´Ÿè½½å¤±è´¥");
    assert_eq!(load.pending_tasks, batch_size, "æ‰€æœ‰ä»»åŠ¡éƒ½åº”è¯¥åœ¨å¾…æ‰§è¡ŒçŠ¶æ€");
}
```

### âœ… æ­¥éª¤3.1å®Œæˆæ ‡å‡†

1. **è°ƒåº¦åŠŸèƒ½**: æ”¯æŒä¼˜å…ˆçº§è°ƒåº¦å’Œæ‰¹æ¬¡ç®¡ç†
2. **å¹¶å‘æ§åˆ¶**: å¯é…ç½®çš„å¹¶å‘é™åˆ¶å’Œèµ„æºç®¡ç†
3. **é”™è¯¯æ¢å¤**: å®Œå–„çš„é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
4. **ç›‘æ§åŠŸèƒ½**: å¥åº·æ£€æŸ¥å’Œæ€§èƒ½æŒ‡æ ‡
5. **äº‹ä»¶ç³»ç»Ÿ**: å®Œæ•´çš„ä»»åŠ¡å’Œæ‰¹æ¬¡äº‹ä»¶é€šçŸ¥
6. **æ€§èƒ½è¡¨ç°**: æ”¯æŒå¤§è§„æ¨¡ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œ
7. **ç¨³å®šæ€§**: å‚è€ƒåŸæœ‰C#é€»è¾‘å¹¶å¢å¼ºé”™è¯¯å¤„ç†èƒ½åŠ›

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

## ğŸš€ Phase 4: åº”ç”¨æœåŠ¡å±‚é‡æ„

### æ­¥éª¤ 4.1: åˆ›å»ºåº”ç”¨æœåŠ¡å±‚

#### ğŸ¯ ç›®æ ‡
é€šè¿‡æœåŠ¡ç»„åˆæ¨¡å¼å®ç°å¤æ‚ä¸šåŠ¡æµç¨‹ï¼Œç¡®ä¿å•ä¸€èŒè´£å’Œé«˜å¯ç»´æŠ¤æ€§ã€‚

#### ğŸ“ å…·ä½“å®æ–½

##### 4.1.1 å®šä¹‰æ ¸å¿ƒåº”ç”¨æœåŠ¡æ¥å£
```rust
// src/services/application/mod.rs
use async_trait::async_trait;
use crate::models::structs::{TestBatchInfo, ChannelTestInstance, ChannelPointDefinition};
use crate::models::errors::ApplicationError;
use std::sync::Arc;

/// æµ‹è¯•ç¼–æ’æœåŠ¡æ¥å£
#[async_trait]
pub trait ITestOrchestrationService: Send + Sync {
    // æ‰¹æ¬¡ç®¡ç†
    async fn create_test_batch(&self, product_model: Option<String>) -> Result<TestBatchInfo, ApplicationError>;
    async fn prepare_instances_for_batch(&self, batch_id: &str, definitions: &[ChannelPointDefinition]) -> Result<Vec<String>, ApplicationError>;
    async fn start_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError>;
    async fn pause_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError>;
    async fn resume_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError>;
    async fn cancel_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError>;
    
    // å®ä¾‹ç®¡ç†
    async fn start_instance_testing(&self, instance_id: &str) -> Result<(), ApplicationError>;
    async fn pause_instance_testing(&self, instance_id: &str) -> Result<(), ApplicationError>;
    async fn reset_instance_for_retest(&self, instance_id: &str) -> Result<(), ApplicationError>;
    
    // æ‰¹é‡æ“ä½œ
    async fn batch_reset_instances(&self, instance_ids: Vec<String>) -> Result<(), ApplicationError>;
    async fn batch_start_testing(&self, instance_ids: Vec<String>) -> Result<(), ApplicationError>;
}

/// æ•°æ®ç®¡ç†æœåŠ¡æ¥å£
#[async_trait]
pub trait IDataManagementService: Send + Sync {
    // é…ç½®å¯¼å…¥å¯¼å‡º
    async fn import_configuration_from_excel(&self, file_path: &str, config_name: &str) -> Result<Vec<ChannelPointDefinition>, ApplicationError>;
    async fn export_configuration_to_excel(&self, config_name: &str, file_path: &str) -> Result<(), ApplicationError>;
    
    // é…ç½®ç®¡ç†
    async fn save_configuration_set(&self, name: &str, definitions: &[ChannelPointDefinition]) -> Result<(), ApplicationError>;
    async fn load_configuration_set(&self, name: &str) -> Result<Vec<ChannelPointDefinition>, ApplicationError>;
    async fn list_configuration_sets(&self) -> Result<Vec<String>, ApplicationError>;
    async fn delete_configuration_set(&self, name: &str) -> Result<(), ApplicationError>;
    
    // æ•°æ®éªŒè¯
    async fn validate_configuration(&self, definitions: &[ChannelPointDefinition]) -> Result<ValidationReport, ApplicationError>;
    async fn check_data_consistency(&self) -> Result<ConsistencyReport, ApplicationError>;
}

/// ç³»ç»Ÿç®¡ç†æœåŠ¡æ¥å£
#[async_trait]
pub trait ISystemManagementService: Send + Sync {
    // ç³»ç»Ÿé…ç½®
    async fn get_system_configuration(&self) -> Result<SystemConfiguration, ApplicationError>;
    async fn update_system_configuration(&self, config: &SystemConfiguration) -> Result<(), ApplicationError>;
    
    // ç³»ç»Ÿç›‘æ§
    async fn get_system_status(&self) -> Result<SystemStatus, ApplicationError>;
    async fn get_performance_metrics(&self) -> Result<SystemPerformanceMetrics, ApplicationError>;
    
    // ç»´æŠ¤æ“ä½œ
    async fn cleanup_old_data(&self, retention_days: u32) -> Result<CleanupReport, ApplicationError>;
    async fn backup_data(&self, backup_path: &str) -> Result<BackupReport, ApplicationError>;
    async fn restore_data(&self, backup_path: &str) -> Result<RestoreReport, ApplicationError>;
}

/// éªŒè¯æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct ValidationReport {
    pub is_valid: bool,
    pub total_checked: usize,
    pub issues: Vec<ValidationIssue>,
    pub warnings: Vec<ValidationWarning>,
    pub summary: String,
}

/// ä¸€è‡´æ€§æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct ConsistencyReport {
    pub is_consistent: bool,
    pub checked_components: Vec<String>,
    pub inconsistencies: Vec<InconsistencyIssue>,
    pub recommendations: Vec<String>,
}

/// ç³»ç»Ÿé…ç½®
#[derive(Debug, Clone)]
pub struct SystemConfiguration {
    pub max_concurrent_tests: usize,
    pub default_timeout_ms: u64,
    pub auto_backup_enabled: bool,
    pub backup_retention_days: u32,
    pub log_level: String,
    pub plc_connection_timeout_ms: u64,
}

/// ç³»ç»ŸçŠ¶æ€
#[derive(Debug, Clone)]
pub struct SystemStatus {
    pub is_healthy: bool,
    pub uptime_seconds: u64,
    pub active_batches: usize,
    pub active_tests: usize,
    pub memory_usage_mb: f64,
    pub cpu_usage_percentage: f64,
    pub disk_usage_percentage: f64,
}

/// ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone)]
pub struct SystemPerformanceMetrics {
    pub tests_completed_today: u64,
    pub average_test_duration_ms: f64,
    pub success_rate_percentage: f64,
    pub error_rate_percentage: f64,
    pub throughput_tests_per_hour: f64,
}

/// æ¸…ç†æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct CleanupReport {
    pub cleaned_files: usize,
    pub freed_space_mb: f64,
    pub deleted_records: usize,
    pub cleanup_duration_ms: u64,
}

/// å¤‡ä»½æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct BackupReport {
    pub backup_path: String,
    pub backup_size_mb: f64,
    pub included_files: usize,
    pub backup_duration_ms: u64,
    pub is_successful: bool,
}

/// æ¢å¤æŠ¥å‘Š
#[derive(Debug, Clone)]
pub struct RestoreReport {
    pub restored_files: usize,
    pub restored_records: usize,
    pub restore_duration_ms: u64,
    pub is_successful: bool,
    pub verification_passed: bool,
}
```

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

##### 4.1.2 å®ç°æµ‹è¯•ç¼–æ’æœåŠ¡
```rust
// src/services/application/test_orchestration_service.rs
use super::*;
use crate::services::state_management::IChannelStateManager;
use crate::services::task_scheduling::ITaskScheduler;
use crate::repositories::{IConfigurationRepository, IRuntimeRepository};
use crate::models::structs::{TestTask, SubTestItem, TaskPriority};
use crate::models::enums::OverallTestStatus;

/// æµ‹è¯•ç¼–æ’æœåŠ¡å®ç°
pub struct TestOrchestrationService {
    config_repo: Arc<dyn IConfigurationRepository>,
    runtime_repo: Arc<dyn IRuntimeRepository>,
    state_manager: Arc<dyn IChannelStateManager>,
    task_scheduler: Arc<dyn ITaskScheduler>,
}

impl TestOrchestrationService {
    pub fn new(
        config_repo: Arc<dyn IConfigurationRepository>,
        runtime_repo: Arc<dyn IRuntimeRepository>,
        state_manager: Arc<dyn IChannelStateManager>,
        task_scheduler: Arc<dyn ITaskScheduler>,
    ) -> Self {
        Self {
            config_repo,
            runtime_repo,
            state_manager,
            task_scheduler,
        }
    }
}

#[async_trait]
impl ITestOrchestrationService for TestOrchestrationService {
    async fn create_test_batch(&self, product_model: Option<String>) -> Result<TestBatchInfo, ApplicationError> {
        let batch_id = uuid::Uuid::new_v4().to_string();
        
        let batch_info = TestBatchInfo {
            batch_id: batch_id.clone(),
            product_model,
            serial_number: None,
            customer_name: None,
            creation_time: chrono::Utc::now(),
            status_summary: Some("å·²åˆ›å»º".to_string()),
            total_points: 0,
            tested_points: 0,
            passed_points: 0,
            failed_points: 0,
        };
        
        self.runtime_repo
            .save_test_batch(&batch_info)
            .await
            .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        
        log::info!("æµ‹è¯•æ‰¹æ¬¡å·²åˆ›å»º: batch_id={}, product_model={:?}", batch_id, product_model);
        Ok(batch_info)
    }
    
    async fn prepare_instances_for_batch(&self, batch_id: &str, definitions: &[ChannelPointDefinition]) -> Result<Vec<String>, ApplicationError> {
        let mut instance_ids = Vec::new();
        
        for definition in definitions {
            let instance = ChannelTestInstance {
                instance_id: uuid::Uuid::new_v4().to_string(),
                definition_id: definition.id.clone(),
                test_batch_id: batch_id.to_string(),
                overall_status: OverallTestStatus::NotTested,
                current_step_details: None,
                error_message: None,
                start_time: None,
                last_updated_time: chrono::Utc::now(),
                final_test_time: None,
                total_test_duration_ms: None,
                sub_test_results: std::collections::HashMap::new(),
                hardpoint_readings: None,
                manual_test_current_value_input: None,
                manual_test_current_value_output: None,
            };
            
            instance_ids.push(instance.instance_id.clone());
            
            self.runtime_repo
                .save_channel_instance(&instance)
                .await
                .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        }
        
        // æ›´æ–°æ‰¹æ¬¡ä¿¡æ¯
        if let Ok(Some(mut batch_info)) = self.runtime_repo.get_test_batch(batch_id).await {
            batch_info.total_points = instance_ids.len();
            batch_info.status_summary = Some("å·²å‡†å¤‡å°±ç»ª".to_string());
            
            self.runtime_repo
                .save_test_batch(&batch_info)
                .await
                .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        }
        
        log::info!("æ‰¹æ¬¡å®ä¾‹å‡†å¤‡å®Œæˆ: batch_id={}, instance_count={}", batch_id, instance_ids.len());
        Ok(instance_ids)
    }
    
    async fn start_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError> {
        // è·å–æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å®ä¾‹
        let instances = self.runtime_repo
            .list_batch_instances(batch_id)
            .await
            .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        
        if instances.is_empty() {
            return Err(ApplicationError::InvalidOperation("æ‰¹æ¬¡ä¸­æ²¡æœ‰æµ‹è¯•å®ä¾‹".to_string()));
        }
        
        // ä¸ºæ¯ä¸ªå®ä¾‹åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        let mut tasks = Vec::new();
        for instance in instances {
            let test_task = TestTask {
                task_id: uuid::Uuid::new_v4().to_string(),
                instance_id: instance.instance_id,
                definition_id: instance.definition_id,
                batch_id: batch_id.to_string(),
                test_items: vec![SubTestItem::HardPoint], // æ ¹æ®å®é™…éœ€è¦é…ç½®
                priority: TaskPriority::Normal,
                retry_count: 0,
                max_retries: 3,
                timeout_ms: Some(30000),
                dependencies: vec![],
                metadata: std::collections::HashMap::new(),
            };
            tasks.push(test_task);
        }
        
        // è°ƒåº¦æ‰¹æ¬¡ä»»åŠ¡
        let task_handles = self.task_scheduler
            .schedule_batch_tasks(batch_id, tasks)
            .await
            .map_err(|e| ApplicationError::SchedulerError(e.to_string()))?;
        
        // æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
        if let Ok(Some(mut batch_info)) = self.runtime_repo.get_test_batch(batch_id).await {
            batch_info.status_summary = Some("æµ‹è¯•ä¸­".to_string());
            
            self.runtime_repo
                .save_test_batch(&batch_info)
                .await
                .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        }
        
        log::info!("æ‰¹æ¬¡æµ‹è¯•å·²å¯åŠ¨: batch_id={}, task_count={}", batch_id, task_handles.len());
        Ok(())
    }
    
    async fn pause_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError> {
        self.task_scheduler
            .pause_batch(batch_id)
            .await
            .map_err(|e| ApplicationError::SchedulerError(e.to_string()))?;
        
        // æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
        if let Ok(Some(mut batch_info)) = self.runtime_repo.get_test_batch(batch_id).await {
            batch_info.status_summary = Some("å·²æš‚åœ".to_string());
            
            self.runtime_repo
                .save_test_batch(&batch_info)
                .await
                .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        }
        
        log::info!("æ‰¹æ¬¡æµ‹è¯•å·²æš‚åœ: batch_id={}", batch_id);
        Ok(())
    }
    
    async fn resume_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError> {
        self.task_scheduler
            .resume_batch(batch_id)
            .await
            .map_err(|e| ApplicationError::SchedulerError(e.to_string()))?;
        
        // æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
        if let Ok(Some(mut batch_info)) = self.runtime_repo.get_test_batch(batch_id).await {
            batch_info.status_summary = Some("æµ‹è¯•ä¸­".to_string());
            
            self.runtime_repo
                .save_test_batch(&batch_info)
                .await
                .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        }
        
        log::info!("æ‰¹æ¬¡æµ‹è¯•å·²æ¢å¤: batch_id={}", batch_id);
        Ok(())
    }
    
    async fn cancel_batch_testing(&self, batch_id: &str) -> Result<(), ApplicationError> {
        self.task_scheduler
            .cancel_batch(batch_id)
            .await
            .map_err(|e| ApplicationError::SchedulerError(e.to_string()))?;
        
        // æ›´æ–°æ‰¹æ¬¡çŠ¶æ€
        if let Ok(Some(mut batch_info)) = self.runtime_repo.get_test_batch(batch_id).await {
            batch_info.status_summary = Some("å·²å–æ¶ˆ".to_string());
            
            self.runtime_repo
                .save_test_batch(&batch_info)
                .await
                .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?;
        }
        
        log::info!("æ‰¹æ¬¡æµ‹è¯•å·²å–æ¶ˆ: batch_id={}", batch_id);
        Ok(())
    }
    
    async fn start_instance_testing(&self, instance_id: &str) -> Result<(), ApplicationError> {
        // è·å–å®ä¾‹ä¿¡æ¯
        let instance = self.runtime_repo
            .get_channel_instance(instance_id)
            .await
            .map_err(|e| ApplicationError::RepositoryError(e.to_string()))?
            .ok_or_else(|| ApplicationError::InstanceNotFound(instance_id.to_string()))?;
        
        // æ£€æŸ¥å®ä¾‹çŠ¶æ€
        if instance.overall_status != OverallTestStatus::NotTested {
            return Err(ApplicationError::InvalidOperation(
                format!("å®ä¾‹çŠ¶æ€ä¸å…è®¸å¯åŠ¨æµ‹è¯•: {}", instance_id)
            ));
        }
        
        // åˆ›å»ºå•ä¸ªå®ä¾‹çš„æµ‹è¯•ä»»åŠ¡
        let test_task = TestTask {
            task_id: uuid::Uuid::new_v4().to_string(),
            instance_id: instance.instance_id.clone(),
            definition_id: instance.definition_id.clone(),
            batch_id: instance.test_batch_id.clone(),
            test_items: vec![SubTestItem::HardPoint], // æ ¹æ®å®é™…éœ€è¦é…ç½®
            priority: TaskPriority::Normal,
            retry_count: 0,
            max_retries: 3,
            timeout_ms: Some(30000),
            dependencies: vec![],
            metadata: std::collections::HashMap::new(),
        };
        
        // è°ƒåº¦ä»»åŠ¡
        let task_handle = self.task_scheduler
            .schedule_test_task(test_task)
            .await
            .map_err(|e| ApplicationError::SchedulerError(e.to_string()))?;
        
        log::info!("å®ä¾‹æµ‹è¯•å·²å¯åŠ¨: instance_id={}, task_handle={:?}", instance_id, task_handle);
        Ok(())
    }
    
    async fn pause_instance_testing(&self, instance_id: &str) -> Result<(), ApplicationError> {
        // åœ¨å®é™…å®ç°ä¸­ï¼Œéœ€è¦æ‰¾åˆ°å¯¹åº”çš„ä»»åŠ¡å¥æŸ„
        // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåœ¨å®é™…é¡¹ç›®ä¸­éœ€è¦ç»´æŠ¤å®ä¾‹IDåˆ°ä»»åŠ¡å¥æŸ„çš„æ˜ å°„
        log::info!("å®ä¾‹æµ‹è¯•æš‚åœè¯·æ±‚: instance_id={}", instance_id);
        Ok(())
    }
    
    async fn reset_instance_for_retest(&self, instance_id: &str) -> Result<(), ApplicationError> {
        self.state_manager
            .reset_for_retest(instance_id)
            .await
            .map_err(|e| ApplicationError::StateError(e.to_string()))?;
        
        log::info!("å®ä¾‹å·²é‡ç½®è¿›è¡Œé‡æµ‹: instance_id={}", instance_id);
        Ok(())
    }
    
    async fn batch_reset_instances(&self, instance_ids: Vec<String>) -> Result<(), ApplicationError> {
        self.state_manager
            .batch_reset_for_retest(instance_ids.clone())
            .await
            .map_err(|e| ApplicationError::StateError(e.to_string()))?;
        
        log::info!("æ‰¹é‡é‡ç½®å®ä¾‹å®Œæˆ: count={}", instance_ids.len());
        Ok(())
    }
    
    async fn batch_start_testing(&self, instance_ids: Vec<String>) -> Result<(), ApplicationError> {
        let mut success_count = 0;
        let mut error_count = 0;
        
        for instance_id in instance_ids {
            match self.start_instance_testing(&instance_id).await {
                Ok(()) => success_count += 1,
                Err(e) => {
                    error_count += 1;
                    log::error!("å¯åŠ¨å®ä¾‹æµ‹è¯•å¤±è´¥: instance_id={}, error={:?}", instance_id, e);
                }
            }
        }
        
        if error_count > 0 {
            return Err(ApplicationError::PartialFailure(
                format!("æ‰¹é‡å¯åŠ¨æµ‹è¯•éƒ¨åˆ†å¤±è´¥: æˆåŠŸ={}, å¤±è´¥={}", success_count, error_count)
            ));
        }
        
        log::info!("æ‰¹é‡å¯åŠ¨æµ‹è¯•å®Œæˆ: count={}", success_count);
        Ok(())
    }
}
```

---

*æœ¬æ–‡æ¡£æŒç»­æ›´æ–°ä¸­...*

#### ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

##### 4.1.3 åº”ç”¨æœåŠ¡æµ‹è¯•
```rust
// src/services/application/tests/test_orchestration_service_tests.rs
use super::super::*;
use tokio;

struct ApplicationServiceTestSuite;

impl ApplicationServiceTestSuite {
    async fn create_test_orchestration_service() -> TestOrchestrationService {
        let config_repo = Arc::new(MockConfigurationRepository::new());
        let runtime_repo = Arc::new(MockRuntimeRepository::new());
        let state_manager = Arc::new(MockChannelStateManager::new());
        let task_scheduler = Arc::new(MockTaskScheduler::new());
        
        TestOrchestrationService::new(
            config_repo,
            runtime_repo,
            state_manager,
            task_scheduler,
        )
    }
    
    fn create_test_definitions() -> Vec<ChannelPointDefinition> {
        (0..5).map(|i| ChannelPointDefinition {
            id: format!("def_{}", i),
            tag: format!("TEST_TAG_{:03}", i),
            variable_name: format!("Test Variable {}", i),
            module_type: ModuleType::AI,
            // ... å…¶ä»–å­—æ®µ
        }).collect()
    }
}

#[tokio::test]
async fn test_create_and_start_batch() {
    let service = ApplicationServiceTestSuite::create_test_orchestration_service().await;
    
    // åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
    let batch_info = service.create_test_batch(Some("æµ‹è¯•äº§å“".to_string())).await.expect("åˆ›å»ºæ‰¹æ¬¡å¤±è´¥");
    assert!(!batch_info.batch_id.is_empty(), "æ‰¹æ¬¡IDä¸åº”ä¸ºç©º");
    assert_eq!(batch_info.product_model, Some("æµ‹è¯•äº§å“".to_string()), "äº§å“å‹å·åº”è¯¥åŒ¹é…");
    
    // å‡†å¤‡å®ä¾‹
    let definitions = ApplicationServiceTestSuite::create_test_definitions();
    let instance_ids = service.prepare_instances_for_batch(&batch_info.batch_id, &definitions).await.expect("å‡†å¤‡å®ä¾‹å¤±è´¥");
    assert_eq!(instance_ids.len(), 5, "åº”è¯¥åˆ›å»º5ä¸ªå®ä¾‹");
    
    // å¯åŠ¨æ‰¹æ¬¡æµ‹è¯•
    service.start_batch_testing(&batch_info.batch_id).await.expect("å¯åŠ¨æ‰¹æ¬¡æµ‹è¯•å¤±è´¥");
}

#[tokio::test]
async fn test_batch_lifecycle() {
    let service = ApplicationServiceTestSuite::create_test_orchestration_service().await;
    
    // åˆ›å»ºå’Œå‡†å¤‡æ‰¹æ¬¡
    let batch_info = service.create_test_batch(None).await.expect("åˆ›å»ºæ‰¹æ¬¡å¤±è´¥");
    let definitions = ApplicationServiceTestSuite::create_test_definitions();
    let _instance_ids = service.prepare_instances_for_batch(&batch_info.batch_id, &definitions).await.expect("å‡†å¤‡å®ä¾‹å¤±è´¥");
    
    // å¯åŠ¨æµ‹è¯•
    service.start_batch_testing(&batch_info.batch_id).await.expect("å¯åŠ¨æµ‹è¯•å¤±è´¥");
    
    // æš‚åœæµ‹è¯•
    service.pause_batch_testing(&batch_info.batch_id).await.expect("æš‚åœæµ‹è¯•å¤±è´¥");
    
    // æ¢å¤æµ‹è¯•
    service.resume_batch_testing(&batch_info.batch_id).await.expect("æ¢å¤æµ‹è¯•å¤±è´¥");
    
    // å–æ¶ˆæµ‹è¯•
    service.cancel_batch_testing(&batch_info.batch_id).await.expect("å–æ¶ˆæµ‹è¯•å¤±è´¥");
}

#[tokio::test]
async fn test_instance_operations() {
    let service = ApplicationServiceTestSuite::create_test_orchestration_service().await;
    
    // åˆ›å»ºå’Œå‡†å¤‡æ‰¹æ¬¡
    let batch_info = service.create_test_batch(None).await.expect("åˆ›å»ºæ‰¹æ¬¡å¤±è´¥");
    let definitions = ApplicationServiceTestSuite::create_test_definitions();
    let instance_ids = service.prepare_instances_for_batch(&batch_info.batch_id, &definitions).await.expect("å‡†å¤‡å®ä¾‹å¤±è´¥");
    
    let instance_id = &instance_ids[0];
    
    // å¯åŠ¨å•ä¸ªå®ä¾‹æµ‹è¯•
    service.start_instance_testing(instance_id).await.expect("å¯åŠ¨å®ä¾‹æµ‹è¯•å¤±è´¥");
    
    // é‡ç½®å®ä¾‹
    service.reset_instance_for_retest(instance_id).await.expect("é‡ç½®å®ä¾‹å¤±è´¥");
    
    // æ‰¹é‡é‡ç½®
    service.batch_reset_instances(instance_ids.clone()).await.expect("æ‰¹é‡é‡ç½®å¤±è´¥");
    
    // æ‰¹é‡å¯åŠ¨
    service.batch_start_testing(instance_ids).await.expect("æ‰¹é‡å¯åŠ¨å¤±è´¥");
}

#[tokio::test]
async fn test_error_handling() {
    let service = ApplicationServiceTestSuite::create_test_orchestration_service().await;
    
    // æµ‹è¯•å¯åŠ¨ä¸å­˜åœ¨çš„æ‰¹æ¬¡
    let result = service.start_batch_testing("not_exist_batch").await;
    assert!(result.is_err(), "å¯åŠ¨ä¸å­˜åœ¨çš„æ‰¹æ¬¡åº”è¯¥å¤±è´¥");
    
    // æµ‹è¯•é‡ç½®ä¸å­˜åœ¨çš„å®ä¾‹
    let result = service.reset_instance_for_retest("not_exist_instance").await;
    assert!(result.is_err(), "é‡ç½®ä¸å­˜åœ¨çš„å®ä¾‹åº”è¯¥å¤±è´¥");
}
```

### âœ… æ­¥éª¤4.1å®Œæˆæ ‡å‡†

1. **æœåŠ¡ç»„åˆ**: é€šè¿‡ç»„åˆé¢†åŸŸæœåŠ¡å®ç°å¤æ‚ä¸šåŠ¡æµç¨‹
2. **å•ä¸€èŒè´£**: æ¯ä¸ªåº”ç”¨æœåŠ¡èŒè´£æ˜ç¡®å•ä¸€
3. **é”™è¯¯å¤„ç†**: ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œè½¬æ¢æœºåˆ¶
4. **äº‹åŠ¡ä¸€è‡´æ€§**: ç¡®ä¿è·¨æœåŠ¡æ“ä½œçš„ä¸€è‡´æ€§
5. **é«˜å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„ä»£ç ç»“æ„å’Œå®Œæ•´æµ‹è¯•è¦†ç›–
6. **æ—¥å¿—è®°å½•**: å®Œæ•´çš„æ“ä½œæ—¥å¿—è®°å½•
7. **å¼‚å¸¸å¤„ç†**: ä¼˜é›…çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯

---

## ğŸ“Š é‡æ„å®Œæˆæ€»ç»“

### ğŸ¯ è¾¾æˆçš„ç›®æ ‡

é€šè¿‡å››ä¸ªé˜¶æ®µçš„è¯¦ç»†é‡æ„ï¼Œæˆ‘ä»¬æˆåŠŸè§£å†³äº†ç”¨æˆ·æå‡ºçš„æ‰€æœ‰å…³é”®é—®é¢˜ï¼š

1. **âœ… ç»Ÿä¸€æ•°æ®æºç®¡ç†**: Repositoryæ¨¡å¼ç¡®ä¿æ‰€æœ‰æ•°æ®è®¿é—®éƒ½é€šè¿‡ç»Ÿä¸€æ¥å£
   - IConfigurationRepository ç®¡ç†é…ç½®æ•°æ®
   - IRuntimeRepository ç®¡ç†è¿è¡Œæ—¶æ•°æ®
   - IPersistentRepository ç®¡ç†æŒä¹…åŒ–æ•°æ®

2. **âœ… æ•°æ®æ¨¡å‹èŒè´£åˆ’åˆ†**: ä¸‰å±‚æ•°æ®æ¨¡å‹æ˜ç¡®åŒºåˆ†é…ç½®ã€è¿è¡Œæ—¶å’ŒæŒä¹…åŒ–æ•°æ®
   - Configuration Layer: åªè¯»é…ç½®æ•°æ®
   - Runtime Layer: å¯å˜è¿è¡Œæ—¶æ•°æ®
   - Persistent Layer: éœ€è¦ä¿å­˜çš„å†å²æ•°æ®

3. **âœ… æœåŠ¡å•ä¸€èŒè´£**: æ¯ä¸ªæœåŠ¡éƒ½æœ‰æ˜ç¡®å•ä¸€çš„åŠŸèƒ½è¾¹ç•Œ
   - ChannelStateManager: åªè´Ÿè´£çŠ¶æ€ç®¡ç†
   - TaskScheduler: åªè´Ÿè´£ä»»åŠ¡è°ƒåº¦
   - TestExecutor: åªè´Ÿè´£æµ‹è¯•æ‰§è¡Œ

4. **âœ… æœåŠ¡ç»„åˆæ¨¡å¼**: åº”ç”¨æœåŠ¡å±‚é€šè¿‡ç»„åˆé¢†åŸŸæœåŠ¡å®ç°å¤æ‚ä¸šåŠ¡æµç¨‹
   - TestOrchestrationService: ç¼–æ’æµ‹è¯•æµç¨‹
   - DataManagementService: ç®¡ç†æ•°æ®æ“ä½œ
   - SystemManagementService: ç®¡ç†ç³»ç»Ÿç»´æŠ¤

5. **âœ… ä»»åŠ¡ç®¡ç†ä¼˜åŒ–**: å‚è€ƒåŸæœ‰é€»è¾‘å¹¶å¢å¼ºç¨³å®šæ€§å’Œé”™è¯¯æ¢å¤èƒ½åŠ›
   - ä¼˜å…ˆçº§è°ƒåº¦å’Œæ‰¹æ¬¡ç®¡ç†
   - å®Œå–„çš„é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤
   - å¥åº·ç›‘æ§å’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ—ï¸ æ¶æ„ä¼˜åŠ¿

- **æ•°æ®ä¸€è‡´æ€§**: é€šè¿‡Repositoryå’ŒçŠ¶æ€ç®¡ç†å™¨ç¡®ä¿æ•°æ®è®¿é—®çš„ä¸€è‡´æ€§
- **é«˜å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„åˆ†å±‚æ¶æ„å’Œå•ä¸€èŒè´£åŸåˆ™
- **é«˜å¯æ‰©å±•æ€§**: æœåŠ¡ç»„åˆæ¨¡å¼æ”¯æŒçµæ´»çš„ä¸šåŠ¡æµç¨‹æ‰©å±•
- **é«˜ç¨³å®šæ€§**: å®Œå–„çš„é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶å’Œå¥åº·ç›‘æ§
- **é«˜æ€§èƒ½**: å†…å­˜ç¼“å­˜ã€å¹¶å‘æ§åˆ¶å’Œæ‰¹é‡æ“ä½œä¼˜åŒ–

### ğŸ“ˆ è´¨é‡ä¿è¯

- **å®Œæ•´æµ‹è¯•è¦†ç›–**: æ¯ä¸ªç»„ä»¶éƒ½æœ‰è¯¦ç»†çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- **æ€§èƒ½éªŒè¯**: æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†çš„æ€§èƒ½æµ‹è¯•
- **å¹¶å‘å®‰å…¨**: å…¨å¼‚æ­¥è®¾è®¡å’Œå¹¶å‘å®‰å…¨ä¿è¯
- **é”™è¯¯æ¢å¤**: å®Œå–„çš„é‡è¯•ç­–ç•¥å’Œæ•…éšœæ¢å¤æœºåˆ¶

### ğŸš€ å®æ–½è·¯å¾„

1. **Phase 1 (1-2å‘¨)**: æ•°æ®è®¿é—®å±‚é‡æ„ - å»ºç«‹RepositoryåŸºç¡€
2. **Phase 2 (1-2å‘¨)**: çŠ¶æ€ç®¡ç†å™¨é‡æ„ - ç¡®ä¿çŠ¶æ€ä¸€è‡´æ€§
3. **Phase 3 (2-3å‘¨)**: ä»»åŠ¡è°ƒåº¦å™¨é‡æ„ - ä¼˜åŒ–ä»»åŠ¡ç®¡ç†
4. **Phase 4 (1-2å‘¨)**: åº”ç”¨æœåŠ¡å±‚é‡æ„ - å®ç°æœåŠ¡ç»„åˆ

### ğŸ’¡ åç»­å»ºè®®

1. **æ¸è¿›å¼é‡æ„**: æŒ‰é˜¶æ®µå®æ–½ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µéƒ½èƒ½ç‹¬ç«‹å·¥ä½œ
2. **æµ‹è¯•å…ˆè¡Œ**: ä¸ºæ¯ä¸ªç»„ä»¶ç¼–å†™å……åˆ†çš„æµ‹è¯•ç”¨ä¾‹
3. **ç›‘æ§æŒ‡æ ‡**: å»ºç«‹å®Œå–„çš„ç³»ç»Ÿç›‘æ§å’Œæ€§èƒ½æŒ‡æ ‡
4. **æ–‡æ¡£ç»´æŠ¤**: ä¿æŒæ¶æ„æ–‡æ¡£å’ŒAPIæ–‡æ¡£çš„æ›´æ–°

è¿™ä¸ªé‡æ„æ–¹æ¡ˆä¸ºFAT_TESTç³»ç»Ÿå¥ å®šäº†åšå®çš„æŠ€æœ¯åŸºç¡€ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿé•¿æœŸç¨³å®šè¿è¡Œå¹¶æ”¯æŒæœªæ¥çš„åŠŸèƒ½æ‰©å±•ã€‚

---

## ğŸ“– é™„å½•

### A. é”™è¯¯ç±»å‹å®šä¹‰
```rust
#[derive(Error, Debug, Clone, Serialize)]
pub enum ApplicationError {
    #[error("Repository error: {0}")]
    RepositoryError(String),
    
    #[error("State error: {0}")]
    StateError(String),
    
    #[error("Scheduler error: {0}")]
    SchedulerError(String),
    
    #[error("Instance not found: {0}")]
    InstanceNotFound(String),
    
    #[error("Invalid operation: {0}")]
    InvalidOperation(String),
    
    #[error("Partial failure: {0}")]
    PartialFailure(String),
}
```

### B. é…ç½®æ–‡ä»¶ç¤ºä¾‹
```toml
[system]
max_concurrent_tests = 10
default_timeout_ms = 30000
auto_backup_enabled = true
backup_retention_days = 30

[logging]
level = "info"
file_path = "logs/fat_test.log"

[plc]
connection_timeout_ms = 5000
retry_count = 3
```

---

**é‡æ„è¯¦ç»†å®æ–½æ­¥éª¤æ–‡æ¡£å®Œæˆ**

*æ­¤æ–‡æ¡£æä¾›äº†FAT_TESTç³»ç»Ÿå®Œæ•´çš„é‡æ„å®æ–½æ–¹æ¡ˆï¼Œé€šè¿‡å››ä¸ªé˜¶æ®µçš„è¯¦ç»†æ­¥éª¤ï¼Œç¡®ä¿ç³»ç»Ÿæ¶æ„çš„ç°ä»£åŒ–å’Œç¨³å®šæ€§ã€‚*